{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SRE &amp; DevOps CheatSheet","text":"<p> Sheet that covers everything from</p> <ul> <li>Linux &amp; Shell Scripting</li> <li>CI/CD tools like Jenkins, GitHub Actions</li> <li>Docker &amp; Kubernetes essentials</li> <li>Infrastructure as Code (Terraform, CloudFormation)</li> <li>Monitoring with Prometheus, ELK, Datadog</li> <li>Configuration Management with Ansible, Puppet</li> <li>Security, Networking, Databases, and more!</li> </ul> <p> Automation scripts in Bash &amp; Python for real-world use cases like:</p> <ul> <li>Automated backups</li> <li>EC2 provisioning</li> <li>Jenkins triggers</li> <li>Kubernetes deployments</li> <li>Infrastructure scaling</li> <li>API testing, and more!</li> </ul> <p>Inspired by a document that was posted on LinkedIn by Vikas Phoughat</p> <p>Find any issues or want to add any tips or tricks... Open up an issue or submit a PR</p> <p>This page was created using Material for MkDocs</p> <p>Awesome tutorial on Getting started with Material for MkDocs by  James Willett</p>"},{"location":"01_System_Admin_Scripting/","title":"System Administration &amp; Scripting","text":"<ul> <li>Linux commands</li> <li>Shell Scripting</li> <li>Pyton</li> </ul>"},{"location":"01_System_Admin_Scripting/#linux-commands","title":"Linux commands","text":""},{"location":"01_System_Admin_Scripting/#file-management","title":"File Management","text":"<ul> <li><code>ls</code> - List directory contents.</li> <li><code>cd</code> - Change directory.</li> <li><code>pwd</code> - Print working directory.</li> <li><code>cp</code> - Copy files or directories.</li> <li><code>mv</code> - Move or rename files or directories.</li> <li><code>rm</code> - Remove files or directories.</li> <li><code>touch</code> - Create a new empty file.</li> <li><code>mkdir</code> - Create a new directory.</li> <li><code>rmdir</code> - Remove an empty directory.</li> <li><code>cat</code> - Concatenate and display file contents.</li> <li><code>head</code> - Display the first few lines of a file.</li> <li><code>tail</code> - Display the last few lines of a file.</li> <li><code>chmod</code> - Change file permissions.</li> <li><code>chown</code> - Change file ownership.</li> <li><code>find</code> - Search for files in a directory hierarchy.</li> <li><code>locate</code> - Find files by name.</li> <li><code>grep</code> - Search text using patterns.</li> <li><code>diff</code> - Compare two files line by line.</li> <li><code>tar</code> - Archive files.</li> <li><code>zip/unzip</code> - Compress and extract files.</li> <li><code>scp</code> - Securely copy files over SSH.</li> </ul>"},{"location":"01_System_Admin_Scripting/#system-information-and-monitoring","title":"System Information and Monitoring","text":"<ul> <li><code>top</code> - Display running processes and system usage.</li> <li><code>htop</code> - Interactive process viewer.</li> <li><code>ps</code> - Display current processes.</li> <li><code>df</code> - Show disk space usage.</li> <li><code>du</code> - Show directory space usage.</li> <li><code>free</code> - Show memory usage.</li> <li><code>uptime</code> - Show system uptime.</li> <li><code>uname</code> - Show system information.</li> <li><code>whoami</code> - Display the current logged-in user.</li> <li><code>lsof</code> - List open files and associated processes.</li> <li><code>vmstat</code> - Report virtual memory statistics.</li> <li><code>iostat</code> - Report I/O statistics.</li> <li><code>netstat</code> - Display network connections and routing tables.</li> <li><code>ifconfig</code> - Display or configure a network interface.</li> <li><code>ping</code> - Check network connectivity.</li> <li><code>traceroute</code> - Track the route packets take to a destination.</li> <li><code>date</code> - Show or set the system date and time.</li> <li><code>env</code> - Display environment variables.</li> <li><code>source</code> - Execute commands from a file in the current shell.</li> </ul>"},{"location":"01_System_Admin_Scripting/#package-management-ubuntudebian","title":"Package Management (Ubuntu/Debian)","text":"<ul> <li><code>apt-get</code> - Install, Remove or update packages.<ul> <li><code>apt-get update</code> - Update package lists.</li> <li><code>apt-get upgrade</code> - Upgrade all packages.</li> <li><code>apt-get install</code> - Install packages.</li> <li><code>apt-get remove</code> - Remove packages.</li> </ul> </li> <li><code>dpkg</code> - Install, remove, and manage individual Debian packages.</li> </ul> Update package lists<pre><code>sudo apt-get update\n</code></pre> Install NGINX<pre><code>sudo apt-get install nginx\n</code></pre>"},{"location":"01_System_Admin_Scripting/#user-and-permission-management","title":"User and Permission Management","text":"<ul> <li><code>useradd</code> - Add a new user.</li> <li><code>userdel</code> - Delete a user.</li> <li><code>usermod</code> - Modify a user.</li> <li><code>passwd</code> - Change user password.</li> <li><code>groupadd</code> - Create a new group.</li> <li><code>groupdel</code> - Delete a group.</li> <li><code>groups</code> - Show groups of a user.</li> <li><code>su</code> - Switch user.</li> <li><code>sudo</code> - Execute a command as another user, usually root.</li> </ul> Add a new user<pre><code>sudo useradd -m newuser\n</code></pre> Change file permissions<pre><code>chmod 755 script.sh\n</code></pre> Change file owner<pre><code>sudo chown newuser file.txt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#networking","title":"Networking","text":"<ul> <li><code>curl</code> - Transfer data from or to a server.</li> <li><code>wget</code> - Download files from the internet.</li> <li><code>ssh</code> - Secure shell to a remote server.</li> <li><code>telnet</code> - Connect to a remote machine.</li> <li><code>nslookup</code> - Query DNS records.</li> <li><code>dig</code> - DNS lookup utility.</li> <li><code>iptables</code> - Configure firewall rules.</li> <li><code>firewalld</code> - Firewall management (CentOS/RHEL).</li> <li><code>hostname</code> - Show or set the system hostname.</li> <li><code>ping</code> - Check connectivity to a host.</li> </ul> send ICMP ECHO_REQUEST network hosts<pre><code>ping google.com\n</code></pre> Send HTTP requests<pre><code>curl https://example.com\n</code></pre> View network interfaces<pre><code>ifconfig\n</code></pre>"},{"location":"01_System_Admin_Scripting/#process-management","title":"Process Management","text":"<ul> <li><code>kill</code> - Send a signal to a process.</li> <li><code>killall</code> - Kill processes by name.</li> <li><code>pkill</code> - Kill processes by pattern matching.</li> <li><code>bg</code> - Move a job to the background.</li> <li><code>fg</code> - Bring a job to the foreground.</li> <li><code>jobs</code> - List background jobs.</li> <li><code>ps</code> - Show running processes.</li> </ul> List processes related to nginx<pre><code>ps aux | grep nginx\n</code></pre> Kill process with PID 1234<pre><code>kill 1234\n</code></pre> Kill all nginx processes<pre><code>pkill nginx\n</code></pre>"},{"location":"01_System_Admin_Scripting/#disk-management","title":"Disk Management","text":"<ul> <li><code>fdisk</code> - Partition a disk.</li> <li><code>mkfs</code> - Make a filesystem.</li> <li><code>mount</code> - Mount a filesystem.</li> <li><code>umount</code> - Unmount a filesystem.</li> <li><code>lsblk</code> - List block devices.</li> <li><code>blkid</code> - Print block device attributes.</li> <li><code>fdisk</code> - Manage disk partitions.</li> <li><code>mount</code> - Mount a filesystem.</li> </ul> List disk partitions<pre><code>sudo fdisk -l\n</code></pre> Mount device sdb1 to /mnt<pre><code>sudo mount /dev/sdb1 /mnt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#text-processing","title":"Text Processing","text":"<ul> <li><code>awk</code> - Pattern scanning and processing.</li> <li><code>sed</code> - Stream editor for modifying text.</li> <li><code>sort</code> - Sort lines of text files.</li> <li><code>uniq</code> - Report or omit repeated lines.</li> <li><code>cut</code> - Remove sections from each line of files.</li> <li><code>wc</code> - Word, line, character count.</li> <li><code>tr</code> - Translate or delete characters.</li> <li><code>nl</code> - Number lines of files.</li> <li><code>grep</code> - Search text.</li> <li><code>awk</code> - Process text with patterns.</li> <li><code>sed</code> - Edit text in streams.</li> </ul> Search for 'error' in syslog<pre><code>grep \"error\" /var/log/syslog\n</code></pre> Print the first column of each line<pre><code>awk '{print $1}' file.txt\n</code></pre> Replace 'old' with 'new'<pre><code>sed 's/old/new/g' file.txt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#logging-and-auditing","title":"Logging and Auditing","text":"<ul> <li><code>dmesg</code> - Print or control kernel ring buffer.</li> <li><code>journalctl</code> - Query the systemd journal.</li> <li><code>logger</code> - Add entries to the system log.</li> <li><code>last</code> - Show listing of last logged-in users.</li> <li><code>history</code> - Show command history.</li> <li><code>tail</code> - View end of file in real time.</li> <li><code>tail -f</code> - Monitor logs in real time.</li> </ul> Follow NGINX access log<pre><code>tail -f /var/log/nginx/access.log\n</code></pre> Logs for NGINX service<pre><code>sudo journalctl -u nginx\n</code></pre>"},{"location":"01_System_Admin_Scripting/#archiving-and-backup","title":"Archiving and Backup","text":"<ul> <li><code>tar</code> - Archive files.</li> <li><code>rsync</code> - Synchronize files and directories.</li> <li><code>tar</code> - Archive files.</li> <li><code>rsync</code> - Sync files and directories.</li> </ul> Create an archive<pre><code>tar -cvf archive.tar /path/to/files \n</code></pre> Extract an archive<pre><code>tar -xvf archive.tar \n</code></pre> Sync with compression and archive mode<pre><code>rsync -avz /source /destination\n</code></pre>"},{"location":"01_System_Admin_Scripting/#shell-scripting","title":"Shell Scripting","text":"<ul> <li><code>echo</code> - Display message or text.</li> <li><code>read</code> - Read input from the user.</li> <li><code>export</code> - Set environment variables.</li> <li><code>alias</code> - Create shortcuts for commands.</li> <li><code>sh</code> - Execute shell scripts.</li> <li><code>sleep</code> - Execute commands from a file in the current shell</li> </ul> Print message<pre><code>echo \"Hello, DevOps!\"\n</code></pre> Add to PATH variable<pre><code>export PATH=$PATH:/new/path\n</code></pre>"},{"location":"01_System_Admin_Scripting/#system-configuration-and-management","title":"System Configuration and Management","text":"<ul> <li><code>crontab</code> - Schedule periodic tasks.</li> <li><code>systemctl</code> - Control the systemd system and service manager.</li> <li><code>service</code> - Start, stop, or restart services.</li> <li><code>timedatectl</code> - Query and change the system clock.</li> <li><code>reboot</code> - Restart the system.</li> <li><code>shutdown</code> - Power off the system.</li> </ul> Edit the crontab file<pre><code>crontab -e\n\n0 2 - - - /path/to/backup.sh\n</code></pre> Restart NGINX<pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"01_System_Admin_Scripting/#containerization-virtualization","title":"Containerization &amp; Virtualization","text":"<ul> <li><code>docker</code> - Manage Docker containers.</li> </ul> List running containers<pre><code>docker ps\n</code></pre> Run NGINX container<pre><code>docker run -d -p 8080:80 nginx\n</code></pre> <ul> <li><code>kubectl</code> - Manage Kubernetes clusters.</li> </ul> List all pods<pre><code>kubectl get pods\n</code></pre> Deploy configuration<pre><code>kubectl apply -f deployment.yaml\n</code></pre>"},{"location":"01_System_Admin_Scripting/#git-version-control","title":"Git Version Control","text":"<ul> <li><code>git status</code> - Show the status of changes.</li> <li><code>git add</code> - Add files to staging.</li> <li><code>git commit</code> - Commit changes.</li> <li><code>git push</code> - Push changes to a remote repository.</li> <li><code>git pull</code> - Pull changes from a remote repository.</li> <li><code>git clone</code> - Clone a repository.</li> <li><code>git remote</code> - Manage set of tracked repositories.</li> </ul> Commit changes with a descriptive message<pre><code>git commit -m \"&lt;message&gt;\"\n</code></pre> Push changes to a remote repository<pre><code>git push &lt;remote&gt; &lt;branch&gt;\n</code></pre> Pull changes from a remote repository<pre><code>git pull &lt;remote&gt; &lt;branch&gt;\n</code></pre> Clone a repository<pre><code>git clone &lt;repository&gt;\n</code></pre> Show URLs of remote repositories<pre><code>git remote -v\n</code></pre> Add a new remote repository<pre><code>git remote add &lt;name&gt; &lt;url&gt;\n</code></pre> Remove a remote repository by name<pre><code>git remote remove &lt;name&gt;\n</code></pre> Rename a remote repository<pre><code>git remote rename &lt;old-name&gt; &lt;new-name&gt;\n</code></pre>"},{"location":"01_System_Admin_Scripting/#network-troubleshooting-and-analysis","title":"Network Troubleshooting and Analysis","text":"<ul> <li><code>traceroute</code> - Track packet route.</li> <li><code>netstat</code> - View network connections, routing tables, and more.</li> <li><code>ss</code> - Display socket statistics (modern alternative to netstat).</li> <li><code>iptables</code> - Manage firewall rules.</li> </ul> Show hops to google.com<pre><code>traceroute google.com\n</code></pre> Show active listening ports with protocol info<pre><code>netstat -tuln\n</code></pre> Show active listening ports<pre><code>ss -tuln\n</code></pre> List current iptables rules<pre><code>sudo iptables -L\n</code></pre>"},{"location":"01_System_Admin_Scripting/#advanced-file-management","title":"Advanced File Management","text":"<ul> <li><code>find</code> - Search files by various criteria.</li> <li><code>locate</code> - Quickly find files by name.</li> </ul> Find all '-.log' files under '/var'<pre><code>find /var -name \"-.log\"\n</code></pre> Find directories named 'test'<pre><code>find /home -type d -name \"test\"\n</code></pre> Locate apache2 configuration file<pre><code>locate apache2.conf\n</code></pre>"},{"location":"01_System_Admin_Scripting/#file-content-and-manipulation","title":"File Content and Manipulation","text":"<ul> <li><code>split</code> - Split files into parts.</li> <li><code>sort</code> - Sort lines in files.</li> <li><code>uniq</code> - Remove duplicates from sorted files</li> </ul> Split file into 500-line chunks<pre><code>split -l 500 largefile.txt smallfile.txt\n</code></pre> Sort lines alphabetically<pre><code>sort files.sort file.txt\n</code></pre> Sort numerically<pre><code>sort -n numbers.txt\n</code></pre> Remove duplicate lines<pre><code>sort file.txt | uniq\n</code></pre>"},{"location":"01_System_Admin_Scripting/#advanced-shell-operations","title":"Advanced Shell Operations","text":"<ul> <li><code>xargs</code> - Build and execute commands from standard input.</li> <li><code>tee</code> - Read from standard input and write to standard output and files.</li> </ul> Delete all .txt files<pre><code>find . -name \"-.txt\" | xargs rm\n</code></pre> Write output to file and terminal<pre><code>echo \"new data\" | tee file.txt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#performance-analysis","title":"Performance Analysis","text":"<ul> <li><code>iostat</code> - Display CPU and I/O statistics.</li> <li><code>vmstat</code> - Report virtual memory stats.</li> <li><code>sar</code> - Collect and report system activity information.</li> </ul> Show disk I/O stats every 2 seconds<pre><code>iostat -d 2\n</code></pre> <p>Display 5 samples at 1-second intervals<pre><code>vmstat 1 5\n</code></pre> Report CPU usage every 5 seconds<pre><code>sar -u 5 5\n</code></pre></p>"},{"location":"01_System_Admin_Scripting/#disk-and-file-system-analysis","title":"Disk and File System Analysis","text":"<ul> <li>lsblk: List block devices.</li> <li>blkid: Display block device attributes.</li> <li>ncdu: Disk usage analyzer with a TUI.</li> </ul> Show filesystems and partitions<pre><code>lsblk -f\n</code></pre> Show UUIDs for devices<pre><code>sudo blkid\n</code></pre> Analyze root directory space usage<pre><code>ncdu /\n</code></pre>"},{"location":"01_System_Admin_Scripting/#file-compression-and-decompression","title":"File Compression and Decompression","text":"<ul> <li><code>gzip</code> - Compress files.</li> <li><code>gunzip</code> - Decompress .gz files.</li> <li><code>bzip2</code> - Compress files with higher compression than gzip.</li> </ul> Compress file with .gz extension<pre><code>gzip largefile.txt\n</code></pre> Decompress file<pre><code>gunzip largefile.txt.gz\n</code></pre> Compress file with .bz2 extension<pre><code>bzip2 largefile.txt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#environment-variables-and-shell-management","title":"Environment Variables and Shell Management","text":"<ul> <li><code>env</code> - Display all environment variables.</li> <li><code>unset</code> - Remove an environment variable.</li> <li><code>set</code> - Set or display shell options and variables.</li> </ul> Display envirnomental variables<pre><code>env\n</code></pre> Show the PATH variable<pre><code>set | grep PATH\n</code></pre> Remove a specific environment variable<pre><code>unset VAR_NAME\n</code></pre>"},{"location":"01_System_Admin_Scripting/#networking-utilities","title":"Networking Utilities","text":"<ul> <li><code>arp</code> - Show or modify the IP-to-MAC address mappings.</li> <li><code>nc (netcat)</code> - Network tool for debugging and investigation.</li> <li><code>nmap</code> - Network scanner to discover hosts and services.</li> </ul> Display all IP-MAC mappings<pre><code>arp -a\n</code></pre> Test if a specific port is open<pre><code>nc -zv example.com 80\n</code></pre> Scan all hosts on a subnet<pre><code>nmap -sP 192.168.1.0/24\n</code></pre>"},{"location":"01_System_Admin_Scripting/#system-security-and-permissions","title":"System Security and Permissions","text":"<ul> <li><code>umask</code> - Set default permissions for new files.</li> <li><code>chmod</code> - Change file or directory permissions.</li> <li><code>chattr</code> - Change file attributes.</li> <li><code>lsattr</code> - List file attributes.</li> </ul> Set default permissions to 755 for new files<pre><code>umask 022\n</code></pre> Owner only read, write, execute<pre><code>chmod 700 file.txt\n</code></pre> Make file immutable<pre><code>sudo chattr +i file.txt\n</code></pre> Show attributes for a file<pre><code>lsattr file.txt\n</code></pre>"},{"location":"01_System_Admin_Scripting/#container-and-kubernetes-management","title":"Container and Kubernetes Management","text":"<ul> <li><code>docker-compose</code> - Manage multi-container Docker applications.</li> <li><code>minikube</code> - Run a local Kubernetes cluster.</li> <li><code>helm</code> - Kubernetes package manager.</li> </ul> Start containers in detached mode<pre><code>docker-compose up -d\n</code></pre> Start minikube cluster<pre><code>minikube start\n</code></pre> Install Helm chart for an app<pre><code>helm install myapp ./myapp-chart\n</code></pre>"},{"location":"01_System_Admin_Scripting/#advanced-git-operations","title":"Advanced Git Operations","text":"<ul> <li><code>git stash</code> - Temporarily save changes.</li> <li><code>git rebase</code> - Reapply commits on top of another base commit.</li> <li><code>git log</code> - View commit history.</li> </ul> Stash current changes<pre><code>git stash\n</code></pre> Rebase current branch onto main<pre><code>git rebase main\n</code></pre> Compact log with graph view<pre><code>git log --oneline --graph\n</code></pre>"},{"location":"01_System_Admin_Scripting/#troubleshooting-and-debugging","title":"Troubleshooting and Debugging","text":"<ul> <li><code>strace</code> - Trace system calls and signals.</li> <li><code>lsof</code> - List open files by processes.</li> <li><code>dmesg</code> - Print kernel ring buffer messages.</li> </ul> Trace process with PID 1234<pre><code>strace -p 1234\n</code></pre> List processes using port 8080<pre><code>lsof -i :8080\n</code></pre> View last 10 kernel messages<pre><code>dmesg | tail -10\n</code></pre>"},{"location":"01_System_Admin_Scripting/#data-manipulation-and-processing","title":"Data Manipulation and Processing","text":"<ul> <li><code>paste</code> - Merge lines of files.</li> <li><code>join</code> - Join lines of two files on a common field.</li> <li><code>column</code> - Format text output into columns.</li> </ul> Combine lines from two files<pre><code>paste file1.txt file2.txt\n</code></pre> Join files on matching lines<pre><code>join file1.txt file2.txt\n</code></pre> Display data in columns<pre><code>cat data.txt | column -t\n</code></pre>"},{"location":"01_System_Admin_Scripting/#file-transfer","title":"File Transfer","text":"<ul> <li><code>rsync</code> - Sync files between local and remote systems.</li> <li><code>scp</code> - Securely copy files between hosts.</li> <li><code>ftp</code> - Transfer files using FTP protocol.</li> </ul> Sync file to remote system<pre><code>rsync -avz /local/dir user@remote:/remote/dir\n</code></pre> Copy to remote<pre><code>scp file.txt user@remote:/path/to/destination\n</code></pre> Connect to FTP server example.com<pre><code>ftp example.com\n</code></pre>"},{"location":"01_System_Admin_Scripting/#job-management-and-scheduling","title":"Job Management and Scheduling","text":"<ul> <li><code>bg</code> - Send a job to the background.</li> <li><code>fg</code> - Bring a background job to the foreground.</li> <li><code>at</code> - Schedule a command to run once at a specified time.</li> </ul> Run a script in the background<pre><code>./script.sh &amp;\n</code></pre> Bring job 1 to the foreground<pre><code>fg %1\n</code></pre> Run in 2 minutes<pre><code>echo \"echo Hello, DevOps\" | at now + 2 minutes\n</code></pre>"},{"location":"01_System_Admin_Scripting/#shell-scripting_1","title":"Shell Scripting","text":""},{"location":"01_System_Admin_Scripting/#01-automating-server-provisioning-aws-ec2-launch","title":"01. Automating Server Provisioning (AWS EC2 Launch)","text":"Provision AWS EC2<pre><code>#!/bin/bash\n\n# Variables\n\nINSTANCE_TYPE=\"t2.micro\"\nAMI_ID=\"ami-0abcdef1234567890\" # Replace with the correct AMI ID\nKEY_NAME=\"my-key-pair\" # Replace with your key pair name\nSECURITY_GROUP=\"sg-0abc1234def567890\" # Replace with your security group ID\nSUBNET_ID=\"subnet-0abc1234def567890\" # Replace with your subnet ID\nREGION=\"us-east-2\" # Replace with your AWS region\n\n# Launch EC2 instance\n\naws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INSTANCE_TYPE \\\n--key-name $KEY_NAME --security-group-ids $SECURITY_GROUP --subnet-id $SUBNET_ID --region $REGION\n\necho \"EC2 instance launched successfully!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#02-system-monitoring-cpu-usage-alert","title":"02. System Monitoring (CPU Usage Alert)","text":"CPU Alert<pre><code>#!/bin/bash\n\n# Threshold for CPU usage\nCPU_THRESHOLD=80\n\n# Get the current CPU usage\nCPU_USAGE=$(top -bn1 | grep \"Cpu(s)\" | sed \"s/.-, -\\([0-9.]-\\)%- id.-/\\1/\" | awk '{print 100 - $1}')\n\n# Check if CPU usage exceeds threshold\nif (( $(echo \"$CPU_USAGE &gt; $CPU_THRESHOLD\" | bc -l) ));\nthen\necho \"Alert: CPU usage is above $CPU_THRESHOLD%. Current usage is $CPU_USAGE%\" | mail -s \"CPU Usage Alert\" user@example.com\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#03-backup-automation-mysql-backup","title":"03. Backup Automation (MySQL Backup)","text":"Backup MySQL<pre><code>#!/bin/bash\n\n# Variables\nDB_USER=\"root\"\nDB_PASSWORD=\"password\"\nDB_NAME=\"my_database\"\nBACKUP_DIR=\"/backup\"\nDATE=$(date +%F)\n\n# Create backup directory if it doesn't exist\nmkdir -p $BACKUP_DIR\n\n# Backup command\nmysqldump -u $DB_USER -p$DB_PASSWORD $DB_NAME &gt; $BACKUP_DIR/backup_$DATE.sql\n\n# Optional: Compress the backup\ngzip $BACKUP_DIR/backup_$DB_NAME_$DATE.sql\n\necho \"Backup completed successfully!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#04-log-rotation-and-cleanup","title":"04. Log Rotation and Cleanup","text":"Rotate Logs<pre><code>#!/bin/bash\n\n# Variables\nLOG_DIR=\"/var/log/myapp\"\nARCHIVE_DIR=\"/var/log/myapp/archive\"\nDAYS_TO_KEEP=30\n\n# Create archive directory if it doesn't exist\nmkdir -p $ARCHIVE_DIR\n\n# Find and compress logs older than 7 days\nfind $LOG_DIR -type f -name \"-.log\" -mtime +7 -exec gzip {} \\; -exec mv {}$ARCHIVE_DIR \\;\n\n# Delete logs older than 30 days\nfind $ARCHIVE_DIR -type f -name \"-.log.gz\" -mtime +$DAYS_TO_KEEP -exec rm {} \\;\necho \"Log rotation and cleanup completed!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#05-cicd-pipeline-automation-trigger-jenkins-job","title":"05. CI/CD Pipeline Automation (Trigger Jenkins Job)","text":"Trigger Jenkins Job<pre><code>#!/bin/bash\n\n# Jenkins details\nJENKINS_URL=\"http://jenkins.example.com\"\nJOB_NAME=\"my-pipeline-job\"\nUSER=\"your-username\"\nAPI_TOKEN=\"your-api-token\"\n\n# Trigger Jenkins job\ncurl -X POST \"$JENKINS_URL/job/$JOB_NAME/build\" --user \"$USER:$API_TOKEN\"\n\necho \"Jenkins job triggered successfully!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#06-deployment-automation-kubernetes-deployment","title":"06. Deployment Automation (Kubernetes Deployment)","text":"Kubernetes Deployment<pre><code>#!/bin/bash\n\n# Variables\nNAMESPACE=\"default\"\nDEPLOYMENT_NAME=\"my-app\"\nIMAGE=\"my-app:v1.0\"\n\n# Deploy to Kubernetes\nkubectl set image deployment/$DEPLOYMENT_NAME\n$DEPLOYMENT_NAME=$IMAGE --namespace=$NAMESPACE\necho \"Deployment updated to version $IMAGE!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#07-infrastructure-as-code-terraform-apply","title":"07. Infrastructure as Code (Terraform Apply)","text":"Terraform Apply<pre><code>#!/bin/bash\n\n# Variables\nTF_DIR=\"/path/to/terraform/config\"\n\n# Navigate to Terraform directory\ncd $TF_DIR\n\n# Run terraform apply\nterraform apply -auto-approve\n\necho \"Terraform apply completed successfully!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#08-database-management-postgresql-schema-migration","title":"08. Database Management (PostgreSQL Schema Migration)","text":"PostgreSQL Schema Migration<pre><code>#!/bin/bash\n\n# Variables\nDB_USER=\"postgres\"\nDB_PASSWORD=\"password\"\nDB_NAME=\"my_database\"\nMIGRATION_FILE=\"/path/to/migration.sql\"\n\n# Run schema migration\nPGPASSWORD=$DB_PASSWORD psql -U $DB_USER -d $DB_NAME -f $MIGRATION_FILE\n\necho \"Database schema migration completed!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#09-user-management-add-user-to-group","title":"09. User Management (Add User to Group)","text":"Add User to Group<pre><code>#!/bin/bash\n\n# Variables\nUSER_NAME=\"newuser\"\nGROUP_NAME=\"devops\"\n\n# Add user to group\nusermod -aG $GROUP_NAME $USER_NAME\necho \"User $USER_NAME added to group $GROUP_NAME!\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#10-security-audits-check-for-open-ports","title":"10. Security Audits (Check for Open Ports)","text":"Check for Open Ports<pre><code>#!/bin/bash\n\n# Check for open ports\n\nOPEN_PORTS=$(netstat -tuln)\n\n# Check if any ports are open (excluding localhost)\n\nif [[ $OPEN_PORTS =~ \"0.0.0.0\" || $OPEN_PORTS =~ \"127.0.0.1\" ]]; then\n\necho \"Security Alert: Open ports detected!\"\n\necho \"$OPEN_PORTS\" | mail -s \"Open Ports Security Alert\" [user@example.com](mailto:user@example.com) else\n\necho \"No open ports detected.\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#11-performance-tuning","title":"11. Performance Tuning","text":"<ul> <li>This script clears memory caches and restarts services to free up system resources.</li> </ul> <pre><code>#!/bin/bash\n\n# Clear memory caches to free up resources**\n\nsync; echo 3 &gt; /proc/sys/vm/drop_caches\n\n# Restart services to free up resources**\n\nsystemctl restart nginx\n\nsystemctl restart apache2\n</code></pre>"},{"location":"01_System_Admin_Scripting/#12-automated-testing","title":"12. Automated Testing","text":"<ul> <li>This script runs automated tests using a testing framework like pytest for Python or JUnit for Java.</li> </ul> <pre><code>#!/bin/bash\n\n# Run unit tests using pytest (Python example)**\n\npytest tests/\n\n# Or, run JUnit tests (Java example)**\n\nmvn test\n</code></pre>"},{"location":"01_System_Admin_Scripting/#13-scaling-infrastructure","title":"13. Scaling Infrastructure","text":"<ul> <li>This script automatically scales EC2 instances in an Auto Scaling group based on CPU usage.</li> </ul> Sacale EC2<pre><code>#!/bin/bash\n\n# Check CPU usage and scale EC2 instances**\n\nCPU_USAGE=$(aws cloudwatch get-metric-statistics --namespace AWS/EC2 --metric-name CPUUtilization --dimensions Name=InstanceId,Value=i-1234567890abcdef0 --statistics Average --period 300 --start-time $(date -d '5 minutes ago' --utc +%FT%TZ) --end-time $(date --utc +%FT%TZ) --query 'Datapoints[0].Average' --output text)\n\nif (( $(echo \"$CPU_USAGE &gt; 80\" | bc -l) )); then\n\naws autoscaling update-auto-scaling-group --auto-scaling-group-name my-auto-scaling-group --desired-capacity 3\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#14-environment-setup","title":"14. Environment Setup","text":"<ul> <li>This script sets environment variables for different environments (development, staging, production).</li> </ul> Set Env variables<pre><code>#!/bin/bash\n\n# Set environment variables for different stages\n\nif [ \"$1\" == \"production\" ]; then\n\nexport DB_HOST=\"prod-db.example.com\"\n\nexport API_KEY=\"prod-api-key\"\n\nelif [ \"$1\" == \"staging\" ]; then\n\nexport DB_HOST=\"staging-db.example.com\"\n\nexport API_KEY=\"staging-api-key\"\n\nelse\n\nexport DB_HOST=\"dev-db.example.com\"\n\nexport API_KEY=\"dev-api-key\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#15-error-handling-and-alerts","title":"15. Error Handling and Alerts","text":"<ul> <li>This script checks logs for errors and sends a Slack notification if an error is found.</li> </ul> Error alerting<pre><code>#!/bin/bash\n\n# Check logs for error messages and send Slack notification\n\nif grep -i \"error\" /var/log/myapp.log; then\n\ncurl -X POST -H 'Content-type: application/json' --data '{\"text\":\"Error found in logs!\"}' https://hooks.slack.com/services/your/webhook/url\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#16-automated-software-installation-and-updates","title":"16. Automated Software Installation and Updates","text":"<ul> <li>This script installs Docker if it's not already installed on the system.</li> </ul> Install Docker<pre><code>#!/bin/bash\n\n#### **# Install Docker**\n\nif ! command -v docker &amp;&gt; /dev/null; then\n\ncurl -fsSL https://get.docker.com -o get-docker.sh\n\nsudo sh get-docker.sh\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#17-configuration-management","title":"17. Configuration Management","text":"<ul> <li>This script updates configuration files (like nginx.conf) across multiple servers.</li> </ul> Update nginx configuration across all servers<pre><code>#!/bin/bash\n\n# Update nginx configuration across all servers\n\nscp nginx.conf user@server:/etc/nginx/nginx.conf\n\nssh user@server \"systemctl restart nginx\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#18-health-check-automation","title":"18. Health Check Automation","text":"<ul> <li>This script checks the health of multiple web servers by making HTTP requests.</li> </ul> Check web servers<pre><code>#!/bin/bash\n\n# Check if web servers are running\n\nfor server in \"server1\" \"server2\" \"server3\"; do\n\ncurl -s --head http://$server | head -n 1 | grep \"HTTP/1.1 200 OK\" &gt; /dev/null\n\nif [ $? -ne 0 ]; then\n\necho \"$server is down\"\n\nelse\n\necho \"$server is up\"\n\ndone\n</code></pre>"},{"location":"01_System_Admin_Scripting/#19-automated-cleanup-of-temporary-files","title":"19. Automated Cleanup of Temporary Files","text":"<ul> <li>This script removes files older than 30 days from the /tmp directory to free up disk space.</li> </ul> Remove files older than x days<pre><code>#!/bin/bash\n\n# Remove files older than 30 days in /tmp\n\nfind /tmp -type f -mtime +30 -exec rm -f {} \\;\n</code></pre>"},{"location":"01_System_Admin_Scripting/#20-environment-variable-management","title":"20. Environment Variable Management","text":"<ul> <li>This script sets environment variables from a .env file.</li> </ul> Set ENV vars from file<pre><code>#!/bin/bash\n\n# Set environment variables from a .env file\n\n\nexport $(grep -v '^#' .env | xargs)\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#21-server-reboot-automation","title":"21. Server Reboot Automation","text":"<ul> <li>This script automatically reboots the server during off-hours (between 2 AM and 4 AM).</li> </ul> Reboot server<pre><code>#!/bin/bash\n\n# Reboot server during off-hours**\n\nif [ $(date +%H) -ge 2 ] &amp;&amp; [ $(date +%H) -lt 4 ]; then\n\nsudo reboot\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#22-ssl-certificate-renewal","title":"22. SSL Certificate Renewal","text":"<ul> <li>This script renews SSL certificates using certbot and reloads the web server.</li> </ul> Renew SSL cert<pre><code>#!/bin/bash\n\n# Renew SSL certificates using certbot**\n\ncertbot renew\n\nsystemctl reload nginx\n</code></pre>"},{"location":"01_System_Admin_Scripting/#23-automatic-scaling-of-containers","title":"23. Automatic Scaling of Containers","text":"<ul> <li>This script checks the CPU usage of a Docker container and scales it based on usage.</li> </ul> Scale Docker Containers<pre><code>#!/bin/bash\n\n# Check CPU usage of a Docker container and scale if necessary\n\nCPU_USAGE=$(docker stats --no-stream --format \"{{.CPUPerc}}\" my-container | sed 's/%//')\n\nif (( $(echo \"$CPU_USAGE &gt; 80\" | bc -l) )); then\n\ndocker-compose scale my-container=3\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#24-backup-verification","title":"24. Backup Verification","text":"<ul> <li>This script verifies the integrity of backup files and reports any corrupted ones.</li> </ul> Verify backup files<pre><code>#!/bin/bash\n\n# Verify backup files integrity\n\nfor backup in /backups/*.tar.gz; do\n\nif ! tar -tzf $backup &gt; /dev/null 2&gt;&amp;1; then\n\necho \"Backup $backup is corrupted\"\n\nelse\n\necho \"Backup $backup is valid\"\n\nfi\n\ndone\n</code></pre>"},{"location":"01_System_Admin_Scripting/#25-automated-server-cleanup","title":"25. Automated Server Cleanup","text":"<ul> <li>This script removes unused Docker images, containers, and volumes to save disk space.</li> </ul> <pre><code>#!/bin/bash\n\n# Remove unused Docker images, containers, and volumes\n\ndocker system prune -af\n</code></pre>"},{"location":"01_System_Admin_Scripting/#26-version-control-operations","title":"26. Version Control Operations","text":"<ul> <li>This script pulls the latest changes from a Git repository and creates a release tag.</li> </ul> <pre><code>#!/bin/bash\n\n# Pull latest changes from Git repository and create a release tag\n\ngit pull origin main\n\ngit tag -a v$(date +%Y%m%d%H%M%S) -m \"Release $(date)\"\n\ngit push origin --tags\n</code></pre>"},{"location":"01_System_Admin_Scripting/#27-application-deployment-rollback","title":"27. Application Deployment Rollback","text":"<ul> <li>This script reverts to the previous Docker container image if a deployment fails. ```bash title=\"\"</li> </ul> Rollback Docker container image<pre><code>#!/bin/bash\n\n# Rollback to the previous Docker container image if deployment fails\n\nif [ $? -ne 0 ]; then docker-compose down\n\ndocker-compose pull my-app:previous\n\ndocker-compose up -d\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#28-automated-log-collection","title":"28. Automated Log Collection","text":"<ul> <li>This script collects logs from multiple servers and uploads them to an S3 bucket.</li> </ul> Collect logs<pre><code>#!/bin/bash\n\n# Collect logs and upload them to an S3 bucket\n\ntar -czf /tmp/logs.tar.gz /var/log/*\n\naws s3 cp /tmp/logs.tar.gz s3://my-log-bucket/logs/$(date +%Y%m%d%H%M%S).tar.gz\n</code></pre>"},{"location":"01_System_Admin_Scripting/#29-security-patch-management","title":"29. Security Patch Management","text":"<ul> <li>This script checks for available security patches and applies them automatically.</li> </ul> Apply patches<pre><code>#!/bin/bash\n\n# Check and apply security patches sudo apt-get update\n\nsudo apt-get upgrade -y --only-upgrade\n</code></pre>"},{"location":"01_System_Admin_Scripting/#30-custom-monitoring-scripts","title":"30. Custom Monitoring Scripts","text":"<ul> <li>This script checks if a database service is running and restarts it if necessary.</li> </ul> Check Database is running<pre><code>#!/bin/bash\n\n# Check if a database service is running and restart it if necessary\n\nif ! systemctl is-active --quiet mysql; then\n\nsystemctl restart mysql\n\necho \"MySQL service was down and has been restarted\"\n\nelse\n\necho \"MySQL service is running\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#31-dns-configuration-automation-route-53","title":"31. DNS Configuration Automation (Route 53)","text":"Update Route53<pre><code>#!/bin/bash\n\n# Variables\n\nZONE_ID=\"your-hosted-zone-id\"\nDOMAIN_NAME=\"your-domain.com\"\nNEW_IP=\"your-new-ip-address\"\n\n# Update Route 53 DNS record\n\naws route53 change-resource-record-sets --hosted-zone-id $ZONE_ID --change-batch '{\n  \"Changes\": [\n    {\n      \"Action\": \"UPSERT\",\n      \"ResourceRecordSet\": {\n        \"Name\": \"'$DOMAIN_NAME'\",\n        \"Type\": \"A\",\n        \"TTL\": 60,\n        \"ResourceRecords\": [\n          {\n            \"Value\": \"'$NEW_IP'\"\n          }\n        ]\n      }\n    }\n  ]\n}'\n</code></pre>"},{"location":"01_System_Admin_Scripting/#32-automated-code-linting-and-formatting-eslint-and-prettier","title":"32. Automated Code Linting and Formatting (ESLint and Prettier)","text":"Run ESLint<pre><code>#!/bin/bash\n\n# Run ESLint\n\nnpx eslint . --fix\n\n# Run Prettier\n\nnpx prettier --write \"**/*.js\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#33-automated-api-testing-using-curl","title":"33. Automated API Testing (Using curl)","text":"<pre><code>#!/bin/bash\n\n# API URL\n\nAPI_URL=\"https://your-api-endpoint.com/endpoint\"\n\n# Make GET request and check for 200 OK response\n\nRESPONSE=$(curl --write-out \"%{http_code}\" --silent --output /dev/null $API_URL)\n\nif [ $RESPONSE -eq 200 ]; then\n\necho \"API is up and running\"\n\nelse\n\necho \"API is down. Response code: $RESPONSE\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#34-container-image-scanning-using-trivy","title":"34. Container Image Scanning (Using Trivy)","text":"Scan Container Image<pre><code>#!/bin/bash\n\n# Image to scan\n\nIMAGE_NAME=\"your-docker-image:latest\"\n\n# Run Trivy scan\n\ntrivy image --exit-code 1 --severity HIGH,CRITICAL $IMAGE_NAME\n\nif [ $? -eq 1 ]; then\n\necho \"Vulnerabilities found in image: $IMAGE_NAME\"\n\nexit 1\n\nelse\n\necho \"No vulnerabilities found in image: $IMAGE_NAME\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#35-disk-usage-monitoring-and-alerts-email-notification","title":"35. Disk Usage Monitoring and Alerts (Email Notification)","text":"Monitor Disk Usage<pre><code>#!/bin/bash\n\n# Disk usage threshold\n\nTHRESHOLD=80\n\n# Get current disk usage percentage\n\nDISK_USAGE=$(df / | grep / | awk '{ print $5 }' | sed 's/%//g')\n\n# Check if disk usage exceeds threshold\n\nif [ $DISK_USAGE -gt $THRESHOLD ]; then\n\necho \"Disk usage is above threshold: $DISK_USAGE%\" | mail -s \"Disk Usage Alert\" [your-email@example.com](mailto:your-email@example.com)\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#36-automated-load-testing-using-apache-benchmark","title":"36. Automated Load Testing (Using Apache Benchmark)","text":"<pre><code>#!/bin/bash\n\n# Target URL\n\nURL=\"https://your-application-url.com\"\n\n# Run Apache Benchmark with 1000 requests and 10 concurrent requests\n\nab -n 1000 -c 10 $URL\n</code></pre>"},{"location":"01_System_Admin_Scripting/#37-automated-email-reports-server-health-report","title":"37. Automated Email Reports (Server Health Report)","text":"<pre><code>#!/bin/bash\n\n# Server Health Report\n\nREPORT=$(top -n 1 | head -n 10)\n\n# Send report via email\n\necho \"$REPORT\" | mail -s \"Server Health Report\" [your-email@example.com](mailto:your-email@example.com)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#38-dns-configuration-automation-route-53","title":"38. DNS Configuration Automation (Route 53)","text":"<ul> <li>Introduction: This script automates the process of updating DNS records in AWS Route 53 when the IP address of a server changes. It ensures that DNS records are updated dynamically when new servers are provisioned.</li> </ul> Update Route53<pre><code>#!/bin/bash\n\n# Variables\nZONE_ID=\"your-hosted-zone-id\"\nDOMAIN_NAME=\"your-domain.com\"\nNEW_IP=\"your-new-ip-address\"\n\n# Update Route 53 DNS record\naws route53 change-resource-record-sets --hosted-zone-id $ZONE_ID--change-batch '{\n  \"Changes\": [\n    {\n      \"Action\": \"UPSERT\",\n      \"ResourceRecordSet\": {\n        \"Name\": \"'$DOMAIN_NAME'\",\n        \"Type\": \"A\",\n        \"TTL\": 60,\n        \"ResourceRecords\": [\n          {\n          \"Value\": \"'$NEW_IP'\"\n          }\n        ]\n      }\n    }\n  ]\n}'\n</code></pre>"},{"location":"01_System_Admin_Scripting/#39-automated-code-linting-and-formatting-eslint-and-prettier","title":"39. Automated Code Linting and Formatting (ESLint and Prettier)","text":"<ul> <li>Introduction: This script runs ESLint and Prettier to check and automatically format JavaScript code before deployment. It ensures code quality and consistency.</li> </ul> Run ESLint<pre><code>#!/bin/bash\n\n# Run ESLint\n\nnpx eslint . --fix\n\n# Run Prettier\n\nnpx prettier --write \"**/*.js\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#40-automated-api-testing-using-curl","title":"40. Automated API Testing (Using curl)","text":"<ul> <li>Introduction: This script automates the process of testing an API by sending HTTP requests and verifying the response status. It helps ensure that the API is functioning correctly.</li> </ul> API Testing<pre><code>#!/bin/bash\n\n# API URL\n\nAPI_URL=\"https://your-api-endpoint.com/endpoint\"\n\n# Make GET request and check for 200 OK response\n\nRESPONSE=$(curl --write-out \"%{http_code}\" --silent --output /dev/null $API_URL)\n\nif [ $RESPONSE -eq 200 ]; then\n\necho \"API is up and running\"\n\nelse\n\necho \"API is down. Response code: $RESPONSE\"\n</code></pre>"},{"location":"01_System_Admin_Scripting/#41-container-image-scanning-using-trivy","title":"41. Container Image Scanning (Using Trivy)","text":"<ul> <li>Introduction: This script scans Docker images for known vulnerabilities using Trivy. It ensures that only secure images are deployed in production.</li> </ul> Container Image Scanning<pre><code>#!/bin/bash\n\n# Image to scan\n\nIMAGE_NAME=\"your-docker-image:latest\"\n\n# Run Trivy scan\n\ntrivy image --exit-code 1 --severity HIGH,CRITICAL $IMAGE_NAME\n\nif [ $? -eq 1 ]; then\n\necho \"Vulnerabilities found in image: $IMAGE_NAME\"\n\nexit 1\n\nelse\n\necho \"No vulnerabilities found in image: $IMAGE_NAME\"\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#42-disk-usage-monitoring-and-alerts-email-notification","title":"42. Disk Usage Monitoring and Alerts (Email Notification)","text":"<ul> <li>Introduction: This script monitors disk usage and sends an alert via email if the disk usage exceeds a specified threshold. It helps in proactive monitoring of disk space.</li> </ul> Disk Usage Monitoring<pre><code>#!/bin/bash\n\n## # Disk usage threshold\n\nTHRESHOLD=80\n\n# Get current disk usage percentage\n\nDISK_USAGE=$(df / | grep / | awk '{ print $5 }' | sed 's/%//g')\n\n# Check if disk usage exceeds threshold\n\nif [ $DISK_USAGE -gt $THRESHOLD ]; then\n\necho \"Disk usage is above threshold: $DISK_USAGE%\" | mail -s \"Disk Usage Alert\" [your-email@example.com](mailto:your-email@example.com)\n\nfi\n</code></pre>"},{"location":"01_System_Admin_Scripting/#43-automated-load-testing-using-apache-benchmark","title":"43. Automated Load Testing (Using Apache Benchmark)","text":"<ul> <li>Introduction: This script runs load tests using Apache Benchmark (ab) to simulate traffic on an application. It helps measure the performance and scalability of the application.</li> </ul> Load testing<pre><code>#!/bin/bash\n\n# Target URL\n\nURL=\"https://your-application-url.com\"\n\n# Run Apache Benchmark with 1000 requests and 10 concurrent requests\n\nab -n 1000 -c 10 $URL\n</code></pre>"},{"location":"01_System_Admin_Scripting/#44-automated-email-reports-server-health-report","title":"44. Automated Email Reports (Server Health Report)","text":"<ul> <li>Introduction: This script generates a server health report using system commands like top and sends it via email. It helps keep track of server performance and health.</li> </ul> Server Health Report<pre><code>#!/bin/bash\n\n# Server Health Report\n\nREPORT=$(top -n 1 | head -n 10)\n\n# Send report via email\n\necho \"$REPORT\" | mail -s \"Server Health Report\" [your-email@example.com](mailto:your-email@example.com)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#45-automating-documentation-generation-using-pdoc-for-python","title":"45. Automating Documentation Generation (Using pdoc for Python)","text":"<ul> <li>Introduction: This script generates HTML documentation from Python code using pdoc. It helps automate the process of creating up-to-date documentation from the source code.</li> </ul> <pre><code>#!/bin/bash\n\n# Generate documentation using pdoc\n\npdoc --html your-python-module --output-dir docs/\n\n# Optionally, you can zip the generated docs\n\nzip -r docs.zip docs/\n</code></pre>"},{"location":"01_System_Admin_Scripting/#46-crontab","title":"46. Crontab","text":"List all cron jobs<pre><code>crontab -l\n</code></pre> Edit cron jobs<pre><code>crontab -e\n</code></pre> Remove all cron jobs<pre><code>crontab -r\n</code></pre> Use a specific editor (e.g., nano)<pre><code>EDITOR=nano crontab -e\n</code></pre> Cron Job Syntax<pre><code>* * * * * command_to_execute\n\u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500 Day of the week (0-6, Sunday=0)\n\u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500 Month (1-12 or JAN-DEC)\n\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Day of the month (1-31)\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Hour (0-23)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Minute (0-59)\n</code></pre> Run a script every minute<pre><code>* * * * * /path/to/script.sh\n</code></pre> Run a script every 5 minutes<pre><code>*/5 * * * * /path/to/script.sh\n</code></pre> Run a script every 10 minutes<pre><code>*/10 * * * * /path/to/script.sh\n</code></pre> Run a script at midnight<pre><code>0 0 * * * /path/to/script.sh\n</code></pre> Run a script every hour<pre><code>0 * * * * /path/to/script.sh\n</code></pre> Run a script every 2 hours<pre><code>0 */2 * * * /path/to/script.sh\n</code></pre> Run a script every Sunday at 3 AM<pre><code>0 3 * * 0 /path/to/script.sh\n</code></pre> Run a script at 9 AM on the 1st of every month<pre><code>0 9 1 * * /path/to/script.sh\n</code></pre> Run a script every Monday to Friday at 6 PM<pre><code>0 18 * * 1-5 /path/to/script.sh\n</code></pre> Run a script on the first Monday of every month<pre><code>0 9 * * 1 [ \"$(date +\\%d)\" -le 7 ] &amp;&amp; /path/to/script.sh\n</code></pre> Run a script on specific dates (e.g., 1st and 15th of the month)<pre><code>0 12 1,15 * * /path/to/script.sh\n</code></pre> Run a script between 9 AM and 5 PM, every hour<pre><code>0 9-17 * * * /path/to/script.sh\n</code></pre> Run a script every reboot<pre><code>@reboot /path/to/script.sh\n</code></pre> Run a script daily at midnight<pre><code>@daily /path/to/script.sh\n</code></pre> Run a script weekly at midnight on Sunday<pre><code>@weekly /path/to/script.sh\n</code></pre> Run a script monthly at midnight on the 1st<pre><code>@monthly /path/to/script.sh\n</code></pre> Run a script yearly at midnight on January 1st<pre><code>@yearly /path/to/script.sh\n</code></pre> Redirect cron job output to a log file<pre><code>0 0 * * * /path/to/script.sh &gt;&gt; /var/log/script.log 2&gt;&amp;1\n</code></pre> Run a job only if the previous instance is not running<pre><code>0 * * * * flock -n /tmp/job.lock /path/to/script.sh\n</code></pre> Run a script with a random delay (0-59 minutes)<pre><code>RANDOM_DELAY=$((RANDOM % 60)) &amp;&amp; sleep $RANDOM_DELAY &amp;&amp; /path/to/script.sh\n</code></pre> Run a script with environment variables<pre><code>SHELL=/bin/bash\n\nPATH=/usr/local/bin:/usr/bin:/bin\n\n0 5 * * * /path/to/script.sh\n</code></pre> Check cron logs (Ubuntu/Debian)<pre><code>grep CRON /var/log/syslog\n</code></pre> Check cron logs (Red Hat/CentOS)<pre><code>grep CRON /var/log/cron\n</code></pre> Restart cron service (Linux)<pre><code>sudo systemctl restart cron\n</code></pre> Check if cron service is running<pre><code>sudo systemctl status cron\n</code></pre>"},{"location":"01_System_Admin_Scripting/#python","title":"Python","text":""},{"location":"01_System_Admin_Scripting/#python-basics","title":"Python Basics","text":"<ul> <li>Run a script: <code>python script.py</code></li> <li>Start interactive mode: <code>python</code></li> <li>Check Python version: <code>python --version</code></li> <li>Install a package: <code>pip install package_name</code></li> </ul>"},{"location":"01_System_Admin_Scripting/#create-a-virtual-environment","title":"Create a virtual environment:","text":"On Linux/macOS<pre><code>python -m venv venv source venv/bin/activate\n</code></pre> On Windows<pre><code>venv\\Scripts\\activate\n</code></pre> Deactivate virtual environment<pre><code>deactivate\n</code></pre>"},{"location":"01_System_Admin_Scripting/#1-file-operations","title":"1. File Operations","text":"Read a file:<pre><code>python\n\nwith open('file.txt', 'r') as file: content = file.read() print(content)\n</code></pre> Write to a file:<pre><code>python\n\nwith open('output.txt', 'w') as file: file.write('Hello, DevOps!')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#2-environment-variables","title":"2. Environment Variables","text":"Get an environment variable:<pre><code>python\n\nimport os\n\ndb_user = os.getenv('DB_USER') print(db_user)\n</code></pre> Set an environment variable:<pre><code>python\n\nimport os\n\nos.environ['NEW_VAR'] = 'value'\n</code></pre>"},{"location":"01_System_Admin_Scripting/#3-subprocess-management","title":"3. Subprocess Management","text":"Run shell commands:<pre><code>python\n\nimport subprocess\n\nresult = subprocess.run(['ls', '-l'], capture_output=True, text=True) print(result.stdout)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#4-api-requests","title":"4. API Requests","text":"Make a GET request:<pre><code>python\n\nimport requests\n\nresponse = requests.get('https://api.example.com/data') print(response.json())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#5-json-handling","title":"5. JSON Handling","text":"Read JSON from a file:<pre><code>python\n\nimport json\n\nwith open('data.json', 'r') as file: data = json.load(file) print(data)\n</code></pre> Write JSON to a file:<pre><code>python\n\nimport json\n\ndata = {'name': 'DevOps', 'type': 'Workflow'} with open('output.json', 'w') as file: json.dump(data, file, indent=4)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#6-logging","title":"6. Logging","text":"Basic logging setup:<pre><code>python\n\nimport logging\n\nlogging.basicConfig(level=logging.INFO) logging.info('This is an informational message')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#7-working-with-databases","title":"7. Working with Databases","text":"Connect to a SQLite database:<pre><code>python\n\nimportsqlite3\n\nconn = sqlite3.connect('example.db') \ncursor = conn.cursor()\ncursor.execute('CREATE TABLE IF NOT EXISTS users (id INTEGER \nPRIMARY KEY, name TEXT)')\nconn.commit() \nconn.close()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#8-automation-with-libraries","title":"8. Automation with Libraries","text":"Using Paramiko for SSH connections:<pre><code>python\n\nimport paramiko\n\nssh = paramiko.SSHClient() \nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) \nssh.connect('hostname', username='user', password='password')\n\nstdin, stdout, stderr = ssh.exec_command('ls') \nprint(stdout.read().decode())\nssh.close()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#9-error-handling","title":"9. Error Handling","text":"Try-except block:<pre><code>python\n\ntry: # code that may raise an exception risky_code() except Exception as e: print(f'Error occurred: {e}')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#10-docker-integration","title":"10. Docker Integration","text":"Using the docker package to interact with Docker:<pre><code>import docker\n\nclient = docker.from_env() containers = client.containers.list() for container in containers: print(container.name)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#11-working-with-yaml-files","title":"11. Working with YAML Files","text":"Read a YAML file:<pre><code>import yaml\n\n- with open('config.yaml', 'r') as file: config = yaml.safe_load(file) print(config)\n</code></pre> Write to a YAML file:<pre><code>import yaml\n\ndata = {'name': 'DevOps', 'version': '1.0'} with open('output.yaml', 'w') as file: yaml.dump(data, file)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#12-parsing-command-line-arguments","title":"12. Parsing Command-Line Arguments","text":"Using argparse:<pre><code>import argparse\n\nparser = argparse.ArgumentParser(description='Process some integers.') parser.add_argument('--num', type=int, help='an integer for the accumulator')\n\nargs = parser.parse_args() \nprint(args.num)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#13-monitoring-system-resources","title":"13. Monitoring System Resources","text":"Using psutil to monitor system resources:<pre><code>import psutil\n\nprint(f\"CPU Usage: {psutil.cpu_percent()}%\") \nprint(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n</code></pre>"},{"location":"01_System_Admin_Scripting/#14-handling-http-requests-with-flask","title":"14. Handling HTTP Requests with Flask","text":"Basic Flask API:<pre><code>from flask import Flask, jsonify\n\napp = Flask( name )\n\n@app.route('/health', methods=['GET']) def health_check(): return jsonify({'status': 'healthy'})\n\nif name == ' main ': app.run(host='0.0.0.0', port=5000)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#15-creating-docker-containers","title":"15. Creating Docker Containers","text":"Using the Docker SDK to create a container:<pre><code>import docker\n\nclient = docker.from_env()\ncontainer = client.containers.run('ubuntu', 'echo Hello World', detach=True) \nprint(container.logs())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#16-scheduling-tasks","title":"16. Scheduling Tasks","text":"Using schedule for task scheduling:<pre><code>importschedule import time\n\ndef job(): print(\"Running scheduled job...\")\n\nschedule.every(1).minutes.do(job)\n\nwhile True: schedule.run_pending() time.sleep(1)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#17-version-control-with-git","title":"17. Version Control with Git","text":"Using GitPython to interact with Git repositories:<pre><code>import git\n\nrepo = git.Repo('/path/to/repo') \nrepo.git.add('file.txt') \nrepo.index.commit('Added file.txt')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#18-email-notifications","title":"18. Email Notifications","text":"Sending emails using smtplib:<pre><code>import smtplib from email.mime.text import MIMEText\n\nmsg = MIMEText('This is the body of the email') \nmsg['Subject'] = 'Email Subject'\nmsg['From'] = 'you@example.com'\nmsg['To'] = 'recipient@example.com'\n\nwith smtplib.SMTP('smtp.example.com', 587) as server: server.starttls() server.login('your_username', 'your_password') server.send_message(msg)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#19-creating-virtual-environments","title":"19. Creating Virtual Environments","text":"Creating and activating a virtual environment:<pre><code>import os import subprocess # Create virtual environment\nsubprocess.run(['python3', '-m', 'venv', 'myenv'])\n\n# Activate virtual environment (Windows)\nos.system('myenv\\\\Scripts\\\\activate')\n\n# Activate virtual environment (Linux/Mac)\nos.system('source myenv/bin/activate')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#20-integrating-with-cicd-tools","title":"20. Integrating with CI/CD Tools","text":"Using the requests library to trigger a Jenkins job:<pre><code>import requests\n\nurl = ['http://your-jenkins-url/job/your-job-name/build'](http://your-jenkins-url/job/your-job-name/build%27) response = requests.post(url, auth=('user', 'token')) print(response.status_code)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#21-database-migration","title":"21. Database Migration","text":"Using Alembic for database migrations:<pre><code>alembic revision -m \"initial migration\" alembic upgrade head\n</code></pre>"},{"location":"01_System_Admin_Scripting/#22-testing-code","title":"22. Testing Code","text":"Using unittest for unit testing:<pre><code>import unittest\n\ndef add(a, b): \n  return a + b\nclass TestMathFunctions(unittest.TestCase): \n  def test_add(self):\n     self.assertEqual(add(2, 3), 5)\nif name == ' main ': \n  unittest.main()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#23-data-transformation-with-pandas","title":"23. Data Transformation with Pandas","text":"Using pandas for data manipulation:<pre><code>import pandas as pd\n\ndf = pd.read_csv('data.csv') df['new_column'] = df['existing_column'] \\* 2 df.to_csv('output.csv', index=False)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#24-using-python-for-infrastructure-as-code","title":"24. Using Python for Infrastructure as Code","text":"Using boto3 for AWS operations:<pre><code>import boto3\n\nec2 = boto3.resource('ec2')\ninstances = ec2.instances.filter(Filters=[{'Name': 'instance-state-name', \n'Values': ['running']}])\nfor instance in instances: \n  print(instance.id, instance.state)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#25-web-scraping","title":"25. Web Scraping","text":"Using BeautifulSoup to scrape web pages:<pre><code>import requests\nfrom bs4 import BeautifulSoup\n\nresponse = requests.get('http://example.com')\nsoup = BeautifulSoup(response.content, 'html.parser')\nprint(soup.title.string)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#26-using-fabric-for-remote-execution","title":"26. Using Fabric for Remote Execution","text":"Running commands on a remote server:<pre><code>from fabric import Connection\n\nconn = Connection(host='user@hostname', connect_kwargs={'password': \n'your_password'})\nconn.run('uname -s')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#27-automating-aws-s3-operations","title":"27. Automating AWS S3 Operations","text":"Upload and download files using boto3:<pre><code>import boto3\n\ns3 = boto3.client('s3')\n\n# Upload a file\ns3.upload_file('local_file.txt', 'bucket_name', 's3_file.txt')\n\n# Download a file\ns3.download_file('bucket_name', 's3_file.txt', 'local_file.txt')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#28-monitoring-application-logs","title":"28. Monitoring Application Logs","text":"Tail logs using tail -f equivalent in Python:<pre><code>import time\n\ndef tail_f(file):\n  file.seek(0, 2) # Move to the end of the file\n  while True:\n    line = file.readline()\n    if not line:\n      time.sleep(0.1) # Sleep briefly\n      continue\n    print(line)\n\nwith open('app.log', 'r') as log_file:\n  tail_f(log_file)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#29-container-health-checks","title":"29. Container Health Checks","text":"Check the health of a running Docker container:<pre><code>import docker\n\nclient = docker.from_env()\ncontainer = client.containers.get('container_id') \nprint(container.attrs['State']['Health']['Status'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#30-using-requests-for-rate-limited-apis","title":"30. Using requests for Rate-Limited APIs","text":"Handle rate limiting in API requests:<pre><code>import requests\nimport time\nurl = 'https://api.example.com/data'\nwhile True:\n  response = requests.get(url)\n  if response.status_code == 200:\n    print(response.json())\n    break\n  elif response.status_code == 429: # Too Many Requests\n    time.sleep(60) # Wait a minute before retrying\n  else:\n    print('Error:', response.status_code)\n    break\n</code></pre>"},{"location":"01_System_Admin_Scripting/#31-docker-compose-integration","title":"31. Docker Compose Integration","text":"Using docker-compose in Python:<pre><code>import os\nimport subprocess\n\n# Start services defined in docker-compose.yml\nsubprocess.run(['docker-compose', 'up', '-d'])\n\n# Stop services\nsubprocess.run(['docker-compose', 'down'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#32-terraform-execution","title":"32. Terraform Execution","text":"Executing Terraform commands with subprocess:<pre><code>import subprocess\n\n# Initialize Terraform\nsubprocess.run(['terraform', 'init'])\n\n# Apply configuration\nsubprocess.run(['terraform', 'apply', '-auto-approve'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#33-working-with-prometheus-metrics","title":"33. Working with Prometheus Metrics","text":"Scraping and parsing Prometheus metrics:<pre><code>import requests\n\nresponse = requests.get('http://localhost:9090/metrics')\nmetrics = response.text.splitlines()\n\nfor metric in metrics:\n  print(metric)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#34-using-pytest-for-testing","title":"34. Using pytest for Testing","text":"Simple test case with pytest:<pre><code>def add(a, b):\n  return a + b\n\ndef test_add():\n  assert add(2, 3) == 5\n</code></pre>"},{"location":"01_System_Admin_Scripting/#35-creating-webhooks","title":"35. Creating Webhooks","text":"Using Flask to create a simple webhook:<pre><code>from flask import Flask, request\n\napp = Flask( name )\n\n@app.route('/webhook', methods=['POST'])\ndef webhook():\n  data = request.json\n  print('Received data:', data)\n  return 'OK', 200\n\nif name == ' main ':\n  app.run(port=5000)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#36-using-jinja2-for-configuration-templates","title":"36. Using Jinja2 for Configuration Templates","text":"Render configuration files with Jinja2:<pre><code>from jinja2 import Template\n\ntemplate = Template('Hello, {{ name }}!')\nrendered = template.render(name='DevOps')\nprint(rendered)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#37-encrypting-and-decrypting-data","title":"37. Encrypting and Decrypting Data","text":"Using cryptography to encrypt and decrypt:<pre><code>from cryptography.fernet import Fernet\n\n# Generate a key\nkey = Fernet.generate_key() \ncipher_suite = Fernet(key)\n\n# Encrypt\nencrypted_text = cipher_suite.encrypt(b'Secret Data')\n\n# Decrypt\ndecrypted_text = cipher_suite.decrypt(encrypted_text) \nprint(decrypted_text.decode())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#38-error-monitoring-with-sentry","title":"38. Error Monitoring with Sentry","text":"Sending error reports to Sentry:<pre><code>import sentry_sdk\n\nsentry_sdk.init('your_sentry_dsn')\n\ndef divide(a, b):\n  return a / b\n\ntry:\n  divide(1, 0)\nexcept ZeroDivisionError as e: \n  sentry_sdk.capture_exception(e)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#39-setting-up-continuous-integration-with-github-actions","title":"39. Setting Up Continuous Integration with GitHub Actions","text":"Sample workflow file (.github/workflows/ci.yml):<pre><code>name: CI\n\non: [push]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.8'\n      - name: Install dependencies\n        run: | \n          pip install -r requirements.txt\n      - name: Run tests\n        run: |\n          pytest\n</code></pre>"},{"location":"01_System_Admin_Scripting/#40-creating-a-simple-api-with-fastapi","title":"40. Creating a Simple API with FastAPI","text":"Using FastAPI for high-performance APIs:<pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get('/items/{item_id}')\nasync def read_item(item_id: int):\n  return {'item_id': item_id}\n\nif name == ' main ':\n  import uvicorn\n  uvicorn.run(app, host='0.0.0.0', port=8000)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#41-log-aggregation-with-elk-stack","title":"41. Log Aggregation with ELK Stack","text":"Sending logs to Elasticsearch:<pre><code>from elasticsearch import Elasticsearch\n\nes = Elasticsearch([\\['http://localhost:9200'\\]](http://localhost:9200/))\n\nlog = {'level': 'info', 'message': 'This is a log message'}\nes.index(index='logs', body=log)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#42-using-pandas-for-etl-processes","title":"42. Using pandas for ETL Processes","text":"Performing ETL with pandas:<pre><code>import pandas as pd\n\n# Extract\ndata = pd.read_csv('source.csv')\n\n# Transform\ndata['new_column'] = data['existing_column'].apply(lambda x: x \\* 2)\n\n# Load\ndata.to_csv('destination.csv', index=False)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#43-serverless-applications-with-aws-lambda","title":"43. Serverless Applications with AWS Lambda","text":"Deploying a simple AWS Lambda function:<pre><code>import json\ndef lambda_handler(event, context): \n  return {\n     'statusCode': 200,\n     'body': json.dumps('Hello from Lambda!')\n  }\n</code></pre>"},{"location":"01_System_Admin_Scripting/#44-working-with-redis","title":"44. Working with Redis","text":"Basic operations with Redis using redis-py:<pre><code>import redis\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n# Set a key\nr.set('foo', 'bar')\n\n# Get a key\nprint(r.get('foo'))\n</code></pre>"},{"location":"01_System_Admin_Scripting/#45-using-pyngrok-for-tunneling","title":"45. Using pyngrok for Tunneling","text":"Create a tunnel to expose a local server:<pre><code>from pyngrok import ngrok\n\n# Start the tunnel\npublic_url = ngrok.connect(5000)\nprint('Public URL:', public_url)\n\n# Keep the tunnel open\ninput('Press Enter to exit...')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#46-creating-a-rest-api-with-flask-restful","title":"46. Creating a REST API with Flask-RESTful","text":"Building REST APIs with Flask-RESTful:<pre><code>from flask import Flask\nfrom flask_restful import Resource, Api\n\napp = Flask( name ) \napi = Api(app)\n\nclass HelloWorld(Resource): \n  def get(self):\n     return {'hello': 'world'}\n\napi.add_resource(HelloWorld, '/')\n\nif name == ' main ': \n  app.run(debug=True)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#47-using-asyncio-for-asynchronous-tasks","title":"47. Using asyncio for Asynchronous Tasks","text":"Running asynchronous tasks in Python:<pre><code>import asyncio\n\nasync def main():\n  print('Hello')\n  await asyncio.sleep(1) \n  print('World')\n\nasyncio.run(main())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#48-network-monitoring-with-scapy","title":"48. Network Monitoring with scapy","text":"Packet sniffing using scapy:<pre><code>from scapy.all import sniff\n\ndef packet_callback(packet):\n  print(packet.summary())\n\nsniff(prn=packet_callback, count=10)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#49-handling-configuration-files-with-configparser","title":"49. Handling Configuration Files with configparser","text":"Reading and writing to INI configuration files:<pre><code>import configparser\n\nconfig = configparser.ConfigParser() \nconfig.read('config.ini')\nprint(config['DEFAULT']['SomeSetting'])\n\nconfig['DEFAULT']['NewSetting'] = 'Value' \nwith open('config.ini', 'w') as configfile:\n  config.write(configfile)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#50-websocket-client-example","title":"50. WebSocket Client Example","text":"Creating a WebSocket client with websocket-client:<pre><code>import websocket\n\ndef on_message(ws, message): \n  print(\"Received message:\", message)\n\nws = websocket.WebSocketApp(\"ws://echo.websocket.org\", \n                on_message=on_message)\nws.run_forever()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#51-creating-a-docker-image-with-python","title":"51. Creating a Docker Image with Python","text":"Using docker library to build an image:<pre><code>import docker\n\nclient = docker.from_env()\n\n# Dockerfile content\ndockerfile_content = \"\"\"\nFROM python:3.9-slim\nWORKDIR /app\nCOPY . /app\nRUN pip install -r requirements.txt\nCMD [\"python\", \"app.py\"]\n\"\"\"\n\n# Create a Docker image\nimage, build_logs =\nclient.images.build(fileobj=dockerfile_content.encode('utf-8'), tag='my-python-app')\n\nfor line in build_logs:\n  print(line)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#52-using-psutil-for-system-monitoring","title":"52. Using psutil for System Monitoring","text":"Retrieve system metrics such as CPU and memory usage:<pre><code>import psutil\n\nprint(\"CPU Usage:\", psutil.cpu_percent(interval=1), \"%\")\nprint(\"Memory Usage:\", psutil.virtual_memory().percent, \"%\")\n</code></pre>"},{"location":"01_System_Admin_Scripting/#53-database-migration-with-alembic","title":"53. Database Migration with Alembic","text":"Script to initialize Alembic migrations:<pre><code>from alembic import command\nfrom alembic import config\n\nalembic_cfg = config.Config(\"alembic.ini\") \ncommand.upgrade(alembic_cfg, \"head\")\n</code></pre>"},{"location":"01_System_Admin_Scripting/#54-using-paramiko-for-ssh-connections","title":"54. Using paramiko for SSH Connections","text":"Execute commands on a remote server via SSH:<pre><code>import paramiko\n\nclient = paramiko.SSHClient() \nclient.set_missing_host_key_policy(paramiko.AutoAddPolicy()) \nclient.connect('hostname', username='user', password='your_password')\n\nstdin, stdout, stderr = client.exec_command('ls -la') \nprint(stdout.read().decode())\nclient.close()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#55-cloudformation-stack-creation-with-boto3","title":"55. CloudFormation Stack Creation with boto3","text":"Creating an AWS CloudFormation stack:<pre><code>import boto3\n\ncloudformation = boto3.client('cloudformation')\n\nwith open('template.yaml', 'r') as template_file: \n  template_body = template_file.read()\n\nresponse = cloudformation.create_stack( \n  StackName='MyStack', \n  TemplateBody=template_body, \n  Parameters=[\n    {\n       'ParameterKey': 'InstanceType', \n       'ParameterValue': 't2.micro'\n    },\n  ],\n  TimeoutInMinutes=5, \n  Capabilities=['CAPABILITY_NAMED_IAM'],\n)\nprint(response)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#56-automating-ec2-instance-management","title":"56. Automating EC2 Instance Management","text":"Starting and stopping EC2 instances:<pre><code>import boto3\n\nec2 = boto3.resource('ec2')\n\n# Start an instance\ninstance = ec2.Instance('instance_id')\ninstance.start()\n\n# Stop an instance\ninstance.stop()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#57-automated-backup-with-shutil","title":"57. Automated Backup with shutil","text":"Backup files to a specific directory:<pre><code>import shutil\nimport os\n\nsource_dir = '/path/to/source'\nbackup_dir = '/path/to/backup'\n\nshutil.copytree(source_dir, backup_dir)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#58-using-watchdog-for-file-system-monitoring","title":"58. Using watchdog for File System Monitoring","text":"Monitor changes in a directory:<pre><code>from watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass MyHandler(FileSystemEventHandler): \n  def on_modified(self, event):\n     print(f'File modified: {event.src_path}')\n\nevent_handler = MyHandler() \nobserver = Observer()\nobserver.schedule(event_handler, path='path/to/monitor', recursive=False) \nobserver.start()\n\ntry:\n  while True: \n    time.sleep(1)\nexcept KeyboardInterrupt: \n  observer.stop()\nobserver.join()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#59-load-testing-with-locust","title":"59. Load Testing with locust","text":"Basic Locust load testing setup:<pre><code>from locust import HttpUser, task, between\n\nclass MyUser(HttpUser):\n  wait_time = between(1, 3)\n\n  @task\n  def load_test(self): \n    self.client.get('/')\n</code></pre> <p>To run, save this as locustfile.py and run: locust</p>"},{"location":"01_System_Admin_Scripting/#60-integrating-with-github-api","title":"60. Integrating with GitHub API","text":"Fetching repository details using GitHub API:<pre><code>import requests\n\nurl = 'https://api.github.com/repos/user/repo'\nresponse = requests.get(url, headers={'Authorization': 'token YOUR_GITHUB_TOKEN'})\nrepo_info = response.json()\nprint(repo_info)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#61-managing-kubernetes-resources-with-kubectl","title":"61. Managing Kubernetes Resources with kubectl","text":"Using subprocess to interact with Kubernetes:<pre><code>importsubprocess\n\n# Get pods\nsubprocess.run(['kubectl', 'get', 'pods'])\n\n# Apply a configuration\nsubprocess.run(['kubectl', 'apply', '-f', 'deployment.yaml'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#62-using-pytest-for-cicd-testing","title":"62. Using pytest for CI/CD Testing","text":"Integrate tests in your CI/CD pipeline:<pre><code># test_example.py\ndef test_addition():\n  assert 1 + 1 == 2\n\n# Run pytest in your CI/CD pipeline\nsubprocess.run(['pytest'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#63-creating-a-simple-cli-tool-with-argparse","title":"63. Creating a Simple CLI Tool with argparse","text":"Build a command-line interface:<pre><code>import argparse\n\nparser = argparse.ArgumentParser(description='Process some integers.') \nparser.add_argument('integers', metavar='N', type=int, nargs='+', help='an \ninteger to be processed')\nparser.add_argument('--sum', dest='accumulate', action='store_const', \nconst=sum, default=max, help='sum the integers (default: find the max)')\n\nargs = parser.parse_args() \nprint(args.accumulate(args.integers))\n</code></pre>"},{"location":"01_System_Admin_Scripting/#64-using-dotenv-for-environment-variables","title":"64. Using dotenv for Environment Variables","text":"Load environment variables from a .env file:<pre><code>from dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\ndatabase_url = os.getenv('DATABASE_URL') \nprint(database_url)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#65-implementing-web-scraping-with-beautifulsoup","title":"65. Implementing Web Scraping with BeautifulSoup","text":"Scraping a web page for data:<pre><code>import requests\nfrom bs4 import BeautifulSoup\n\nresponse = requests.get('http://example.com')\nsoup = BeautifulSoup(response.text, 'html.parser')\n\nfor item in soup.find_all('h1'):\n  print(item.text)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#66-using-pyyaml-for-yaml-configuration-files","title":"66. Using PyYAML for YAML Configuration Files","text":"Load and dump YAML files:<pre><code>import yaml\n\n# Load YAML file\nwith open('config.yaml', 'r') as file:\n  config = yaml.safe_load(file)\n  print(config)\n\n# Dump to YAML file\nwith open('output.yaml', 'w') as file:\n  yaml.dump(config, file)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#67-creating-a-simple-message-queue-with-rabbitmq","title":"67. Creating a Simple Message Queue with RabbitMQ","text":"Send and receive messages using pika:<pre><code>import pika\n\n# Sending messages \nconnection =\npika.BlockingConnection(pika.ConnectionParameters('localhost')) \nchannel = connection.channel() \nchannel.queue_declare(queue='hello')\n\nchannel.basic_publish(exchange='', routing_key='hello', body='Hello World!')\nconnection.close()\n\n# Receiving messages\ndef callback(ch, method, properties, body): \n  print(\"Received:\", body)\n\nconnection = \npika.BlockingConnection(pika.ConnectionParameters('localhost')) \nchannel = connection.channel() \nchannel.queue_declare(queue='hello')\n\nchannel.basic_consume(queue='hello', on_message_callback=callback, \nauto_ack=True)\nchannel.start_consuming()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#68-using-sentry_sdk-for-monitoring","title":"68. Using sentry_sdk for Monitoring","text":"Integrate Sentry for error tracking:<pre><code>import sentry_sdk\n\nsentry_sdk.init(\"YOUR_SENTRY_DSN\")\n\ntry:\n  # Your code that may throw an exception\n  1 / 0\nexcept Exception as e:\n  sentry_sdk.capture_exception(e)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#69-using-openpyxl-for-excel-file-manipulation","title":"69. Using openpyxl for Excel File Manipulation","text":"Read and write Excel files:<pre><code>from openpyxl import Workbook, load_workbook\n\n# Create a new workbook\nwb = Workbook()\nws = wb.active\nws['A1'] = 'Hello'\nwb.save('sample.xlsx')\n\n# Load an existing workbook\nwb = load_workbook('sample.xlsx')\nws = wb.active\nprint(ws['A1'].value)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#70-using-sqlalchemy-for-database-interaction","title":"70. Using sqlalchemy for Database Interaction","text":"Define a model and perform CRUD operations:<pre><code>from sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm importsessionmaker\n\nBase = declarative_base()\n\nclass User(Base):\n  __tablename__= 'users'\n\n  id = Column(Integer, primary_key=True) \n  name = Column(String)\n\nengine = create_engine('sqlite:///example.db')\nBase.metadata.create_all(engine)\n\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n# Create\nnew_user = User(name='Alice')\nsession.add(new_user)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#71-monitoring-docker-containers-with-docker-py","title":"71. Monitoring Docker Containers with docker-py","text":"Fetch and print the status of running containers:<pre><code>import docker\n\nclient = docker.from_env()\ncontainers = client.containers.list()\n\nfor container in containers:\n  print(f'Container Name: {container.name}, Status: {container.status}')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#72-using-flask-to-create-a-simple-api","title":"72. Using flask to Create a Simple API","text":"Basic API setup with Flask:<pre><code>from flask import Flask, jsonify\n\napp = Flask( name )\n\n@app.route('/api/data', methods=['GET'])\n\ndef get_data():\n  return jsonify({\"message\": \"Hello, World!\"})\n\nif __name__ == '__main__':\n  app.run(debug=True)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#73-automating-certificate-renewal-with-certbot","title":"73. Automating Certificate Renewal with certbot","text":"Script to renew Let's Encrypt certificates:<pre><code>import subprocess\n\n# Renew certificates\nsubprocess.run(['certbot', 'renew'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#74-using-numpy-for-data-analysis","title":"74. Using numpy for Data Analysis","text":"Performing basic numerical operations:<pre><code>import numpy as np\n\ndata = np.array([1, 2, 3, 4, 5])\nmean_value = np.mean(data)\nprint(\"Mean Value:\", mean_value)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#75-creating-and-sending-emails-with-smtplib","title":"75. Creating and Sending Emails with smtplib","text":"Send an email using Python:<pre><code>import smtplib\nfrom email.mime.text import MIMEText\n\nsender = 'you@example.com'\nrecipient = 'recipient@example.com'\nmsg = MIMEText('This is a test email.') \nmsg['Subject'] = 'Test Email' \nmsg['From'] = sender\nmsg['To'] = recipient\n\nwith smtplib.SMTP('smtp.example.com') as server:\n  server.login('username', 'password')\n  server.send_message(msg)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#76-using-schedule-for-task-scheduling","title":"76. Using schedule for Task Scheduling","text":"Schedule tasks at regular intervals:<pre><code>importschedule import time\n\ndef job():\n  print(\"Job is running...\")\n\nschedule.every(10).minutes.do(job)\n\nwhile True:\n  schedule.run_pending()\n  time.sleep(1)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#77-using-matplotlib-for-data-visualization","title":"77. Using matplotlib for Data Visualization","text":"Plotting a simple graph:<pre><code>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [2, 3, 5, 7, 11]\n\nplt.plot(x, y)\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Simple Plot')\nplt.show()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#78-creating-a-custom-python-package","title":"78. Creating a Custom Python Package","text":"Structure your project as a package:<pre><code>my_package/\n \u251c\u2500\u2500 init .py\n \u251c\u2500\u2500 module1.py\n \u2514\u2500\u2500 module2.py\n</code></pre> setup.py for packaging:<pre><code>from setuptools import setup, find_packages\n\n\nsetup(\n  name='my_package', \n  version='0.1', \n  packages=find_packages(), \n  install_requires=[\n     'requests', \n     'flask'\n  ],\n)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#79-using-pytest-for-unit-testing","title":"79. Using pytest for Unit Testing","text":"Writing a simple unit test:<pre><code># test_sample.py\ndef add(a, b):\n  return a + b\n\ndef test_add():\n  assert add(1, 2) == 3\n</code></pre>"},{"location":"01_System_Admin_Scripting/#80-implementing-oauth-with-requests-oauthlib","title":"80. Implementing OAuth with requests-oauthlib","text":"Authenticate with an API using OAuth:<pre><code>from requests_oauthlib import OAuth1Session\n\noauth = OAuth1Session(client_key='YOUR_CLIENT_KEY', \nclient_secret='YOUR_CLIENT_SECRET')\nresponse = oauth.get('https://api.example.com/user') \nprint(response.json())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#81-using-pandas-for-data-manipulation","title":"81. Using pandas for Data Manipulation","text":"Load and manipulate data in a CSV file:<pre><code>import pandas as pd\n\ndf = pd.read_csv('data.csv') \nprint(df.head())\n\n# Filter data\nfiltered_df = df[df['column_name'] &gt; 10]\nprint(filtered_df)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#82-using-requests-for-http-requests","title":"82. Using requests for HTTP Requests","text":"Making a GET and POST request:<pre><code>import requests\n\n# GET request\nresponse = requests.get('https://api.example.com/data') \nprint(response.json())\n\n# POST request\ndata = {'key': 'value'}\nresponse = requests.post('https://api.example.com/data', json=data) \nprint(response.json())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#83-creating-a-basic-web-server-with-httpserver","title":"83. Creating a Basic Web Server with http.server","text":"Simple HTTP server to serve files:<pre><code>from http.server import SimpleHTTPRequestHandler, HTTPServer\n\nPORT = 8000 handler = SimpleHTTPRequestHandler\n\nwith HTTPServer(('', PORT), handler) as httpd: \n  print(f'Serving on port {PORT}') \n  httpd.serve_forever()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#84-using-flask-for-webhooks","title":"84. Using Flask for Webhooks","text":"Handling incoming webhook requests:<pre><code>from flask import Flask, request\n\napp = Flask( name )\n@app.route('/webhook', methods=['POST']) \ndef webhook():\n  data = request.json \n  print(data)\n  return '', 200\n\nif name == ' main ': app.run(port=5000)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#85-creating-a-bash-script-with-subprocess","title":"85. Creating a Bash Script with subprocess","text":"Run shell commands from Python:<pre><code>import subprocess\n\nsubprocess.run(['echo', 'Hello, World!'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#86-using-docker-compose-with-python","title":"86. Using docker-compose with Python","text":"Programmatically run Docker Compose commands:<pre><code>import subprocess\n\nsubprocess.run(['docker-compose', 'up', '-d'])\n</code></pre>"},{"location":"01_System_Admin_Scripting/#87-using-moto-for-mocking-aws-services-in-tests","title":"87. Using moto for Mocking AWS Services in Tests","text":"Mocking AWS S3 for unit testing:<pre><code>import boto3 from moto import mock_s3\n\n@mock_s3\ndef test_s3_upload():\n  s3 = boto3.client('s3', region_name='us-east-1') \n  s3.create_bucket(Bucket='my-bucket') \n  s3.upload_file('file.txt', 'my-bucket', 'file.txt')\n  # Test logic here\n</code></pre>"},{"location":"01_System_Admin_Scripting/#88-using-asyncio-for-asynchronous-tasks","title":"88. Using asyncio for Asynchronous Tasks","text":"Run multiple tasks concurrently:<pre><code>import asyncio\n\nasync defsay_hello(): \n  print(\"Hello\")\n  await asyncio.sleep(1) \n  print(\"World\")\n\n\nasync def main():\n  await asyncio.gather(say_hello(), say_hello())\n\nasyncio.run(main())\n</code></pre>"},{"location":"01_System_Admin_Scripting/#89-using-flask-cors-for-cross-origin-resource-sharing","title":"89. Using flask-cors for Cross-Origin Resource Sharing","text":"Allow CORS in a Flask app:<pre><code>from flask import Flask\nfrom flask_cors import CORS\n\napp = Flask( name ) \nCORS(app)\n\n@app.route('/data', methods=['GET']) \ndef data():\n  return {\"message\": \"Hello from CORS!\"}\n\nif name == ' main ': app.run()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#90-using-pytest-fixtures-for-setup-and-teardown","title":"90. Using pytest Fixtures for Setup and Teardown","text":"Create a fixture to manage resources:<pre><code>import pytest\n\n@pytest.fixture\ndefsample_data():\n  data = {\"key\": \"value\"}\n  yield data # This is the test data\n  # Teardown code here (if necessary)\n\ndef test_sample_data(sample_data):\n  assert sample_data['key'] == 'value'\n</code></pre>"},{"location":"01_System_Admin_Scripting/#91-using-httpclient-for-low-level-http-requests","title":"91. Using http.client for Low-Level HTTP Requests","text":"Make a raw HTTP GET request:<pre><code>import http.client\n\nconn = http.client.HTTPSConnection(\"www.example.com\") \nconn.request(\"GET\", \"/\")\nresponse = conn.getresponse() \nprint(response.status, response.reason) \ndata = response.read()\nconn.close()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#92-implementing-redis-caching-with-redis-py","title":"92. Implementing Redis Caching with redis-py","text":"Basic operations with Redis:<pre><code>import redis\n\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n# Set and get value\nr.set('key', 'value')\nprint(r.get('key').decode('utf-8'))\n</code></pre>"},{"location":"01_System_Admin_Scripting/#93-using-json-for-data-serialization","title":"93. Using json for Data Serialization","text":"Convert Python objects to JSON:<pre><code>import json\n\ndata = {\"key\": \"value\"}\njson_data = json.dumps(data)\nprint(json_data)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#94-using-xmletreeelementtree-for-xml-processing","title":"94. Using xml.etree.ElementTree for XML Processing","text":"Parse an XML file:<pre><code>import xml.etree.ElementTree as ET\n\ntree = ET.parse('data.xml')\nroot = tree.getroot()\n\nfor child in root:\n  print(child.tag, child.attrib)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#95-creating-a-virtual-environment-with-venv","title":"95. Creating a Virtual Environment with venv","text":"Programmatically create a virtual environment:<pre><code>import venv\n\nvenv.create('myenv', with_pip=True)\n</code></pre>"},{"location":"01_System_Admin_Scripting/#96-using-psutil-for-system-monitoring","title":"96. Using psutil for System Monitoring","text":"Get system memory usage:<pre><code>import psutil\n\nmemory = psutil.virtual_memory()\nprint(f'Total Memory: {memory.total}, Available Memory:\n{memory.available}')\n</code></pre>"},{"location":"01_System_Admin_Scripting/#97-using-sqlite3-for-lightweight-database-management","title":"97. Using sqlite3 for Lightweight Database Management","text":"Basic SQLite operations:<pre><code>importsqlite3\n\nconn = sqlite3.connect('example.db') \nc = conn.cursor()\n\nc.execute('''CREATE TABLE IF NOT EXISTS users (id INTEGER \nPRIMARY KEY, name TEXT)''')\nc.execute(\"INSERT INTO users(name) VALUES ('Alice')\") \nconn.commit()\n\nfor row in c.execute('SELECT * FROM users'): \n  print(row)\n\nconn.close()\n</code></pre>"},{"location":"01_System_Admin_Scripting/#98-using-pytest-to-run-tests-in-parallel","title":"98. Using pytest to Run Tests in Parallel","text":"Run tests concurrently:<pre><code>pytest -n 4 # Run tests in parallel with 4 workers\n</code></pre>"},{"location":"01_System_Admin_Scripting/#99-using-argparse-for-command-line-arguments","title":"99. Using argparse for Command-Line Arguments","text":"Parse command-line arguments:<pre><code>import argparse\n\nparser = argparse.ArgumentParser(description='Process some integers.') \nparser.add_argument('integers', metavar='N', type=int, nargs='+',\n            help='an integer for the accumulator') \nparser.add_argument('--sum', dest='accumulate', action='store_const',\n            const=sum, default=max,\n            help='sum the integers (default: find the max)')\n\nargs = parser.parse_args() \nprint(args.accumulate(args.integers))\n</code></pre>"},{"location":"01_System_Admin_Scripting/#100-using-jsonschema-for-json-validation","title":"100. Using jsonschema for JSON Validation","text":"Validate JSON against a schema:<pre><code>from jsonschema import validate\nfrom jsonschema.exceptions import ValidationError\n\nschema = {\n  \"type\": \"object\", \n  \"properties\": {\n     \"name\": {\"type\": \"string\"},\n     \"age\": {\"type\": \"integer\", \"minimum\": 0}\n  },\n  \"required\": [\"name\", \"age\"]\n}\ndata = {\"name\": \"John\", \"age\": 30} \ntry:\n  validate(instance=data, schema=schema) \n  print(\"Data is valid\")\nexcept ValidationError as e: \n  print(f\"Data is invalid: {e.message}\")\n</code></pre>"},{"location":"02_Version_Control/","title":"Version Control","text":"<ul> <li>Git</li> <li>GitHub</li> <li>GitLab</li> <li>Bitbucket</li> </ul>"},{"location":"02_Version_Control/#1-git","title":"1. Git","text":""},{"location":"02_Version_Control/#1-git-setup-and-configuration","title":"1. Git Setup and Configuration","text":"<ul> <li><code>git --version</code> - Check Git version</li> <li><code>git config --global user.name \"Your Name\"</code> - Set global username</li> <li><code>git config --global user.email \"your.email@example.com\"</code> - Set global email</li> <li><code>git config --global core.editor \"vim\"</code> - Set default editor</li> <li><code>git config --global init.defaultBranch main</code> - Set default branch name</li> <li><code>git config --list</code> - View Git configuration</li> <li><code>git help &lt;command&gt;</code> - Get help for a Git command</li> </ul>"},{"location":"02_Version_Control/#2-creating-and-cloning-repositories","title":"2. Creating and Cloning Repositories","text":"<ul> <li><code>git init</code> - Initialize a new Git repository</li> <li><code>git clone &lt;repo_url&gt;</code> - Clone an existing repository</li> <li><code>git remote add origin &lt;repo_url&gt;</code> - Link local repo to a remote repo</li> <li><code>git remote -v</code> - List remote repositories</li> </ul>"},{"location":"02_Version_Control/#3-staging-and-committing-changes","title":"3. Staging and Committing Changes","text":"<ul> <li><code>git status</code> - Check the status of changes                                </li> <li><code>git add &lt;file&gt;</code> - Add a file to the staging area                   </li> <li><code>git add .</code> - Add all files to the staging area                                                        </li> <li><code>git commit -m \"Commit message\"</code> - Commit staged files                         </li> <li><code>git commit -am \"Commit message\"</code> - Add &amp; commit changes in one step</li> <li><code>git commit --amend -m \"New message\"</code> - Modify the last commit message</li> </ul>"},{"location":"02_Version_Control/#4-viewing-history-and-logs","title":"4. Viewing History and Logs","text":"<ul> <li><code>git log</code> - Show commit history</li> <li><code>git log --oneline</code> - Show history in one-line format</li> <li><code>git log --graph --decorate --all</code> - Display commit history as a graph</li> <li><code>git show &lt;commit_id&gt;</code> - Show details of a specific commit</li> <li><code>git diff</code> - Show unstaged changes</li> <li><code>git diff --staged</code> - Show staged but uncommitted changes</li> <li><code>git blame &lt;file&gt;</code> - Show who modified each line of a file</li> </ul>"},{"location":"02_Version_Control/#5-branching-and-merging","title":"5. Branching and Merging","text":"<ul> <li><code>git branch</code> - List all branches</li> <li><code>git branch &lt;branch_name&gt;</code> - Create a new branch</li> <li><code>git checkout &lt;branch_name&gt;</code> - Switch to another branch</li> <li><code>git checkout -b &lt;branch_name&gt;</code> - Create and switch to a new branch</li> <li><code>git merge &lt;branch_name&gt;</code> - Merge a branch into the current branch</li> <li><code>git branch -d &lt;branch_name&gt;</code> - Delete a local branch</li> <li><code>git branch -D &lt;branch_name&gt;</code> - Force delete a branch</li> </ul>"},{"location":"02_Version_Control/#6-working-with-remote-repositories","title":"6. Working with Remote Repositories","text":"<ul> <li><code>git fetch</code> - Fetch changes from remote repo</li> <li><code>git pull origin &lt;branch_name&gt;</code> - Pull latest changes</li> <li><code>git push origin &lt;branch_name&gt;</code> - Push changes to remote repo</li> <li><code>git push -u origin &lt;branch_name&gt;</code> - Push and set upstream tracking</li> <li><code>git remote show origin</code> - Show details of the remote repo</li> <li><code>git remote rm origin</code> - Remove the remote repository</li> </ul>"},{"location":"02_Version_Control/#7-undoing-changes","title":"7. Undoing Changes","text":"<ul> <li><code>git restore &lt;file&gt;</code> - Unstage changes</li> <li><code>git restore --staged &lt;file&gt;</code> - Unstage a file from the staging area</li> <li><code>git reset HEAD~1</code> - Undo the last commit but keep changes</li> <li><code>git reset --hard HEAD~1</code> - Undo the last commit and discard changes</li> <li><code>git revert &lt;commit_id&gt;&lt;/commit_id&gt;</code> - Create a new commit to undo changes</li> <li><code>git stash</code> - Save uncommitted changes temporarily</li> <li><code>git stash pop</code> - Apply stashed changes</li> <li><code>git stash drop</code> - Remove stashed changes</li> </ul>"},{"location":"02_Version_Control/#8-tagging-and-releases","title":"8. Tagging and Releases","text":"<ul> <li><code>git tag</code> - List all tags</li> <li><code>git tag &lt;tag_name&gt;</code> - Create a tag</li> <li><code>git tag -a &lt;tag_name&gt; -m \"Tag message\"</code> - Create an annotated tag</li> <li><code>git push origin &lt;tag_name&gt;</code> - Push a tag to remote</li> <li><code>git tag -d &lt;tag_name&gt;</code> - Delete a local tag</li> <li><code>git push --delete origin &lt;tag_name&gt;</code> - Delete a remote tag</li> </ul>"},{"location":"02_Version_Control/#9-working-with-submodules","title":"9. Working with Submodules","text":"<ul> <li><code>git submodule add &lt;repo_url&gt; &lt;path&gt;</code> - Add a submodule</li> <li><code>git submodule update --init --recursive</code> - Initialize and update submodules</li> <li><code>git submodule foreach git pull origin main</code> - Update all submodules</li> </ul>"},{"location":"02_Version_Control/#10-git-aliases-shortcuts","title":"10. Git Aliases (Shortcuts)","text":"<ul> <li><code>git config --global alias.st status</code> - Create alias for status command</li> <li><code>git config --global alias.co checkout</code> - Create alias for checkout command</li> <li><code>git config --global alias.br branch</code> - Create alias for branch command</li> <li><code>git config --global alias.cm commit</code> - Create alias for commit command</li> <li><code>git config --list | grep alias</code> - View all configured aliases</li> </ul>"},{"location":"02_Version_Control/#11-deleting-files-and-folders","title":"11. Deleting Files and Folders","text":"<ul> <li><code>git rm &lt;file&gt;</code> - Remove a file and stage deletion</li> <li><code>git rm -r &lt;folder&gt;</code> - Remove a directory</li> <li><code>git rm --cached &lt;file&gt;</code> - Remove file from repo but keep locally</li> </ul>"},{"location":"02_Version_Control/#12-force-push-and-rollback-use-with-caution","title":"12. Force Push and Rollback (Use with Caution)","text":"<ul> <li><code>git push --force</code> - Force push changes</li> <li><code>git reset --hard &lt;commit_id&gt;</code> - Reset repo to a specific commit</li> <li><code>git reflog</code> - Show history of HEAD changes</li> <li><code>git reset --hard ORIG_HEAD</code> - Undo the last reset</li> </ul>"},{"location":"02_Version_Control/#2-github","title":"2. GitHub","text":""},{"location":"02_Version_Control/#1-authentication-configuration","title":"1. Authentication &amp; Configuration","text":"<ul> <li><code>gh auth logout</code> \u2013 Log out of GitHub CLI</li> <li><code>gh auth status</code> \u2013 Check authentication status</li> <li><code>gh auth refresh</code> \u2013 Refresh authentication token</li> <li><code>gh config set editor &lt;editor&gt;</code> \u2013 Set the default editor (e.g., nano, vim)</li> <li><code>gh config get editor</code> \u2013 Get the current editor setting</li> </ul>"},{"location":"02_Version_Control/#2-repository-management","title":"2. Repository Management","text":"<ul> <li><code>gh repo list</code> \u2013 List repositories for the authenticated user</li> <li><code>gh repo delete &lt;name&gt;</code> \u2013 Delete a repository</li> <li><code>gh repo rename &lt;new-name&gt;</code> \u2013 Rename a repository</li> <li><code>gh repo fork --clone=false &lt;url&gt;</code> \u2013 Fork a repository without cloning</li> </ul>"},{"location":"02_Version_Control/#3-branch-commit-management","title":"3. Branch &amp; Commit Management","text":"<ul> <li><code>gh branch list</code> \u2013 List branches in a repository</li> <li><code>gh branch delete &lt;branch&gt;</code> \u2013 Delete a branch</li> <li><code>gh browse</code> \u2013 Open the repository in a browser</li> <li><code>gh co &lt;branch&gt;</code> \u2013 Check out a branch</li> </ul>"},{"location":"02_Version_Control/#4-issue-pull-request-handling","title":"4. Issue &amp; Pull Request Handling","text":"<ul> <li><code>gh issue create</code> \u2013 Create a new issue</li> <li><code>gh issue close &lt;issue-number&gt;</code> \u2013 Close an issue</li> <li><code>gh issue reopen &lt;issue-number&gt;</code> \u2013 Reopen a closed issue</li> <li><code>gh issue comment &lt;issue-number&gt; --body \"Comment\"</code> \u2013 Add a comment to an issue</li> <li><code>gh pr list</code> \u2013 List open pull requests</li> <li><code>gh pr checkout &lt;pr-number&gt;</code> \u2013 Check out a pull request branch</li> <li><code>gh pr close &lt;pr-number&gt;</code> \u2013 Close a pull request</li> </ul>"},{"location":"02_Version_Control/#5-gists-actions","title":"5. Gists &amp; Actions","text":"<ul> <li><code>gh gist create &lt;file&gt;</code> \u2013 Create a new gist</li> <li><code>gh gist list</code>\u2013 List all gists</li> <li><code>gh workflow list</code> \u2013 List GitHub Actions workflows</li> <li><code>gh run list</code> \u2013 List workflow runs</li> </ul>"},{"location":"02_Version_Control/#webhooks","title":"Webhooks","text":"<ul> <li>Go to Repo \u2192 Settings \u2192 Webhooks \u2192 Add Webhook</li> <li>Events: push, pull_request, issues, etc.</li> <li>Payload sent in JSON format to the specified URL</li> </ul>"},{"location":"02_Version_Control/#3-gitlab","title":"3. GitLab","text":""},{"location":"02_Version_Control/#1-project-repository-management","title":"1. Project &amp; Repository Management","text":"<ul> <li><code>gitlab project create &lt;name&gt;</code> \u2013 Create a new project</li> <li><code>gitlab repo list</code> \u2013 List repositories</li> <li><code>gitlab project delete &lt;id&gt;</code> \u2013 Delete a project</li> <li><code>gitlab repo fork &lt;repo&gt;</code> \u2013 Fork a repository</li> <li><code>gitlab repo clone &lt;url&gt;</code> \u2013 Clone a GitLab repository</li> <li><code>gitlab repo archive &lt;repo&gt;</code> \u2013 Archive a repository</li> </ul>"},{"location":"02_Version_Control/#2-issues-merge-requests","title":"2. Issues &amp; Merge Requests","text":"<ul> <li><code>gitlab issue list</code> \u2013 List all issues in a project</li> <li><code>gitlab issue create --title \"&lt;title&gt;\" --description \"&lt;desc&gt;\"</code> \u2013 Create an issue</li> <li><code>gitlab issue close &lt;issue_id&gt;</code> \u2013 Close an issue</li> <li><code>gitlab issue reopen &lt;issue_id&gt;</code> \u2013 Reopen an issue</li> <li><code>gitlab merge_request list</code> \u2013 List merge requests</li> <li><code>gitlab merge_request create --source-branch &lt;branch&gt; --target-branch &lt;branch&gt; --title \"&lt;title&gt;\"</code> \u2013 Create a merge request</li> <li><code>gitlab merge_request close &lt;mr_id&gt;</code> \u2013 Close a merge request</li> </ul>"},{"location":"02_Version_Control/#3-pipeline-cicd","title":"3. Pipeline &amp; CI/CD","text":"<ul> <li><code>gitlab pipeline trigger</code> \u2013 Trigger a pipeline</li> <li><code>gitlab pipeline list</code> \u2013 List all pipelines</li> <li><code>gitlab pipeline retry &lt;pipeline_id&gt;</code> \u2013 Retry a failed pipeline</li> <li><code>gitlab pipeline cancel &lt;pipeline_id&gt;</code> \u2013 Cancel a running pipeline</li> <li><code>gitlab pipeline delete &lt;pipeline_id&gt;</code> \u2013 Delete a pipeline</li> <li><code>gitlab runner register</code> \u2013 Register a CI/CD runner</li> <li><code>gitlab runner list</code> \u2013 List registered runners</li> <li><code>gitlab runner unregister &lt;runner_id&gt;</code> \u2013 Unregister a runner</li> </ul>"},{"location":"02_Version_Control/#4-user-group-management","title":"4. User &amp; Group Management","text":"<ul> <li><code>gitlab user list</code> \u2013 List users in GitLab</li> <li><code>gitlab user create --name \"&lt;name&gt;\" --email \"&lt;email&gt;\"</code> \u2013 Create a new user</li> <li><code>gitlab group list</code> \u2013 List groups in GitLab</li> <li><code>gitlab group create --name \"&lt;group_name&gt;\" --path \"&lt;group_path&gt;\"</code> \u2013 Create a group</li> <li><code>gitlab group delete &lt;group_id&gt;</code> \u2013 Delete a group</li> </ul>"},{"location":"02_Version_Control/#5-access-permissions","title":"5. Access &amp; Permissions","text":"<ul> <li><code>gitlab project member list &lt;project_id&gt;</code> \u2013 List project members</li> <li><code>gitlab project member add &lt;project_id&gt; &lt;user_id&gt; &lt;access_level&gt;</code> \u2013 Add a user to a project</li> <li><code>gitlab group member list &lt;group_id&gt;</code> \u2013 List group members</li> <li><code>gitlab group member add &lt;group_id&gt; &lt;user_id&gt; &lt;access_level&gt;</code> \u2013 Add a user to a group</li> </ul>"},{"location":"02_Version_Control/#6-repository-protection-settings","title":"6. Repository Protection &amp; Settings","text":"<ul> <li><code>gitlab branch protect &lt;branch&gt;</code> \u2013 Protect a branch</li> <li><code>gitlab branch unprotect &lt;branch&gt;</code> \u2013 Unprotect a branch</li> <li><code>gitlab repository mirror</code> \u2013 Set up repository mirroring</li> <li><code>gitlab repository settings update</code> \u2013 Update repository settings</li> </ul>"},{"location":"02_Version_Control/#webhooks_1","title":"Webhooks:","text":"<ul> <li>Go to Settings \u2192 Webhooks</li> <li>Select triggers: Push events, Tag push, Merge request, etc.</li> <li>Use GitLab CI/CD with .gitlab-ci.yml</li> </ul>"},{"location":"02_Version_Control/#4-bitbucket","title":"4. Bitbucket","text":""},{"location":"02_Version_Control/#1-repository-management","title":"1. Repository Management","text":"<ul> <li><code>bitbucket repo create &lt;name&gt;</code> - Create a repository</li> <li><code>bitbucket repo list</code> - List all repositories</li> <li><code>bitbucket repo delete &lt;name&gt;</code> - Delete a repository</li> <li><code>bitbucket repo clone &lt;repo-url&gt;</code> - Clone a repository</li> <li><code>bitbucket repo fork &lt;repo&gt;</code> - Fork a repository</li> <li><code>bitbucket repo update &lt;repo&gt;</code> - Update repository settings</li> </ul>"},{"location":"02_Version_Control/#2-branch-management","title":"2. Branch Management","text":"<ul> <li><code>bitbucket branch create &lt;branch-name&gt;</code> \u2013 Create a new branch</li> <li><code>bitbucket branch list</code> - List all branches</li> <li><code>bitbucket branch delete &lt;branch-name&gt;</code> - Delete a branch</li> </ul>"},{"location":"02_Version_Control/#3-pipeline-management","title":"3. Pipeline Management","text":"<ul> <li><code>bitbucket pipeline run</code> - Run a pipeline</li> <li><code>bitbucket pipeline list</code> - List pipelines</li> <li><code>bitbucket pipeline stop &lt;pipeline-id&gt;</code> - Stop a running pipeline</li> <li><code>bitbucket pipeline rerun &lt;pipeline-id&gt;</code> - Rerun a pipeline</li> </ul>"},{"location":"02_Version_Control/#4-issue-tracking","title":"4. Issue Tracking","text":"<ul> <li><code>bitbucket issue list</code> - List all issues</li> <li><code>bitbucket issue create \"&lt;title&gt;\" --kind=&lt;bug/task/enhancement&gt;</code> - Create an issue</li> <li><code>bitbucket issue update &lt;issue-id&gt; --status=&lt;open/closed/resolved&gt;</code> - Update issue status</li> <li><code>bitbucket issue delete &lt;issue-id&gt;</code> - Delete an issue</li> </ul>"},{"location":"02_Version_Control/#5-pull-request-management","title":"5. Pull Request Management","text":"<ul> <li><code>bitbucket pullrequest create --source &lt;branch&gt; --destination &lt;branch&gt;</code> - Create a pull request</li> <li><code>bitbucket pullrequest list</code> - List pull requests</li> <li><code>bitbucket pullrequest merge &lt;id&gt;</code> - Merge a pull request</li> <li><code>bitbucket pullrequest approve &lt;id&gt;</code> - Approve a pull request</li> <li><code>bitbucket pullrequest decline &lt;id&gt;</code> - Decline a pull request</li> </ul>"},{"location":"02_Version_Control/#webhooks_2","title":"Webhooks","text":"<ul> <li>Go to Repo \u2192 Repository Settings \u2192 Webhooks</li> <li>Choose event typesd like repo:push, pullrequest:created, etc</li> </ul>"},{"location":"03_CICD/","title":"Continuous Integration (CI) &amp; Continuous Deployment (CD)","text":""},{"location":"03_CICD/#jenkins-pipelines-declarative-scripts","title":"Jenkins (pipelines, declarative scripts)","text":""},{"location":"03_CICD/#jenkins-installation-ubuntu","title":"Jenkins Installation (Ubuntu)","text":"<ul> <li>Install Java (Jenkins requires Java)</li> </ul> <pre><code>sudo apt update &amp;&amp; sudo apt install -y openjdk-17-jdk\n</code></pre> <ul> <li>Add Jenkins repository &amp; install Jenkins</li> </ul> <pre><code>wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo tee /usr/share/keyrings/jenkins-keyring.asc &gt; /dev/null echo \"deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] https://pkg.jenkins.io/debian-stable binary/\" | sudo tee /etc/apt/sources.list.d/jenkins.list &gt; /dev/null sudo apt update &amp;&amp; sudo apt install -y jenkins\n</code></pre> <ul> <li>Start &amp; Enable Jenkins</li> </ul> <pre><code>sudo systemctl enable --now jenkins\n</code></pre> <ul> <li>Check Jenkins status</li> </ul> <pre><code>sudo systemctl status jenkins\n</code></pre> <ul> <li>Access Jenkins UI at http://your-server-ip:8080</li> </ul> <pre><code>sudo cat /var/lib/jenkins/secrets/initialAdminPassword\n</code></pre>"},{"location":"03_CICD/#1-basic-jenkins-commands","title":"1. Basic Jenkins Commands","text":"<ul> <li><code>systemctl start jenkins</code> - Start Jenkins service </li> <li><code>systemctl stop jenkins</code> - Stop Jenkins service </li> <li><code>systemctl restart jenkins</code> - Restart Jenkins service </li> <li><code>systemctl status jenkins</code> - Check Jenkins service status </li> <li><code>journalctl -u jenkins -f</code> - View real-time logs</li> </ul>"},{"location":"03_CICD/#2-jenkins-cli-commands","title":"2. Jenkins CLI Commands","text":"<ul> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) list-jobs</code> - List all jobs</li> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) build &lt;job-name&gt;</code> - Trigger a job</li> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) delete-job &lt;job-name&gt;</code> - Delete a job</li> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) enable-job &lt;job-name&gt;</code> - Enable a job</li> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) disable-job &lt;job-name&gt;</code> - Disable a job</li> <li><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) who-am-i</code> - Show current user info</li> </ul>"},{"location":"03_CICD/#3-jenkins-environment-variables","title":"3. Jenkins Environment Variables","text":"<ul> <li><code>JENKINS_HOME</code> - Jenkins home directory</li> <li><code>BUILD_NUMBER</code> - Current build number</li> <li><code>JOB_NAME</code> - Job name</li> <li><code>WORKSPACE</code> - Workspace directory</li> <li><code>GIT_COMMIT</code> - Git commit hash of the build</li> <li><code>BUILD_URL</code> - URL of the build</li> <li><code>NODE_NAME</code> - Name of the node the build is running on</li> </ul>"},{"location":"03_CICD/#4-jenkins-pipeline-declarative","title":"4. Jenkins Pipeline (Declarative)","text":"<pre><code>pipeline {\n  agent any\n  environment {\n    APP_ENV = 'production'\n  }\n  stages {\n    stage('Checkout') {\n      steps {\n        git 'https://github.com/your-repo.git'\n      }\n    }\n    stage('Build') { \n      steps {\n        sh 'mvn clean package'\n      }\n    }\n    stage('Test') { \n      steps {\n        sh 'mvn test'\n      }\n    }\n    stage('Deploy') { \n      steps {\n        sh 'scp target/*.jar user@server:/deploy/'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#5-jenkins-pipeline-scripted","title":"5. Jenkins Pipeline (Scripted)","text":"<pre><code>node {\n  stage('Checkout') {\n    git 'https://github.com/your-repo.git'\n  }\n  stage('Build') {\n    sh 'mvn clean package'\n  }\n  stage('Test') { \n    sh 'mvn test'\n  }\n  stage('Deploy') {\n    sh 'scp target/*.jar user@server:/deploy/'\n  }\n}\n</code></pre>"},{"location":"03_CICD/#6-jenkins-webhook-github-example","title":"6. Jenkins Webhook (GitHub Example)","text":"<ol> <li>Go to GitHub Repo &gt; Settings &gt; Webhooks</li> <li>Add URL: http:///github-webhook/ <li>Select application/json as content type</li> <li>Choose Just the push event</li> <li>Save and trigger a push event to test</li>"},{"location":"03_CICD/#7-manage-plugins-via-cli","title":"7. Manage Plugins via CLI","text":"<p>Install a plugin<pre><code>java-jarjenkins-cli.jar-shttp://localhost:8080install-plugin &lt;plugin-name&gt;\n</code></pre> List installed plugins<pre><code>java -jar jenkins-cli.jar -s http://localhost:8080list-plugins \n</code></pre> Restart safely after installing plugins<pre><code>java -jar jenkins-cli.jar -s http://localhost:8080safe-restart\n</code></pre></p>"},{"location":"03_CICD/#8-manage-jenkins-jobs-via-cli","title":"8. Manage Jenkins Jobs via CLI","text":"<p>Create a job<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) create-job my-job &lt; job-config.xml\n</code></pre> Export job config<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) get-job my-job &gt; job-config.xml\n</code></pre> Update job config<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) update-job my-job &lt; job-config.xml\n</code></pre></p>"},{"location":"03_CICD/#9-backup-restore-jenkins","title":"9. Backup &amp; Restore Jenkins","text":"Restore Jenkins<pre><code>cp -r $JENKINS_HOME /backup/jenkins_$(date +%F) - Backup Jenkins cp -r /backup/jenkins_&lt;date&gt;/\\* $JENKINS_HOME\n</code></pre>"},{"location":"03_CICD/#10-jenkins-security-commands","title":"10. Jenkins Security Commands","text":"<p>Reload config<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) reload-configuration\n</code></pre> Safe shutdown<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) safe-shutdown\n</code></pre> Restart Jenkins<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) restart\n</code></pre></p>"},{"location":"03_CICD/#11-jenkins-credentials-via-cli","title":"11. Jenkins Credentials via CLI","text":"<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) create-credentials-by-xml system::system::jenkins _ &lt; credentials.xml\n</code></pre>"},{"location":"03_CICD/#12-jenkins-node-management","title":"12. Jenkins Node Management","text":"<p>List all nodes<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) list-nodes\n</code></pre> Create a new node<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) create-node &lt;node-name&gt;\n</code></pre> Delete a node<pre><code>java -jar jenkins-cli.jar -s [http://localhost:8080](http://localhost:8080/) delete-node &lt;node-name&gt;\n</code></pre></p>"},{"location":"03_CICD/#13-jenkins-job-trigger-examples","title":"13. Jenkins Job Trigger Examples","text":"<pre><code>trigger {\n  cron('H 4 * * *') # Run at 4 AM every day\n}\ntrigger {\n  pollSCM('H/5 * * * *') # Check SCM every 5 minutes\n}\n</code></pre>"},{"location":"03_CICD/#14-jenkins-file-parameter-example","title":"14. Jenkins File Parameter Example","text":"<pre><code>pipeline { \n  agent any \n  parameters {\n     file(name: 'configFile')\n  }\n  stages {\n     stage('Read File') { \n        steps {\n           sh 'cat ${configFile}'\n        }\n     }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#15-jenkins-docker-pipeline-example","title":"15. Jenkins Docker Pipeline Example","text":"<pre><code>pipeline {\n  agent {\n    docker {\n      image 'maven:3.8.7'\n    }\n  }\n  stages {\n    stage('Build') { \n      steps {\n        sh 'mvn clean package'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#jenkins-pipeline-scripts-with-devops-tools","title":"Jenkins Pipeline Scripts with DevOps Tools","text":""},{"location":"03_CICD/#1-basic-cicd-pipeline","title":"1. Basic CI/CD Pipeline","text":"<pre><code>pipeline { \n  agent any \n  stages {\n    stage('Clone Repository') { \n      steps {\n        git 'https://github.com/user/repo.git'\n      }\n    }\n    stage('Build') { \n      steps {\n        sh 'mvn clean package'\n      }\n    }\n    stage('Test') { \n      steps {\n        sh 'mvn test'\n      }\n    }\n    stage('Deploy') { \n      steps {\n        sh 'scp target/app.jar user@server:/deploy/path'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#2-docker-build-push","title":"2. Docker Build &amp; Push","text":"<pre><code>pipeline { \n  agent any\n  environment {\n    DOCKER_HUB_USER = 'your-dockerhub-username'\n  }\n  stages {\n    stage('Build Docker Image') { \n      steps {\n        sh 'docker build -t my-app:latest .'\n      }\n    }\n    stage('Push to Docker Hub') { \n      steps {\n        withDockerRegistry([credentialsId: 'docker-hub-credentials', url: '']) { \n          sh 'docker tag my-app:latest $DOCKER_HUB_USER/my-app:latest' \n          sh 'docker push $DOCKER_HUB_USER/my-app:latest'\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#3-kubernetes-deployment","title":"3. Kubernetes Deployment","text":"<pre><code>pipeline { \n  agent any \n  stages {\n    stage('Deploy to Kubernetes') {\n      steps {\n        sh 'kubectl apply -f k8s/deployment.'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#4-terraform-deployment","title":"4. Terraform Deployment","text":"<pre><code>pipeline { \n  agent any \n  stages {\n    stage('Terraform Init') { \n      steps {\n        sh 'terraform init'\n      }\n    }\n    stage('Terraform Apply') { \n      steps {\n        sh 'terraform apply -auto-approve'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#5-security-scanning-with-trivy","title":"5. Security Scanning with Trivy","text":"<pre><code>pipeline { \n  agent any \n  stages {\n    stage('Scan with Trivy') { \n      steps {\n        sh 'trivy image my-app:latest'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#6-sonarqube-code-analysis","title":"6. SonarQube Code Analysis","text":"<pre><code>pipeline { \n  agent any\n  environment {\n    SONAR_TOKEN = credentials('sonar-token')\n  }\n  stages {\n    stage('SonarQube Analysis') { \n      steps {\n        withSonarQubeEnv('SonarQube') {\n          sh 'mvn sonar:sonar -Dsonar.login=$SONAR_TOKEN'\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"03_CICD/#github-actions-workflows-syntax","title":"GitHub Actions (workflows, syntax)","text":"<p>GitHub Actions allows automation for CI/CD pipelines directly within GitHub repositories.</p> <ul> <li>Workflows (.github/workflows/*.yml): Defines automation steps.</li> <li>Jobs: Runs tasks inside a workflow.</li> <li>Steps: Individual commands executed in jobs.</li> <li>Actions: Predefined or custom reusable commands.</li> </ul>"},{"location":"03_CICD/#commands","title":"Commands","text":""},{"location":"03_CICD/#1-initialize-a-github-actions-workflow","title":"1. Initialize a GitHub Actions workflow","text":"<pre><code>mkdir -p .github/workflows &amp;&amp; touch .github/workflows/main.yml\n</code></pre>"},{"location":"03_CICD/#2-validate-github-actions-workflow-syntax","title":"2. Validate GitHub Actions workflow syntax","text":"List available workflows<pre><code>act -l\n</code></pre> Run a specific job locally<pre><code>act -j &lt;job-name&gt;\n</code></pre> Run the workflow locally<pre><code>act -w .github/workflows/main.yml\n</code></pre>"},{"location":"03_CICD/#3-set-up-github-actions-runner","title":"3. Set up GitHub Actions runner","text":"<ul> <li><code>gh workflow list</code> - List workflows in the repo</li> <li><code>gh workflow run &lt;workflow-name&gt;</code> - Manually trigger a workflow</li> <li><code>gh workflow enable &lt;workflow-name&gt;</code> - Enable a workflow</li> <li><code>gh workflow disable &lt;workflow-name&gt;</code> - Disable a workflow</li> </ul>"},{"location":"03_CICD/#4-manage-workflow-runs","title":"4. Manage workflow runs","text":"<ul> <li><code>gh run list</code> - List recent workflow runs</li> <li><code>gh run view &lt;run-id&gt;</code> - View details of a specific workflow run</li> <li><code>gh run rerun &lt;run-id&gt;</code> - Rerun a failed workflow</li> <li><code>gh run cancel &lt;run-id&gt;</code> - Cancel a running workflow</li> <li><code>gh run delete &lt;run-id&gt;</code> - Delete a workflow run</li> </ul>"},{"location":"03_CICD/#5-manage-workflow-artifacts","title":"5. Manage workflow artifacts","text":"<ul> <li><code>gh run download -n &lt;artifact-name&gt;</code> - Download artifacts from a workflow run</li> <li><code>gh run view --log</code> - View logs of the latest workflow run</li> </ul>"},{"location":"03_CICD/#6-manage-secrets-for-github-actions","title":"6. Manage secrets for GitHub Actions","text":"<ul> <li><code>gh secret list</code> - List repository secrets</li> <li><code>gh secret set &lt;SECRET_NAME&gt; --body &lt;value&gt;</code> - Add or update a secret</li> <li><code>gh secret remove &lt;SECRET_NAME&gt;</code> - Remove a secret</li> </ul>"},{"location":"03_CICD/#7-using-github-actions-cache","title":"7. Using GitHub Actions Cache","text":"<ul> <li><code>actions/cache@v3</code> - GitHub Actions cache</li> <li><code>actions/upload-artifact@v3</code> - Upload artifacts</li> <li><code>actions/download-artifact@v3</code> - Download artifacts</li> </ul>"},{"location":"03_CICD/#8-run-a-workflow-manually-via-api","title":"8. Run a workflow manually via API","text":"<pre><code>curl -X POST -H \"Authorization: token &lt;YOUR_GITHUB_TOKEN&gt;\" \\\n-H \"Accept: application/vnd.github.v3+json\" \\\nhttps://api.github.com/repos/&lt;owner&gt;/&lt;repo&gt;/actions/workflows/&lt;workflow_file&gt;/ dispatches \\\n-d '{\"ref\":\"main\"}'\n</code></pre>"},{"location":"03_CICD/#github-actions-workflow","title":"Github Actions Workflow:","text":""},{"location":"03_CICD/#basic-github-actions-workflow","title":"Basic GitHub Actions Workflow","text":"<p> File: .github/workflows/ci-cd.yml</p> <pre><code>name: CI/CD Pipeline\n\non:\n  push:\n    branches:\n     - main\n  pull_request:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n\n    - name: Set Up Java\n      uses: actions/setup-java@v3\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - name: Build with Maven\n      run: mvn clean package\n\n    - name: Upload Build Artifact\n      uses: actions/upload-artifact@v4\n      with:\n        name: application\n        path: target/\\*.jar\n</code></pre>"},{"location":"03_CICD/#docker-build-push-to-docker-hub","title":"Docker Build &amp; Push to Docker Hub","text":"<p> File: .github/workflows/docker.yml</p> <pre><code>name: Docker Build &amp; Push\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Login to Docker Hub \n      uses: docker/login-action@v3 \n      with:\n        username: ${{ secrets.DOCKER_USERNAME }} \n        password: ${{ secrets.DOCKER_PASSWORD }}\n    - name: Build and Push Docker Image \n      run: |\n        docker build -t my-app:latest .\n        docker tag my-app:latest ${{ secrets.DOCKER_USERNAME }}/my-app:latest\n        docker push ${{ secrets.DOCKER_USERNAME }}/my-app:latest\n</code></pre>"},{"location":"03_CICD/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p> File: .github/workflows/k8s.yml</p> <pre><code>name: Deploy to Kubernetes\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Set Up Kubectl\n      uses: azure/setup-kubectl@v3\n      with:\n        version: 'latest'\n    - name: Apply Kubernetes Manifest\n      run: kubectl apply -f k8s/deployment.\n</code></pre>"},{"location":"03_CICD/#terraform-deployment","title":"Terraform Deployment","text":"<p> File: .github/workflows/terraform.yml</p> <pre><code>name: Terraform Deployment\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  terraform:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Set Up Terraform\n      uses: hashicorp/setup-terraform@v3\n    - name: Terraform Init &amp; Apply\n      run: | \n        terraform init\n        terraform apply -auto-approve\n</code></pre>"},{"location":"03_CICD/#security-scanning-with-trivy","title":"Security Scanning with Trivy","text":"<p> File: .github/workflows/trivy.yml</p> <pre><code>name: Security Scan with Trivy\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  scan:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Run Trivy Image Scan\n      run: | \n        docker pull ${{ secrets.DOCKER_USERNAME }}/my-app:latest\n        trivy image ${{ secrets.DOCKER_USERNAME }}/my-app:latest\n</code></pre>"},{"location":"03_CICD/#sonarqube-code-analysis","title":"SonarQube Code Analysis","text":"<p> File: .github/workflows/sonarqube.yml</p> <pre><code>name: SonarQube Analysis\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  sonar:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Set Up Java\n      uses: actions/setup-java@v3\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n    - name: Run SonarQube Analysis\n      run: mvn sonar:sonar -Dsonar.login=${{ secrets.SONAR_TOKEN }}\n</code></pre>"},{"location":"03_CICD/#upload-deploy-to-aws-s3","title":"Upload &amp; Deploy to AWS S3","text":"<p> File: .github/workflows/s3-upload.yml</p> <pre><code>name: Upload to S3\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Upload Files to S3\n      run: |\n        aws s3 sync . s3://my-bucket-name --delete\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }}\n</code></pre>"},{"location":"03_CICD/#gitlab-cicd-stages-jobs-runners","title":"GitLab CI/CD (stages, jobs, runners)","text":""},{"location":"03_CICD/#gitlab-cicd-basics","title":"GitLab CI/CD Basics","text":"<ul> <li>.gitlab-ci.yml: Defines the CI/CD pipeline in the repository root.</li> <li>Stages: Pipeline execution order (build, test, deploy).</li> <li>Jobs: Specific tasks in each stage.</li> <li>Runners: Machines executing jobs (shared or self-hosted).</li> <li>Artifacts: Files preserved after job execution.</li> </ul>"},{"location":"03_CICD/#basic-gitlab-cicd-pipeline","title":"Basic GitLab CI/CD Pipeline","text":"<p> File: .gitlab-ci.yml</p> <pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n  - echo \"Building application...\"\n  - mvn clean package\n  artifacts:\n    paths:\n    - target/\\*.jar\n\ntest:\n  stage: test\n    script:\n    - echo \"Running tests...\"\n    - mvn test\n\ndeploy:\n  stage: deploy \n  script:\n  - echo \"Deploying application...\"\n  - scp target/*.jar user@server:/deploy/path \n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#docker-build-push-to-gitlab-container-registry","title":"Docker Build &amp; Push to GitLab Container Registry","text":"<p> File: .gitlab-ci.yml</p> <pre><code>variables:\n  IMAGE_NAME: registry.gitlab.com/your-namespace/your-repo\n\nstages:\n  - build\n  - push\n\nbuild:\n  stage: build \n  script:\n  - docker build -t $IMAGE_NAME:latest . \n  only:\n  - main\n\npush:\n  stage: push\n  script:\n  - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n  - docker push $IMAGE_NAME:latest \n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#kubernetes-deployment_1","title":"Kubernetes Deployment","text":"<p> File: .gitlab-ci.yml</p> <pre><code>stages:\n- deploy\n\ndeploy:\n  stage: deploy\n  image: bitnami/kubectl\n  script:\n  - kubectl apply -f k8s/deployment.\n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#terraform-deployment_1","title":"Terraform Deployment","text":"<p> File: .gitlab-ci.yml</p> <pre><code>image: hashicorp/terraform:latest\n\nstages:\n- terraform\n\nterraform:\n  stage: terraform\n  script:\n  - terraform init\n  - terraform apply -auto-approve \n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#security-scanning-with-trivy_1","title":"Security Scanning with Trivy","text":"<p> File: .gitlab-ci.yml</p> <pre><code>stages:\n- security_scan\n\nsecurity_scan: stage:security_scan\n  script:\n  - docker pull registry.gitlab.com/your-namespace/your-repo:latest\n  - trivy image registry.gitlab.com/your-namespace/your-repo:latest\n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#sonarqube-code-analysis_1","title":"SonarQube Code Analysis","text":"<p> File: .gitlab-ci.yml</p> <pre><code>image: maven:3.8.7\n\nstages:\n- analysis\n\nsonarqube:\n  stage: analysis\n  script:\n  - mvn sonar:sonar -Dsonar.login=$SONAR_TOKEN\n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#aws-s3-upload","title":"AWS S3 Upload","text":"<p> File: .gitlab-ci.yml</p> <pre><code>stages:\n- deploy\n\ndeploy_s3:\n  stage: deploy\n  script:\n  - aws s3 sync . s3://my-bucket-name --delete\n  only:\n  - main\n  environment:\n  name: production\n</code></pre>"},{"location":"03_CICD/#notify-on-slack","title":"Notify on Slack","text":"<p> File: .gitlab-ci.yml</p> <pre><code>notify:\n  stage: notify\n  script:\n  - curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"Deployment completed successfully!\"}' $SLACK_WEBHOOK_URL\n  only:\n  - main\n</code></pre>"},{"location":"03_CICD/#tekton","title":"Tekton","text":"<p>What is Tekton?</p> <p>Tekton is a Kubernetes-native CI/CD framework that allows you to create and run pipelines for automating builds, testing, security scans, and deployments. It provides reusable components such as Tasks, Pipelines, and PipelineRuns, making it ideal for cloud-native DevOps workflows.</p>"},{"location":"03_CICD/#installation-on-kubernetes-cluster","title":"Installation (On Kubernetes Cluster)","text":"1. Install Tekton Pipelines<pre><code>kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/latest/release.\n</code></pre> 2. Verify Installation<pre><code>kubectl get pods -n tekton-pipelines\n</code></pre> 3. Install Tekton CLI (tkn)<pre><code>curl -LO https://github.com/tektoncd/cli/releases/latest/download/tkn-linux-amd64 chmod +x tkn-linux-amd64 sudo mv tkn-linux-amd64 /usr/local/bin/tkn\n</code></pre> 4. Check Tekton CLI Version<pre><code>tkn version\n</code></pre>"},{"location":"03_CICD/#tekton-basics","title":"Tekton Basics","text":"<ul> <li>Tasks: The smallest execution unit in Tekton.</li> <li>Pipelines: A sequence of tasks forming a CI/CD process.</li> <li>PipelineRuns: Executes a pipeline.</li> <li>TaskRuns: Executes a task.</li> <li>Workspaces: Used for sharing data between tasks.</li> <li>Resources: Defines input/output artifacts (e.g., Git repositories, images).</li> </ul>"},{"location":"03_CICD/#tekton-pipeline-commands","title":"Tekton Pipeline Commands","text":"<ul> <li><code>tkn pipeline list</code> - List all pipelines</li> <li><code>tkn pipeline describe &lt;pipeline-name&gt;</code> - Describe a specific pipeline</li> <li><code>tkn pipeline start &lt;pipeline-name&gt;</code> --showlog - Start a pipeline and show logs</li> <li><code>tkn pipeline delete &lt;pipeline-name&gt;</code> - Delete a pipeline</li> </ul>"},{"location":"03_CICD/#tekton-task-commands","title":"Tekton Task Commands","text":"<ul> <li><code>tkn task list</code> - List all tasks</li> <li><code>tkn task describe &lt;task-name&gt;</code>- Describe a specific task </li> <li><code>tkn task start &lt;task-name&gt; --showlog</code> - Start a task and show logs </li> <li><code>tkn task delete &lt;task-name&gt;</code> - Delete a task</li> </ul>"},{"location":"03_CICD/#tekton-pipelinerun-commands","title":"Tekton PipelineRun Commands","text":"<ul> <li><code>tkn pipelinerun list</code> - List pipeline runs </li> <li><code>tkn pipelinerun describe &lt;pipelinerun-name&gt;</code> - Describe a pipeline run </li> <li><code>tkn pipelinerun logs &lt;pipelinerun-name&gt;</code> - Show logs of a pipeline run </li> <li><code>tkn pipelinerun delete &lt;pipelinerun-name&gt;</code> - Delete a pipeline run</li> </ul>"},{"location":"03_CICD/#tekton-taskrun-commands","title":"Tekton TaskRun Commands","text":"<ul> <li><code>tkn taskrun list</code> - List task runs </li> <li><code>tkn taskrun describe &lt;taskrun-name&gt;</code> - Describe a task run </li> <li><code>tkn taskrun logs &lt;taskrun-name&gt;</code> - Show logs of a task run </li> <li><code>tkn taskrun delete &lt;taskrun-name&gt;</code> - Delete a task run</li> </ul>"},{"location":"03_CICD/#tekton-resources-commands","title":"Tekton Resources Commands","text":"<ul> <li><code>tkn resource list</code> - List all pipeline resources </li> <li><code>tkn resource describe &lt;resource-name&gt;</code> - Describe a specific resource </li> <li><code>tkn resource delete &lt;resource-name&gt;</code> - Delete a resource</li> </ul>"},{"location":"03_CICD/#tekton-triggers-commands","title":"Tekton Triggers Commands","text":"<ul> <li><code>tkn triggerbinding list</code>- List trigger bindings </li> <li><code>tkn triggertemplate list</code> - List trigger templates </li> <li><code>tkn eventlistener list</code> - List event listeners </li> <li><code>tkn eventlistener logs &lt;listener-name&gt;</code> - Show logs of an event listener</li> </ul>"},{"location":"03_CICD/#tekton-debugging-monitoring","title":"Tekton Debugging &amp; Monitoring","text":"<ul> <li><code>kubectl logs -l app=tekton-pipelines-controller -n tekton-pipelines</code> - View Tekton controller logs </li> <li><code>kubectl get pods -n tekton-pipelines - List running Tekton pods kubectl describe pod &lt;pod-name&gt; -n tekton-pipelines</code> - Get details of a specific pod</li> </ul>"},{"location":"03_CICD/#delete-all-tekton-resources","title":"Delete All Tekton Resources","text":"<ul> <li><code>kubectl delete pipelineruns --all -n &lt;namespace&gt;</code></li> <li><code>kubectl delete taskruns --all -n &lt;namespace&gt;</code></li> <li><code>kubectl delete pipelines --all -n &lt;namespace&gt;</code></li> <li><code>kubectl delete tasks --all -n &lt;namespace&gt;</code></li> </ul>"},{"location":"03_CICD/#basic-tekton-task","title":"Basic Tekton Task","text":"<p> File: task.yml</p> task.yml<pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\n  metadata:\n  name: echo-task\nspec:\n  steps:\n  - name: echo-message\n    image: alpine\n    script: |\n      #!/bin/sh\n      echo \"Hello from Tekton Task!\"\n</code></pre> Apply the task:<pre><code>kubectl apply -f task.\n</code></pre> Run the task:<pre><code>tkn task start echo-task\n</code></pre>"},{"location":"03_CICD/#tekton-pipeline-with-tasks","title":"Tekton Pipeline with Tasks","text":"<p> File: pipeline.yml</p> pipeline.yml<pre><code>apiVersion: tekton.dev/v1beta1\nkind: Pipeline\n  metadata:\n  name: sample-pipeline\nspec:\n  tasks:\n  - name: build-task\n    taskRef:\n      name: build-task\n  - name: deploy-task\n    taskRef:\n      name: deploy-task\n    runAfter:\n    - build-task\n</code></pre> Apply:<pre><code>kubectl apply -f pipeline.\n</code></pre>"},{"location":"03_CICD/#tekton-pipelinerun","title":"Tekton PipelineRun","text":"<p> File: pipelinerun.yml</p> pipeline.yml<pre><code>apiVersion: tekton.dev/v1beta1\nkind: PipelineRun\nmetadata:\n  name:sample-pipelinerun\nspec:\n  pipelineRef:\n    name: sample-pipeline\n</code></pre> Run the pipeline:<pre><code>kubectl apply -f pipelinerun.\n</code></pre> Check status:<pre><code>tkn pipelinerun describe sample-pipelinerun\n</code></pre>"},{"location":"03_CICD/#build-push-docker-image","title":"Build &amp; Push Docker Image","text":"<p> File: task-build-push.yml</p> task-build-push.yml:<pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: build-push-task\nspec:\n  steps:\n  - name: build-and-push\n    image: gcr.io/kaniko-project/executor:latest\n    script: | \n      #!/bin/sh /kaniko/executor --context=/workspace/source --destination=docker.io/myrepo/myapp:latest\n</code></pre>"},{"location":"03_CICD/#kubernetes-deployment-with-tekton","title":"Kubernetes Deployment with Tekton","text":"<p> File: task-k8s-deploy.yml</p> task-k8s-deploy.yml<pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: deploy-task\nspec:\n  steps:\n  - name: apply-manifest\n    image: bitnami/kubectl\n    script: |\n    #!/bin/sh\n    kubectl apply -f k8s/deployment\n</code></pre>"},{"location":"03_CICD/#tekton-with-terraform","title":"Tekton with Terraform","text":"<p> File: task-terraform.yml</p> <pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: terraform-task\nspec:\n  steps:\n  - name: terraform-apply\n    image: hashicorp/terraform:latest\n    script: | \n      #!/bin/sh\n      terraform init\n      terraform apply -auto-approve\n</code></pre>"},{"location":"03_CICD/#security-scanning-with-trivy_2","title":"Security Scanning with Trivy","text":"<p> File: task-trivy.yml</p> <pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: trivy-scan\nspec:\n  steps:\n  - name: run-trivy\n    image: aquasec/trivy:latest\n    script: |\n      #!/bin/sh\n      trivy image docker.io/myrepo/myapp:latest\n</code></pre>"},{"location":"03_CICD/#sonarqube-code-analysis_2","title":"SonarQube Code Analysis","text":"<p> File: task-sonarqube.yml</p> <pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: sonarqube-task\nspec:\n  steps:\n  - name: sonar-scan\n    image: maven:3.8.7\n    script: |\n      #!/bin/sh\n      mvn sonar:sonar -Dsonar.login=$SONAR_TOKEN\n</code></pre>"},{"location":"03_CICD/#notify-on-slack_1","title":"Notify on Slack","text":"<p> File: task-slack.yml</p> <pre><code>apiVersion: tekton.dev/v1beta1\nkind: Task\nmetadata:\n  name: slack-notify\nspec:\n  steps:\n  - name: send-slack-message\n    image: curlimages/curl:latest\n    script: |\n    #!/bin/sh\n    curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"Deployment completed successfully!\"}' $SLACK_WEBHOOK_URL\n</code></pre>"},{"location":"03_CICD/#circleci","title":"CircleCI","text":"<p>What is CircleCI?</p> <p>CircleCI is a cloud-based CI/CD tool that automates software testing and deployment. It provides seamless integration with GitHub, Bitbucket, and other version control systems, enabling automated builds, tests, and deployments.</p>"},{"location":"03_CICD/#installation","title":"Installation","text":"<ul> <li>Sign up at CircleCI</li> <li>Connect your repository (GitHub, Bitbucket)</li> <li>Configure the <code>.circleci/config.yml</code> file in your project</li> </ul>"},{"location":"03_CICD/#circleci-commands-pipeline-example","title":"CircleCI Commands (Pipeline Example)","text":"<ul> <li><code>circleci checkout</code> - Check out the repository to the current directory</li> <li><code>circleci sphere list</code> - List all the available workspaces in your account</li> <li><code>circleci config process</code> - Process the CircleCI config file and output the final configuration</li> <li><code>circleci step halt</code> - Halt the current job execution, useful in workflows</li> <li><code>circleci job follow &lt;job_id&gt;</code> - Stream the logs of a specific job in real-time</li> <li><code>circleci pipeline trigger &lt;pipeline_id&gt;</code> - Trigger a pipeline by its ID</li> <li><code>circleci pipeline list</code> - List all the pipelines for your project</li> <li><code>circleci project status &lt;project_slug&gt;</code> - View the status of the project</li> <li><code>circleci sphere create &lt;sphere_name&gt;</code> - Create a new workspace</li> <li><code>circleci sphere remove &lt;sphere_name&gt;</code> - Remove a workspace</li> <li><code>circleci sync</code> - Sync CircleCI configuration for a given project</li> <li><code>circleci orb publish &lt;orb_name&gt; &lt;version&gt; &lt;path_to_orb&gt;</code> - Publish a new version of an orb</li> </ul>"},{"location":"03_CICD/#circleci-pipeline-script-example","title":"CircleCI Pipeline Script Example","text":""},{"location":"03_CICD/#basic-circleci-pipeline-configuration","title":"Basic CircleCI Pipeline Configuration","text":"<p>version: 2.1 - Define the CircleCI version</p> <pre><code># Define jobs\njobs:\n  build:\n    docker:\n    - image: circleci/python:3.8 # Use a Python 3.8 Docker image\n    steps:\n    - checkout # Check out the code\n    - run:\n      name: Install dependencies\n      command: pip install -r requirements.txt\n    - run:\n      name: Run tests\n      command: pytest\n  deploy:\n    docker:\n    - image: circleci/python:3.8\n    steps:\n    - checkout\n    - run:\n      name: Deploy application\n      command: ./deploy.sh # Custom deploy script\n\n# Define workflows (Job execution order)\nworkflows:\n  version: 2\n  build_and_deploy:\n    jobs:\n    - build\n    - deploy:\n      requires:\n      - build # Ensure deployment happens after build succeeds\n</code></pre>"},{"location":"03_CICD/#advanced-circleci-features","title":"Advanced CircleCI Features","text":""},{"location":"03_CICD/#1-running-jobs-based-on-branches","title":"1. Running Jobs Based on Branches","text":"<pre><code>jobs:\n  deploy:\n    docker:\n    - image: circleci/python:3.8\n    steps:\n    - checkout\n    - run:\n      name: Deploy to Production\n      command: ./deploy_production.sh\nworkflows:\n  version: 2\n  deploy_to_production:\n    jobs:\n    - deploy:\n      filters:\n        branches:\n          only: main # Deploy only on the 'main' branch\n</code></pre>"},{"location":"03_CICD/#2-caching-dependencies-to-speed-up-builds","title":"2. Caching Dependencies to Speed Up Builds","text":"<pre><code>jobs:\n  build:\n    docker:\n    - image: circleci/python:3.8\n    steps:\n    - checkout\n    - restore_cache:\n      keys:\n      - v1-dependencies-{{ checksum \"requirements.txt\" }}\n    - run:\n      name: Install dependencies\n      command: pip install -r requirements.txt\n    - save_cache:\n      paths:\n      - ~/.cache/pip # Save pip cache\n      key: v1-dependencies-{{ checksum \"requirements.txt\" }}\n</code></pre>"},{"location":"03_CICD/#3-using-environment-variables-for-sensitive-data","title":"3. Using Environment Variables for Sensitive Data","text":"<pre><code>jobs:\n  deploy:\n    docker:\n    - image: circleci/python:3.8\n    steps:\n    - checkout\n    - run:\n      name: Deploy using environment variables\n      command: ./deploy.sh\n    environment:\n      API_KEY: $API_KEY # Use stored API keys\n</code></pre>"},{"location":"03_CICD/#4-running-jobs-conditionally-based-on-file-changes","title":"4. Running Jobs Conditionally Based on File Changes","text":"<pre><code>jobs:\n  deploy:\n    docker:\n    - image: circleci/python:3.8\n    steps:\n    - checkout\n    - run:\n      name: Deploy Application\n      command: ./deploy.sh\n    filters:\n      branches:\n        only: main\n    requires:\n    - build\n    when:\n      changes:\n      - Dockerfile # Only run deploy if the Dockerfile changes\n</code></pre>"},{"location":"03_CICD/#5-running-tests-in-parallel","title":"5. Running Tests in Parallel","text":"<pre><code>jobs:\n  test:\n    docker:\n    - image: circleci/python:3.8\n    parallelism: 4 # Run 4 test jobs in parallel\n    steps:\n    - checkout\n    - run:\n      name: Run tests\n      command: pytest\n</code></pre>"},{"location":"03_CICD/#6-using-multiple-docker-containers","title":"6. Using Multiple Docker Containers","text":"<pre><code>jobs:\n  build:\n    docker:\n    - image: circleci/python:3.8\n    - image: circleci/postgres:13 # Additional container for PostgreSQL\n      environment:\n        POSTGRES_USER: circleci\n    steps:\n    - checkout\n    - run:\n      name: Install dependencies\n      command: pip install -r requirements.txt\n    - run:\n      name: Run database migrations\n      command: python manage.py migrate\n    - run:\n      name: Run tests\n      command: pytest\n</code></pre>"},{"location":"03_CICD/#7-running-jobs-manually-manual-approvals","title":"7. Running Jobs Manually (Manual Approvals)","text":"<pre><code>jobs:\n  manual_deploy:\n  docker:\n  - image: circleci/python:3.8\n  steps:\n  - checkout\n  - run:\n    name: Deploy to Production\n    command: ./deploy.sh\n  when: manual # Only run when triggered manually\n</code></pre>"},{"location":"03_CICD/#8-sending-notifications-on-job-failure","title":"8. Sending Notifications on Job Failure","text":"<pre><code>workflows:\n  version: 2\n  notify_on_failure:\n    jobs:\n    - build\n    notification:\n      email:\n      - user@example.com # Send email notifications on failures\n</code></pre>"},{"location":"03_CICD/#9-running-multiple-jobs-in-parallel","title":"9. Running Multiple Jobs in Parallel","text":"<pre><code>workflows:\n  version: 2\n  build_and_deploy:\n    jobs:\n    - build\n    - deploy:\n      requires:\n      - build # Deploy after build completes\n      filters:\n        branches:\n          only: main\n</code></pre>"},{"location":"03_CICD/#argocd-gitops","title":"ArgoCD (GitOps)","text":"<p>What is ArgoCD?</p> <p>Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. It enables the deployment of applications from Git repositories to Kubernetes clusters, ensuring that the live state of the cluster matches the desired state defined in Git.</p>"},{"location":"03_CICD/#installation_1","title":"Installation","text":"<ol> <li>Install Argo CD CLI </li> </ol>"},{"location":"03_CICD/#macos","title":"macOS:","text":"<pre><code>brew install argocd\n</code></pre>"},{"location":"03_CICD/#linux","title":"Linux:","text":"<pre><code>curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/download/v2.5.4/argocd-linux-amd64 chmod +x /usr/local/bin/argocd\n</code></pre>"},{"location":"03_CICD/#install-argo-cd-on-kubernetes","title":"Install Argo CD on Kubernetes:","text":"<pre><code>kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.\n</code></pre>"},{"location":"03_CICD/#accessing-the-argo-cd-ui","title":"Accessing the Argo CD UI","text":"<ul> <li>Access the Argo CD API Server (Local Port Forwarding)</li> </ul> <pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre>"},{"location":"03_CICD/#login-to-the-argo-cd-ui","title":"Login to the Argo CD UI","text":"<ul> <li>Initial Password (default is admin and the password is the name of the pod running Argo CD):</li> </ul> <pre><code>kubectl get pods -n argocd\nkubectl logs &lt;argocd-server-pod-name&gt; -n argocd | grep \"admin\"\n</code></pre>"},{"location":"03_CICD/#argo-cd-commands","title":"Argo CD Commands","text":"<ul> <li>Login to Argo CD via CLI</li> </ul> <pre><code>argocd login &lt;ARGOCD_SERVER&gt; --username admin --password &lt;password&gt;\n</code></pre>"},{"location":"03_CICD/#view-the-current-applications","title":"View the current applications","text":"<pre><code>argocd app list\n</code></pre>"},{"location":"03_CICD/#1-sync-an-application","title":"1. Sync an Application","text":"<ul> <li>Syncs the application with the desired state from the Git repository.</li> </ul> <pre><code>argocd app sync &lt;app-name&gt;\n</code></pre> <ul> <li>Get Application Status</li> </ul> <pre><code>argocd app get &lt;app-name&gt;\n</code></pre>"},{"location":"03_CICD/#2-create-an-application","title":"2. Create an Application","text":"<ul> <li>Creates an app in Argo CD by specifying the Git repository, target namespace, and project.</li> </ul> <pre><code>argocd app create &lt;app-name&gt; \\\n--repo &lt;git-repository-url&gt; \\\n--path &lt;path-to-k8s-manifests&gt; \\\n--dest-server https://kubernetes.default.svc \\\n--dest-namespace &lt;namespace&gt;\n</code></pre> <ul> <li>Delete an Application</li> </ul> <pre><code>argocd app delete &lt;app-name&gt;\n</code></pre>"},{"location":"03_CICD/#3-refresh-application","title":"3. Refresh Application","text":"<ul> <li>Refreshes the application state from the Git repository.</li> </ul> <pre><code>argocd app refresh &lt;app-name&gt;\n</code></pre>"},{"location":"03_CICD/#application-resources-and-syncing","title":"Application Resources and Syncing","text":"<ul> <li>Sync Status Check</li> </ul> <pre><code>argocd app sync &lt;app-name&gt; --prune\n</code></pre>"},{"location":"03_CICD/#1-compare-with-live","title":"1. Compare with Live","text":"<ul> <li>Compare the live state of an application with the Git repository. <pre><code>argocd app diff &lt;app-name&gt;\n</code></pre></li> </ul>"},{"location":"03_CICD/#2-manual-sync","title":"2. Manual Sync","text":"<ul> <li>Manually sync the application state.</li> </ul> <pre><code>argocd app sync &lt;app-name&gt; --force\n</code></pre>"},{"location":"03_CICD/#managing-projects","title":"Managing Projects","text":"<ul> <li>Create a Project</li> </ul> <pre><code>argocd proj create &lt;project-name&gt; \\\n- --description \"&lt;description&gt;\" \\\n- --dest-namespace &lt;namespace&gt; \\\n- --dest-server &lt;server-url&gt;\n</code></pre> <ul> <li>List Projects</li> </ul> <pre><code>argocd proj list\n</code></pre> <ul> <li>Add a Git Repo to a Project</li> </ul> <pre><code>argocd proj add-repo &lt;project-name&gt; --repo &lt;git-repository-url&gt;\n</code></pre>"},{"location":"03_CICD/#gitops-and-source-repositories","title":"GitOps and Source Repositories","text":"<ul> <li>Add a Git Repository</li> </ul> <pre><code>argocd repo add &lt;git-repo-url&gt; --username &lt;username&gt; --password &lt;password&gt; --type git\n</code></pre> <ul> <li>List Repositories</li> </ul> <pre><code>argocd repo list\n</code></pre> <ul> <li>Remove a Git Repository</li> </ul> <pre><code>argocd repo rm &lt;git-repo-url&gt;\n</code></pre>"},{"location":"03_CICD/#notifications-and-alerts","title":"Notifications and Alerts","text":""},{"location":"03_CICD/#1-enable-notifications","title":"1. Enable Notifications","text":"<ul> <li>Install Argo CD Notifications to integrate with Slack, email, etc.</li> </ul> <pre><code>kubectl apply -k github.com/argoproj-labs/argocd-notifications/manifests/install\n</code></pre>"},{"location":"03_CICD/#2-set-up-notification-settings","title":"2. Set Up Notification Settings","text":"<ul> <li>Configure notification settings in the Argo CD UI.</li> </ul>"},{"location":"03_CICD/#application-health-and-troubleshooting","title":"Application Health and Troubleshooting","text":"<ul> <li>Check Application Health</li> </ul> <pre><code>argocd app health &lt;app-name&gt;\n</code></pre>"},{"location":"03_CICD/#1-check-logs","title":"1. Check Logs","text":"<ul> <li>View logs for troubleshooting.</li> </ul> <pre><code>kubectl logs &lt;pod-name&gt; -n argocd\n</code></pre>"},{"location":"03_CICD/#2-app-rollback","title":"2. App Rollback","text":"<ul> <li>Rollback to a previous revision of an application.</li> </ul> <pre><code>argocd app rollback &lt;app-name&gt; &lt;revision&gt;\n</code></pre>"},{"location":"03_CICD/#argo-cd-in-cicd-pipelines","title":"Argo CD in CI/CD Pipelines","text":""},{"location":"03_CICD/#integrate-with-cicd","title":"Integrate with CI/CD","text":"<ul> <li>Add Argo CD commands in Jenkins, GitLab CI, or GitHub Actions pipelines to automatically deploy updates to Kubernetes based on changes in Git repositories.</li> </ul>"},{"location":"03_CICD/#best-practices","title":"Best Practices","text":"<ul> <li>Declarative GitOps: Keep all manifests in Git, and let Argo CD automatically synchronize and deploy them.</li> <li>Namespaces and Projects: Use projects to group applications and limit resource access across environments.</li> <li>RBAC: Use Role-Based Access Control (RBAC) to secure Argo CD's access and resource usage.</li> </ul>"},{"location":"03_CICD/#flux-cd","title":"Flux CD","text":"<p>What is FluxCD?</p> <p>Flux CD is a GitOps tool for Kubernetes that automates deployment, updates, and rollback of applications using Git as the source of truth.</p>"},{"location":"03_CICD/#installation-install-flux-cli","title":"Installation Install Flux CLI","text":"<pre><code>curl -s https://fluxcd.io/install.sh | sudo\n</code></pre>"},{"location":"03_CICD/#verify-installation","title":"Verify Installation","text":"<pre><code>flux --version\n</code></pre>"},{"location":"03_CICD/#bootstrap-flux-in-a-cluster","title":"Bootstrap Flux in a Cluster","text":"<pre><code>flux bootstrap github \\\n --owner=&lt;GITHUB_USER_OR_ORG&gt; \\\n --repository=&lt;REPO_NAME&gt; \\\n --branch=main \\\n --path=clusters/my-cluster \\\n --personal\n</code></pre>"},{"location":"03_CICD/#key-flux-cd-commands","title":"Key Flux CD Commands","text":""},{"location":"03_CICD/#general-commands","title":"General Commands","text":"<ul> <li><code>fluxcheck</code> - CheckFluxinstallation</li> <li><code>flux install</code> - Install Flux components in a cluster</li> <li><code>flux bootstrap github</code> - SetupFluxinGitHubrepository</li> <li><code>flux version</code> - Show Flux CLI version</li> </ul>"},{"location":"03_CICD/#managing-deployments","title":"Managing Deployments","text":"<ul> <li><code>flux get sources git</code> - List Git sources</li> <li><code>flux get kustomizations</code> - List kustomizations</li> <li><code>flux reconcile kustomization &lt;name&gt;</code> - Force sync a kustomization</li> <li><code>flux suspend kustomization &lt;name&gt;</code> - Pause updates for a kustomization</li> <li><code>flux resume kustomization &lt;name&gt;</code> - Resume updates for a kustomization</li> </ul>"},{"location":"03_CICD/#git-repository-management","title":"Git Repository Management","text":"<pre><code>flux create source git my-app \\\n--url=https://github.com/my-org/my-app \\\n--branch=main \\\n--interval=1m\n</code></pre> <pre><code>flux create kustomization my-app \\\n--source=my-app \\\n--path=\"./deploy\" \\\n--prune=true \\\n--interval=5m\n</code></pre>"},{"location":"03_CICD/#helm-chart-management","title":"Helm Chart Management","text":"<pre><code>flux create source helm my-chart \\\n--url=https://charts.bitnami.com/bitnami \\\n--interval=1h\n</code></pre> <pre><code>flux create helmrelease my-app \\\n--source=my-chart \\\n--chart=nginx \\\n--values=./values. \\\n--interval=5m\n</code></pre>"},{"location":"03_CICD/#monitoring-and-debugging","title":"Monitoring and Debugging","text":"<ul> <li><code>fluxlogs</code> - View Flux logs</li> <li><code>flux get sources helm</code> - List Helm sources</li> <li><code>flux get helm releases</code> - List deployed Helm releases</li> <li><code>flux trace kustomization &lt;name&gt;</code> - Trace errors in a kustomization</li> <li><code>flux suspend source git &lt;name&gt;</code> - Suspend Git syncing</li> <li><code>flux resume source git &lt;name&gt;</code> - Resume Git syncing</li> </ul>"},{"location":"03_CICD/#uninstall-flux","title":"Uninstall Flux","text":"<pre><code>flux uninstall --silent\n</code></pre>"},{"location":"04_IaC/","title":"Infrastructure as Code (IaC)","text":""},{"location":"04_IaC/#terraform","title":"Terraform","text":""},{"location":"04_IaC/#terraform-installation-on-ubuntudebian","title":"Terraform Installation on Ubuntu/Debian:","text":"<ul> <li>Commands:</li> </ul> <pre><code>wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\n\necho \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\n\nsudo apt update &amp;&amp; sudo apt install terraform\n</code></pre>"},{"location":"04_IaC/#aws-cli-installation-on-ubuntu","title":"AWS CLI Installation on Ubuntu:","text":"<ul> <li>Commands:</li> </ul> <pre><code>curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n\nunzip awscliv2.zip\n\nsudo ./aws/install\n</code></pre>"},{"location":"04_IaC/#kubectl-installation-on-ubuntu","title":"Kubectl Installation on Ubuntu:","text":"<ul> <li>Commands:</li> </ul> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre>"},{"location":"04_IaC/#step-by-step-configuration-guide-with-aws-ec2-instance","title":"Step-by-Step Configuration Guide with AWS EC2 Instance","text":""},{"location":"04_IaC/#1-main-terraform-configuration","title":"1. Main Terraform Configuration:","text":"<p> main.tf</p> <ul> <li>Terraform Configuration Example:</li> </ul> <pre><code>terraform { \n  required_providers { \n  aws = {\n    source = \"hashicorp/aws\" \n    version = \"~&gt; 4.16\"\n    }\n  }\n  required_version = \"&gt;= 1.2.0\"\n}\n\nprovider \"aws\" { \n  region = \"us-west-2\"\n}\n\nresource \"aws_instance\" \"app_server\" { \n  ami = \"ami-08d70e59c07c61a3a\" \n  instance_type = \"t2.micro\"\n  tags = {\n    Name = var.instance_name\n  }\n}\n</code></pre>"},{"location":"04_IaC/#2-input-variables","title":"2. Input Variables:","text":"<p> variables.tf</p> <ul> <li>Example: hcl</li> </ul> <pre><code>variable \"instance_name\" {\n  description = \"Value of the Name tag for the EC2 instance\"\n  type = string\n  default = \"ExampleAppServerInstance\" }\n</code></pre>"},{"location":"04_IaC/#3-output-values","title":"3. Output Values:","text":"<p> outputs.tf:</p> <ul> <li>Example: hcl</li> </ul> <pre><code>output \"instance_id\" {\n  description = \"ID of the EC2 instance\"\n  value = aws_instance.app_server.id\n}\n\noutput \"instance_public_ip\" {\n  description = \"Public IP address of the EC2 instance\" \n  value = aws_instance.app_server.public_ip\n}\n</code></pre>"},{"location":"04_IaC/#4-running-the-configuration","title":"4. Running the Configuration:","text":"<ul> <li>Initialize Terraform:</li> </ul> <pre><code>terraform init\n</code></pre> <ul> <li>Apply the Configuration:</li> </ul> <pre><code>terraform apply\n</code></pre> <p>Note</p> <p>Confirm by typing yes when prompted.</p> <ul> <li>Inspect Output Values:</li> </ul> <pre><code>terraform output\n</code></pre> <ul> <li>Destroy the Infrastructure:</li> </ul> <pre><code>terraform destroy\n</code></pre>"},{"location":"04_IaC/#terraform-advanced-configuration-use-cases","title":"Terraform Advanced Configuration Use Cases","text":""},{"location":"04_IaC/#1-provider-configuration","title":"1. Provider Configuration:","text":"<pre><code>provider \"aws\" { \n  region = \"us-west-2\"\n}\n</code></pre>"},{"location":"04_IaC/#2-resource-creation","title":"2. Resource Creation:","text":"<pre><code>resource \"aws_instance\" \"example\" { \n  ami = \"ami-0c55b159cbfafe1f0\" \n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"ExampleInstance\"\n  }\n}\n</code></pre>"},{"location":"04_IaC/#3-variable-management","title":"3. Variable Management:","text":"<pre><code>variable \"region\" { \n  default = \"us-west-2\"\n}\n\nprovider \"aws\" { \n  region = var.region\n}\n</code></pre>"},{"location":"04_IaC/#4-state-management","title":"4. State Management:","text":"<ul> <li>Example for using remote state in S3:</li> </ul> <pre><code>terraform {\n  backend \"s3\" {\n    bucket = \"my-tfstate-bucket\"\n    key = \"terraform/state\"\n    region = \"us-west-2\"\n    encrypt = true\n    dynamodb_table = \"terraform-locks\"\n  }\n}\n</code></pre>"},{"location":"04_IaC/#5-modules","title":"5. Modules:","text":"<pre><code>module \"vpc\" {\n    source = \"terraform-aws-modules/vpc/aws\"\n    name = \"my-vpc\"\n    cidr = \"10.0.0.0/16\"\n    azs = [\"us-west-2a\", \"us-west-2b\"]\n    public_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n    private_subnets = [\"10.0.3.0/24\", \"10.0.4.0/24\"] }\n</code></pre>"},{"location":"04_IaC/#terraform-commands-cheat-sheet","title":"Terraform Commands Cheat Sheet","text":"<ul> <li><code>terraform init</code> - Initializes the Terraform configuration.</li> <li><code>terraform fmt</code> - Formats configuration files.</li> <li><code>terraform validate</code> - Validates the configuration files.</li> <li><code>terraform plan</code> - Previews changes to be applied.</li> <li><code>terraform apply</code> - Applies the changes to reach the desired state.</li> <li><code>terraform destroy</code> - Destroys the infrastructure and removes it from the state.</li> <li><code>terraform show</code> - Displays the current state of resources.</li> <li><code>terraform state list</code> - Lists resources in the current state.</li> <li><code>terraform taint &lt;resource&gt;</code> - Marks a resource for recreation.</li> <li><code>terraform import &lt;resource&gt; &lt;resource_id&gt;</code> - Imports existing resources into Terraform.</li> <li><code>terraform providers</code> - Lists the providers used in the configuration.</li> </ul>"},{"location":"04_IaC/#terraform-best-practices","title":"Terraform Best Practices","text":"<ul> <li>Use Version Control to manage your Terraform code.</li> <li>Break your code into Modules for reusability.</li> <li>Use Remote State (e.g., AWS S3, Terraform Cloud) to store state files.</li> <li>Always run terraform plan before terraform apply.</li> <li>Use terraform fmt &amp; terraform validate to ensure code correctness.</li> <li>Avoid hardcoding secrets; use environment variables or secret management tools.</li> <li>Keep configurations modular and well-documented.</li> </ul>"},{"location":"04_IaC/#cloudformation-stacks-templates","title":"CloudFormation (stacks, templates)","text":""},{"location":"04_IaC/#1-cloudformation-concepts","title":"1. CloudFormation Concepts","text":"<ul> <li>Stack - A group of AWS resources defined in a template.</li> <li>Template - /JSON file defining resources and configurations.</li> <li>StackSet - Deploys stacks across multiple accounts and regions.</li> <li>Change Set - Previews updates before applying changes.</li> <li>Rollback - Automatic stack rollback if an error occurs.</li> <li>Drift Detection - Identifies manual changes made outside CloudFormation.</li> </ul>"},{"location":"04_IaC/#2-cloudformation-template-example","title":"2. CloudFormation Template Example","text":"<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nDescription: \"Basic AWS CloudFormation Example\"\nResources:\n  MyBucket:\n    Type: \"AWS::S3::Bucket\"\n  MyEC2Instance:\n    Type: \"AWS::EC2::Instance\"\n    Properties:\n      InstanceType: \"t2.micro\"\n      ImageId: \"ami-0abcdef1234567890\"\nOutputs:\n  InstanceID:\n    Description: \"The Instance ID\"\n    Value: !Ref MyEC2Instance\n</code></pre>"},{"location":"04_IaC/#3-cloudformation-cli-commands","title":"3. CloudFormation CLI Commands","text":"<ul> <li>Stack Operations</li> </ul> <p><pre><code>aws cloudformation create-stack --stack-name my-stack --template-body file://template\n</code></pre> <pre><code>aws cloudformation update-stack --stack-name my-stack --template-body file://template\n</code></pre> <pre><code>aws cloudformation delete-stack --stack-name my-stack\n</code></pre></p> <ul> <li>Viewing Stack Details</li> </ul> <p><pre><code>aws cloudformation describe-stacks --stack-name my-stack\n</code></pre> <pre><code>aws cloudformation list-stack-resources --stack-name my-stack\n</code></pre> <pre><code>aws cloudformation describe-stack-events --stack-name my-stack\n</code></pre></p> <ul> <li>Change Set (Preview Changes)</li> </ul> <p><pre><code>aws cloudformation create-change-set --stack-name my-stack --template-body file://template. --change-set-name my-change-set\n</code></pre> <pre><code>aws cloudformation describe-change-set --stack-name my-stack --change-set-name my-change-set\n</code></pre> <pre><code>aws cloudformation execute-change-set --stack-name my-stack --change-set-name my-change-set\n</code></pre></p> <ul> <li>Drift Detection</li> </ul> <p><pre><code>aws cloudformation detect-stack-drift --stack-name my-stack\n</code></pre> <pre><code>aws cloudformation describe-stack-drift-detection-status--stack-name my-stack\n</code></pre></p>"},{"location":"04_IaC/#4-cloudformation-best-practices","title":"4. CloudFormation Best Practices","text":"<ul> <li>Use Parameters for Flexibility</li> <li>Define parameters to make templates reusable:</li> </ul> <pre><code>Parameters:\n  InstanceType:\n    Type: String\n    Default: \"t2.micro\"\n    AllowedValues: [\"t2.micro\", \"t2.small\", \"t2.medium\"]\n</code></pre> <ul> <li>Use Mappings for Region-Specific Configurations</li> </ul> <pre><code>Mappings:\n  RegionMap:\n    us-east-1:\n      AMI: \"ami-12345678\"\n    us-west-1:\n      AMI: \"ami-87654321\"\n</code></pre> <ul> <li>Use Conditions for Conditional Resource Creation</li> </ul> <pre><code>Conditions:\n  IsProd: !Equals [!Ref \"Environment\", \"prod\"]\nResources:\n  MyDatabase:\n    Type: \"AWS::RDS::DBInstance\"\n    Condition: IsProd\n</code></pre> <ul> <li>Use Outputs to Export Values</li> </ul> <pre><code>Outputs:\n  S3BucketName:\n    Description: \"Name of the created S3 bucket\"\n    Value: !Ref MyBucket\n    Export:\n      Name: MyBucketExport\n</code></pre> <ul> <li>Use Nested Stacks for Large Templates</li> </ul> <p>Note</p> <p>Break large stacks into smaller, reusable nested stacks.</p>"},{"location":"04_IaC/#5-cloudformation-troubleshooting","title":"5. CloudFormation Troubleshooting","text":"<ul> <li>Stack creation fails - Check describe-stack-events for error details.</li> <li>Parameter validation error - Ensure correct parameter types and values.</li> <li>Rollback triggered - Check logs and describe-stack-events to debug.</li> <li>Resources stuck in DELETE_FAILED - Manually delete dependencies before retrying.</li> <li>Template validation error - Use aws cloudformation validate-template --template-body file://template to validate the template.</li> </ul>"},{"location":"05_Containerization_Orchestration/","title":"Containerization","text":""},{"location":"05_Containerization_Orchestration/#docker-build-run-volumes-networks-compose","title":"Docker (build, run, volumes, networks, compose)","text":""},{"location":"05_Containerization_Orchestration/#basic-commands","title":"Basic Commands","text":"<ul> <li><code>docker ps</code> - List running containers</li> <li><code>docker ps -a</code> - List all containers</li> <li><code>docker info</code> - Get Docker configuration</li> <li><code>docker version</code> - Get Docker version</li> </ul>"},{"location":"05_Containerization_Orchestration/#image-commands","title":"Image Commands","text":"<ul> <li><code>docker build -t &lt;image&gt;:&lt;tag&gt; .</code> - Build an image from a Dockerfile</li> <li><code>docker login &lt;repository&gt;</code> - Authenticate with a remote repository</li> <li><code>docker push &lt;image&gt;:&lt;tag&gt;</code> - Push an image to a repository</li> <li><code>docker pull &lt;image&gt;:&lt;tag&gt;</code> -Pull an image from a repository</li> <li><code>docker images</code> - List locally available images</li> <li><code>docker create &lt;image&gt;:&lt;tag&gt;</code> - Create a container from an image</li> <li><code>docker rmi &lt;image&gt;</code> - Delete an image</li> <li><code>docker save &lt;image&gt;</code> - Save an image as a tarball</li> <li><code>docker search &lt;image&gt;</code> - Search for an image in a repository</li> </ul>"},{"location":"05_Containerization_Orchestration/#container-commands","title":"Container Commands","text":"<ul> <li><code>docker inspect &lt;container&gt;</code> - View container details</li> <li><code>docker stats &lt;container&gt;</code> - Display live resource usage</li> <li><code>docker logs &lt;container&gt;</code> - View container logs</li> <li><code>docker run &lt;container&gt;</code> - Run a container</li> <li><code>docker kill &lt;container&gt;</code> - Force stop a running container</li> <li><code>docker start &lt;container&gt;</code> - Start a stopped container</li> <li><code>docker stop &lt;container&gt;</code> - Gracefully stop a running container</li> <li><code>docker restart &lt;container&gt;</code> - Restart a container</li> <li><code>docker rm &lt;container&gt;</code> - Remove a container</li> <li><code>docker port &lt;container&gt;</code> - Show port mappings</li> <li><code>docker pause &lt;container&gt;</code> - Suspend container processes</li> <li><code>docker unpause &lt;container&gt;</code> - Resume container processes</li> </ul>"},{"location":"05_Containerization_Orchestration/#network-commands","title":"Network Commands","text":"<ul> <li><code>docker network ls</code> - List networks</li> <li><code>docker network inspect &lt;network&gt;</code> - View network details</li> <li><code>docker network create &lt;network&gt;</code> - Create a network</li> <li><code>docker network rm &lt;network&gt;</code> - Delete a network</li> <li><code>docker network connect &lt;network&gt; &lt;container&gt;</code> - Connect a container to a network</li> <li><code>docker network disconnect &lt;network&gt; &lt;container&gt;</code> - Disconnect a container from a network</li> </ul>"},{"location":"05_Containerization_Orchestration/#volume-commands","title":"Volume Commands","text":"<ul> <li><code>docker volume ls</code> - List volumes</li> <li><code>docker volume inspect &lt;volume&gt;</code> - View volume details</li> <li><code>docker volume create &lt;volume&gt;</code> - Create a volume</li> <li><code>docker volume rm &lt;volume&gt;</code> - Delete a volume</li> </ul>"},{"location":"05_Containerization_Orchestration/#copy-execution-commands","title":"Copy &amp; Execution Commands","text":"<ul> <li><code>docker cp &lt;container&gt;:&lt;source_path&gt; &lt;dest_path&gt;</code> - Copy from container to host</li> <li><code>docker cp &lt;source_path&gt; &lt;container&gt;:&lt;dest_path&gt;</code> - Copy from host to container</li> <li><code>docker exec -ti &lt;container&gt; &lt;command&gt;</code> - Run a command inside a running container</li> </ul>"},{"location":"05_Containerization_Orchestration/#dockerfile-commands","title":"Dockerfile Commands","text":"<ul> <li><code>FROM &lt;image&gt;:&lt;tag&gt;</code> - Base image for the container</li> <li><code>COPY &lt;source&gt; &lt;destination&gt;</code> - Copy files/directories</li> <li><code>ADD &lt;source&gt; &lt;destination&gt;</code> - Copy files &amp; extract archives</li> <li><code>CMD [\"command\", \"arg1\"]</code> - Default command executed in container</li> <li><code>ENTRYPOINT [\"command\", \"arg1\"]</code> - Container's main command</li> <li><code>LABEL key=value</code> - Add metadata</li> <li><code>ENV key=value</code> - Set environment variables</li> <li><code>EXPOSE &lt;port&gt;</code> - Declare exposed ports</li> <li><code>RUN &lt;command&gt;</code> - Run command during image build</li> <li><code>WORKDIR &lt;path&gt;</code> - Set working directory</li> </ul>"},{"location":"05_Containerization_Orchestration/#system-diagnostics","title":"System &amp; Diagnostics","text":"<ul> <li><code>docker system df</code> - Show Docker disk usage</li> <li><code>docker system info</code> - Display system details</li> <li><code>docker diff &lt;container&gt;</code> - Show modified files in a container</li> <li><code>docker top &lt;container&gt;</code> - Show running processes inside a container</li> </ul>"},{"location":"05_Containerization_Orchestration/#general-best-practices-for-dockerfiles","title":"General Best Practices for Dockerfiles:","text":"<ol> <li>Minimize Layers - Combine RUN, COPY, and ADD commands to reduce layers and image size.</li> <li>Use Specific Versions - Always specify versions for base images (e.g., FROM python:3.9-slim).</li> <li>.dockerignore - Use .dockerignore to exclude unnecessary files (e.g., .git, node_modules).</li> <li>Multi-Stage Builds - Separate the build process and runtime environment to optimize image size.</li> <li>Non-root User - Always create and use a non-root user for security.</li> <li>Leverage Docker Cache - Copy dependencies first, so Docker can cache them for faster builds.</li> </ol>"},{"location":"05_Containerization_Orchestration/#dockerfile-examples-with-different-programming-language","title":"Dockerfile Examples with different Programming language","text":""},{"location":"05_Containerization_Orchestration/#1-python-flaskdjango","title":"1. Python (Flask/Django)","text":"<pre><code>FROM python:3.9-slim AS base\n\nWORKDIR /app\n\n# Install dependencies\n\nCOPY requirements.txt .\n\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the app files\n\nCOPY . .\n\nEXPOSE 5000\n\n# Run as a non-root user\n\nRUN useradd -m appuser\n\nUSER appuser\n\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>Best Practices</p> <ul> <li>--no-cache-dir to prevent caching Python packages.</li> <li>Copy requirements.txt first to leverage Docker cache.</li> <li>Use a non-root user (appuser).</li> </ul>"},{"location":"05_Containerization_Orchestration/#2-nodejs","title":"2. Node.js","text":"<pre><code>FROM node:16-alpine AS build\n\nWORKDIR /app\n\n# Install dependencies\n\nCOPY package.json package-lock.json ./\n\nRUN npm install --production\n\n# Copy the app code\n\nCOPY . .\n\nEXPOSE 3000\n\n# Run as a non-root user\n\nRUN addgroup --system app &amp;&amp; adduser --system --ingroup app app\n\nUSER app\n\nCMD [\"node\", \"app.js\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Use --production to avoid installing devDependencies.</li> <li>Multi-stage builds for optimized images.</li> <li>Use a non-root user (app).</li> </ul>"},{"location":"05_Containerization_Orchestration/#3-java-spring-boot","title":"3. Java (Spring Boot)","text":"<pre><code>FROM openjdk:17-jdk-slim AS build\n\nWORKDIR /app\n\n# Copy the jar file\n\nCOPY target/myapp.jar myapp.jar\n\nEXPOSE 8080\n\n# Run as a non-root user\n\nRUN addgroup --system app &amp;&amp; adduser --system --ingroup app app\n\nUSER app\n\nCMD [\"java\", \"-jar\", \"myapp.jar\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Multi-stage builds for separating build and runtime.</li> <li>Use -jdk-slim for smaller images.</li> <li>Non-root user (app).</li> </ul>"},{"location":"05_Containerization_Orchestration/#4-ruby-on-rails","title":"4. Ruby on Rails","text":"<pre><code>FROM ruby:3.0-alpine\n\n# Install dependencies\n\nRUN apk add --no-cache build-base\n\nWORKDIR /app\n\n# Install Ruby gems\n\nCOPY Gemfile Gemfile.lock ./\n\nRUN bundle install --without development test\n\n# Copy the app code\n\nCOPY . .\n\nEXPOSE 3000\n\n# Run as a non-root user\n\nRUN addgroup --system app &amp;&amp; adduser --system --ingroup app app\n\nUSER app\n\nCMD [\"rails\", \"server\", \"-b\", \"0.0.0.0\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Install dependencies in one RUN statement.</li> <li>Avoid devDependencies in production.</li> <li>Use non-root user (app).</li> </ul>"},{"location":"05_Containerization_Orchestration/#5-go","title":"5. Go","text":"<pre><code>FROM golang:1.16-alpine AS build\n\nWORKDIR /app\n\n# Copy and install dependencies\n\nCOPY go.mod go.sum ./\n\nRUN go mod tidy\n\n# Copy the app code and build\n\nCOPY . .\n\nRUN go build -o myapp .\n\n# Use a minimal base image for running\n\nFROM alpine:latest\n\nWORKDIR /app\n\n# Copy the binary\n\nCOPY --from=build /app/myapp .\n\nEXPOSE 8080\n\n# Run as a non-root user\n\nRUN addgroup --system app &amp;&amp; adduser --system --ingroup app app\n\nUSER app\n\nCMD [\"./myapp\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Multi-stage build to separate build and runtime.</li> <li>alpine for smaller runtime images.</li> <li>Non-root user (app).</li> </ul>"},{"location":"05_Containerization_Orchestration/#6-angular-frontend","title":"6. Angular (Frontend)","text":"<pre><code># Build stage\n\nFROM node:16 AS build\n\nWORKDIR /app\n\nCOPY . .\n\nRUN npm install\n\nRUN npm run build --prod\n\n# Production stage using nginx\n\nFROM nginx:alpine\n\n## # Copy build artifacts from the build stage\n\nCOPY --from=build /app/dist/ /usr/share/nginx/html\n\nEXPOSE 80\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Multi-stage build: separate build and serving phases.</li> <li>Use nginx:alpine for a minimal serving environment.</li> <li>Copy only production build files.</li> </ul>"},{"location":"05_Containerization_Orchestration/#7-php-laravel","title":"7. PHP (Laravel)","text":"<pre><code>FROM php:8.0-fpm\n\n# Install dependencies\n\nRUN apt-get update &amp;&amp; apt-get install -y libzip-dev &amp;&amp; docker-php-ext-install zip\n\nWORKDIR /var/www/html\n\n# Install Composer\n\nCOPY --from=composer:latest /usr/bin/composer /usr/bin/composer\n\n# Install PHP dependencies\n\nCOPY composer.json composer.lock ./\n\nRUN composer install --no-dev --no-scripts\n\n# Copy application files\n\nCOPY . .\n\nEXPOSE 9000\n\n# Run as a non-root user\n\nRUN useradd -ms /bin/ appuser\n\nUSER appuser\n\nCMD [\"php-fpm\"]\n</code></pre> <p>Best Practices</p> <ul> <li>Use Composer for PHP dependency management.</li> <li>Avoid dev dependencies in production (--no-dev).</li> <li>Run PHP-FPM as a non-root user.</li> </ul>"},{"location":"05_Containerization_Orchestration/#8-best-practices-for-security-and-optimization","title":"8. Best Practices for Security and Optimization:","text":"<ul> <li>Minimize Image Size - Use smaller base images like alpine or slim, and multi-stage builds to reduce the final image size.</li> <li>Use a Non-root User - Always run applications as a non-root user to enhance security.</li> <li>Pin Versions - Avoid using the latest tag for images. Use specific versions to ensure predictable builds.</li> <li>Leverage Caching - Place frequently changing files (e.g., source code) after dependencies to take advantage of Docker's build cache.</li> <li>Avoid ADD Unless Necessary - Use COPY instead of ADD unless you need to fetch files from a URL or extract archives.</li> </ul>"},{"location":"05_Containerization_Orchestration/#docker-compose-commands","title":"Docker Compose Commands","text":"<ul> <li><code>docker-compose up</code> - Start all services in the background</li> <li><code>docker-compose up -d</code> - Start services in detached mode</li> <li><code>docker-compose up --build</code> - Rebuild images before starting services</li> <li><code>docker-compose down</code> - Stop and remove containers, networks, volumes</li> <li><code>docker-compose down -v</code> - Remove volumes along with containers</li> <li><code>docker-compose stop</code> - Stop running containers without removing them</li> <li><code>docker-compose start</code> - Restart stopped containers</li> <li><code>docker-compose restart</code> - Restart all containers</li> <li><code>docker-compose ps</code> - List running containers</li> <li><code>docker-compose logs</code> - Show logs from containers</li> <li><code>docker-compose logs -f</code> - Follow container logs</li> <li><code>docker-compose exec &lt;service&gt; &lt;cmd&gt;</code> - Execute a command inside a running container</li> <li><code>docker-compose run &lt;service&gt; &lt;cmd&gt;</code> - Run a one-time command inside a service</li> <li><code>docker-compose config</code> - Validate and view merged configuration</li> <li><code>docker-compose version</code> - Show Docker Compose version</li> </ul>"},{"location":"05_Containerization_Orchestration/#docker-compose-docker-composeyml-example","title":"Docker Compose (docker-compose.yml) Example","text":"<pre><code>version: '3.8'\nservices:\n  app:\n    image: my-app:latest\n    container_name: my_app\n    ports:\n    - \"8080:80\"\n    environment:\n    - NODE_ENV=production\n    volumes:\n    - ./app:/usr/src/app\n    depends_on:\n    - db\n  db:\n    image: postgres:latest\n    container_name: my_db\n    restart: always\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n      POSTGRES_DB: mydatabase\n    ports:\n    - \"5432:5432\"\n    volumes:\n    - pgdata:/var/lib/postgresql/data\n    volumes:\n      pgdata:\n</code></pre>"},{"location":"05_Containerization_Orchestration/#key-directives","title":"Key Directives","text":"<ul> <li>version - Defines the Compose file format version</li> <li>services - Defines all application services</li> <li>image - Specifies the container image</li> <li>container_name - Names the container explicitly</li> <li>build - Specifies build context for Dockerfile</li> <li>ports - Maps container ports to host</li> <li>volumes - Mounts persistent storage</li> <li>environment - Passes environment variables</li> <li>depends_on - Specifies dependencies between services</li> <li>restart - Defines restart policy (always, unless-stopped, on-failure)</li> </ul>"},{"location":"05_Containerization_Orchestration/#general-docker-compose-structure","title":"General Docker Compose Structure","text":"<pre><code>version: '3'\nservices:\n  service_name:\n    image: &lt;image-name&gt; # The image to use\n    build: . # Path to the Dockerfile if you need to build the image\n    container_name: &lt;name&gt; # Container name (optional)\n    ports:\n    - \"&lt;host-port&gt;:&lt;container-port&gt;\" # Exposing ports\n    environment:\n    - VAR_NAME=value # Set environment variables\n    volumes:\n    - &lt;host-path&gt;:&lt;container-path&gt; # Mount volumes for persistent data\n    depends_on: - other_service # Define service dependencies\n    networks: - &lt;network-name&gt; # Assign the service to a network\n</code></pre>"},{"location":"05_Containerization_Orchestration/#docker-compose-example-configurations","title":"Docker Compose Example Configurations","text":""},{"location":"05_Containerization_Orchestration/#1-python-flask-redis-example","title":"1. Python (Flask) + Redis Example:","text":"<pre><code>version: '3'\nservices:\n  web:\n    build: ./app\n    ports:\n    - \"5000:5000\"\n    environment:\n    - FLASK_APP=app.py\n    - FLASK_ENV=development\n    volumes:\n    - ./app:/app\n    networks:\n    - app_network\n  redis:\n    image: \"redis:alpine\"\n    networks:\n    - app_network\nnetworks:\n  app_network:\n    driver: bridge\n</code></pre>"},{"location":"05_Containerization_Orchestration/#2-nodejs-express-mongodb-example","title":"2. Node.js (Express) + MongoDB Example:","text":"<pre><code>version: '3'\nservices:\n  app:\n    build: ./node-app\n    ports:\n    - \"3000:3000\"\n    environment:\n    - MONGO_URI=mongodb://mongo:27017/mydb\n    depends_on:\n    - mongo\n    networks:\n    - backend\n  mongo:\n    image: mongo:latest\n    volumes:\n    - mongo_data:/data/db\n    networks:\n    - backend\nnetworks:\n  backend:\n    driver: bridge\n  volumes:\n    mongo_data:\n</code></pre>"},{"location":"05_Containerization_Orchestration/#3-nginx-php-laravel-example","title":"3. Nginx + PHP (Laravel) Example:","text":"<pre><code>version: '3'\nservices:\n  nginx:\n    image: nginx:alpine\n    volumes:\n    - ./nginx.conf:/etc/nginx/nginx.conf\n    - ./html:/usr/share/nginx/html\n    ports:\n    - \"8080:80\"\n    depends_on:\n    - php\n    networks:\n    - frontend\n  php:\n    image: php:8.0-fpm\n    volumes:\n    - ./html:/var/www/html\n    networks:\n    - frontend\nnetworks:\n  frontend:\n    driver: bridge\n</code></pre>"},{"location":"05_Containerization_Orchestration/#best-practices","title":"Best Practices","text":"<ul> <li>Use Versioning - Always specify a version for Docker Compose files (e.g., version: '3')</li> <li>Define Volumes - Use named volumes for persistent data (e.g., database storage)</li> <li>Environment Variables - Use environment variables for configuration (e.g., database connection strings)</li> <li>Use depends_on - Ensure proper start order for dependent services</li> <li>Custom Networks - Use custom networks for better service communication management</li> <li>Avoid latest Tag - Always use specific version tags for predictable builds</li> </ul>"},{"location":"05_Containerization_Orchestration/#advanced-options","title":"Advanced Options","text":""},{"location":"05_Containerization_Orchestration/#build-arguments","title":"Build Arguments:","text":"<ul> <li>Pass information during the image build process</li> </ul> <pre><code>build:\n  context: .\n  args:\n    NODE_ENV: production\n</code></pre>"},{"location":"05_Containerization_Orchestration/#health-checks","title":"Health Checks:","text":"<ul> <li>Add health checks to monitor service status</li> </ul> <pre><code>services:\n  web:\n    image: my-web-app\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", [\"http://localhost/health\"](http://localhost/health)]\n      interval: 30s\n      retries: 3\n</code></pre>"},{"location":"05_Containerization_Orchestration/#scaling-services","title":"Scaling Services:","text":"<ul> <li>Scale services using the command</li> </ul> <pre><code>docker-compose up --scale web=3\n</code></pre>"},{"location":"06_Kubernetes/","title":"Kubernetes","text":""},{"location":"06_Kubernetes/#kubernetes-k8s","title":"Kubernetes (K8s)","text":""},{"location":"06_Kubernetes/#1-kubernetes-basics","title":"1. Kubernetes Basics","text":"<p>Display cluster information<pre><code>kubectl cluster-info`\n</code></pre> List all nodes in the cluster<pre><code>kubectl get nodes`\n</code></pre> List all pods in the current namespace<pre><code>kubectl get pods`\n</code></pre> List all services<pre><code>kubectl get services`\n</code></pre> List all deployments<pre><code>kubectl get deployments`\n</code></pre></p>"},{"location":"06_Kubernetes/#2-managing-pods","title":"2. Managing Pods","text":"<p>Create a pod with Nginx<pre><code>kubectl run my-pod` --image=nginx\n</code></pre> Delete a pod<pre><code>kubectl delete pod my-pod`\n</code></pre> View pod logs<pre><code>kubectl logs my-pod`\n</code></pre> Access a pod's shell<pre><code>kubectl exec -it my-pod -- /bin/sh`\n</code></pre></p>"},{"location":"06_Kubernetes/#3-managing-deployments","title":"3. Managing Deployments","text":"<p>Create a deployment<pre><code>kubectl create deployment my-deploy --image=nginx`\n</code></pre> Scale deployment to 3 replicas<pre><code>kubectl scale deployment my-deploy --replicas=3`\n</code></pre> Check rollout status<pre><code>kubectl rollout status deployment my-deploy`\n</code></pre> Rollback to the previous version<pre><code>kubectl rollout undo deployment my-deploy`\n</code></pre></p>"},{"location":"06_Kubernetes/#4-managing-services","title":"4. Managing Services","text":"<p>Expose deployment as a service<pre><code>kubectl expose deployment my-deploy --type=NodePort --port=80`\n</code></pre> List services<pre><code>kubectl get svc`\n</code></pre> Get service details<pre><code>kubectl describe svc my-service`\n</code></pre></p>"},{"location":"06_Kubernetes/#5-namespaces","title":"5. Namespaces","text":"<p>List all namespaces<pre><code>kubectl get ns`\n</code></pre> Create a new namespace<pre><code>kubectl create namespace dev`\n</code></pre> Delete a namespace<pre><code>kubectl delete namespace dev`\n</code></pre></p>"},{"location":"06_Kubernetes/#6-configmaps-secrets","title":"6. ConfigMaps &amp; Secrets","text":"<p>Create a ConfigMap<pre><code>kubectl create configmap my-config --from-literal=key=value`\n</code></pre> List ConfigMaps<pre><code>kubectl get configmap`\n</code></pre> Create a secret<pre><code>kubectl create secret generic my-secret --from-literal=password=12345`\n</code></pre> List secrets<pre><code>kubectl get secrets`\n</code></pre></p>"},{"location":"06_Kubernetes/#7-troubleshooting","title":"7. Troubleshooting","text":"<p>View cluster events<pre><code>kubectl get events\n</code></pre> Get detailed pod information<pre><code>kubectl describe pod my-pod\n</code></pre> View logs of a specific pod<pre><code>kubectl logs my-pod\n</code></pre> Show resource usage of pods<pre><code>kubectl top pod\n</code></pre></p>"},{"location":"06_Kubernetes/#8-helm-package-manager-for-kubernetes","title":"8. Helm (Package Manager for Kubernetes)","text":"<p>Add a Helm repo<pre><code>helm repo add stable https://charts.helm.sh/stable\n</code></pre> Install a Helm chart<pre><code>helm install my-release stable/nginx\n</code></pre> List installed releases<pre><code>helm list\n</code></pre> Uninstall a release<pre><code>helm delete my-release\n</code></pre></p>"},{"location":"06_Kubernetes/#9-persistent-volumes-storage","title":"9. Persistent Volumes &amp; Storage","text":"<p>List persistent volume claims<pre><code>kubectl get pvc\n</code></pre> List persistent volumes<pre><code>kubectl get pv\n</code></pre> Describe a persistent volume claim<pre><code>kubectl describe pvc &lt;pvc&gt;\n</code></pre> Delete a persistent volume claim<pre><code>kubectl delete pvc &lt;pvc&gt;\n</code></pre></p>"},{"location":"06_Kubernetes/#10-autoscaling","title":"10. Autoscaling","text":"<p>Enable autoscaling<pre><code>kubectl autoscale deployment &lt;deployment&gt; --cpu-percent=50 --min=1 --max=10\n</code></pre> View horizontal pod autoscaler<pre><code>kubectl get hpa\n</code></pre></p>"},{"location":"06_Kubernetes/#11-kubernetes-debugging","title":"11. Kubernetes Debugging","text":"<p>Show events<pre><code>kubectl get events --sort-by=.metadata.creationTimestamp\n</code></pre> Show pod details<pre><code>kubectl describe pod &lt;pod&gt;\n</code></pre> Check logs<pre><code>kubectl logs &lt;pod&gt;\n</code></pre> Access pod shell<pre><code>kubectl exec -it &lt;pod&gt; -- /bin/sh\n</code></pre></p>"},{"location":"06_Kubernetes/#kubernetes-yaml-configurations","title":"Kubernetes YAML Configurations","text":""},{"location":"06_Kubernetes/#1-pod","title":"1. Pod","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: nginx\n  image: nginx:latest\n  ports:\n  - containerPort: 80\n</code></pre>"},{"location":"06_Kubernetes/#2-deployment","title":"2. Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n  matchLabels:\n    app: my-app\n  template:\n  metadata:\n    labels:\n      app: my-app\n    spec:\n      containers:\n      - name: nginx\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre>"},{"location":"06_Kubernetes/#3-replicaset","title":"3. ReplicaSet","text":"<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: my-replicaset\nspec:\n  replicas: 3\n  selector:\n  matchLabels:\n    app: my-app\n  template:\n  metadata:\n    labels:\n    app: my-app\n  spec:\n    containers:\n      - name: nginx\n      image: nginx:latest\n</code></pre>"},{"location":"06_Kubernetes/#4-service-clusterip-nodeport-loadbalancer","title":"4. Service (ClusterIP, NodePort, LoadBalancer)","text":"<ul> <li>ClusterIP (default)</li> </ul> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n  port: 80\n  targetPort: 80\n</code></pre> <ul> <li>NodePort</li> </ul> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-app\n  type: NodePort\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n    nodePort: 30080\n</code></pre> <ul> <li>LoadBalancer</li> </ul> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-app\n  type: LoadBalancer\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n</code></pre>"},{"location":"06_Kubernetes/#5-configmap","title":"5. ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-config\ndata:\n  key1: value1\n  key2: value2\n</code></pre>"},{"location":"06_Kubernetes/#6-secret","title":"6. Secret","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: my-secret\ntype: Opaque\n  data:\n    password: cGFzc3dvcmQ= # Base64 encoded value\n</code></pre>"},{"location":"06_Kubernetes/#7-persistent-volume-pv","title":"7. Persistent Volume (PV)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 1Gi\n  accessModes:\n  - ReadWriteOnce\n  hostPath:\n    path: /mnt/data\n</code></pre>"},{"location":"06_Kubernetes/#8-persistent-volume-claim-pvc","title":"8. Persistent Volume Claim (PVC)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Mi\n</code></pre>"},{"location":"06_Kubernetes/#9-ingress","title":"9. Ingress","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ingress\nspec:\n  rules:\n  - host: example.com\n  http:\n    paths:\n    - path: /\n      pathType: Prefix\n      backend:\n        service:\n          name: my-service\n          port:\n            number: 80\n</code></pre>"},{"location":"06_Kubernetes/#10-horizontal-pod-autoscaler-hpa","title":"10. Horizontal Pod Autoscaler (HPA)","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: my-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-deployment\n  minReplicas: 2\n  maxReplicas: 5\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 50\n</code></pre>"},{"location":"06_Kubernetes/#11-cronjob","title":"11. CronJob","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: my-cronjob\nspec:\n  schedule: \"*/5 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: my-cron\n            image: busybox\n            command: [\"echo\", \"Hello from CronJob\"]\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"07_Cloud_Services/","title":"Cloud Services","text":"<ul> <li>AWS</li> <li>Azure</li> <li>GCP</li> </ul>"},{"location":"07_Cloud_Services/#aws","title":"AWS","text":""},{"location":"07_Cloud_Services/#ec2-elastic-compute-cloud","title":"EC2 (Elastic Compute Cloud)","text":"<p>List all instances<pre><code>aws ec2 describe-instances\n</code></pre> Start an instance<pre><code>aws ec2 start-instances --instance-ids &lt;id&gt;\n</code></pre> Stop an instance<pre><code>aws ec2 stop-instances --instance-ids &lt;id&gt;\n</code></pre> Terminate an instance<pre><code>aws ec2 terminate-instances --instance-ids &lt;id&gt;\n</code></pre> Create a key pair<pre><code>aws ec2 create-key-pair --key-name &lt;name&gt;\n</code></pre> List security groups<pre><code>aws ec2 describe-security-groups\n</code></pre></p>"},{"location":"07_Cloud_Services/#s3-simple-storage-service","title":"S3 (Simple Storage Service)","text":"<p>List buckets<pre><code>aws s3 ls\n</code></pre> Create a bucket<pre><code>aws s3 mb s3://&lt;bucket&gt;\n</code></pre> Upload a file<pre><code>aws s3 cp &lt;file&gt; s3://&lt;bucket&gt;/\n</code></pre> Delete a file<pre><code>aws s3 rm s3://&lt;bucket&gt;/&lt;file&gt;\n</code></pre> Delete a bucket<pre><code>aws s3 rb s3://&lt;bucket&gt; --force\n</code></pre> Sync local and S3<pre><code>aws s3 sync &lt;local-dir&gt; s3://&lt;bucket&gt;/\n</code></pre></p>"},{"location":"07_Cloud_Services/#iam-identity-and-access-management","title":"IAM (Identity and Access Management)","text":"<p>List IAM users<pre><code>aws iam list-users\n</code></pre> Create a user<pre><code>aws iam create-user --user-name &lt;name&gt;\n</code></pre> Attach a policy<pre><code>aws iam attach-user-policy --user-name &lt;name&gt; --policy-arn &lt;policy&gt;\n</code></pre> List IAM roles<pre><code>aws iam list-roles\n</code></pre> Create a role<pre><code>aws iam create-role --role-name &lt;name&gt; --assume-role-policy-document file://policy.json\n</code></pre> List policies<pre><code>aws iam list-policies\n</code></pre></p>"},{"location":"07_Cloud_Services/#vpc-virtual-private-cloud","title":"VPC (Virtual Private Cloud)","text":"<p>List VPCs<pre><code>aws ec2 describe-vpcs\n</code></pre> Create a VPC<pre><code>aws ec2 create-vpc --cidr-block &lt;CIDR&gt;\n</code></pre> Delete a VPC<pre><code>aws ec2 delete-vpc --vpc-id &lt;id&gt;\n</code></pre> Create a subnet<pre><code>aws ec2 create-subnet --vpc-id &lt;id&gt; --cidr-block &lt;CIDR&gt;\n</code></pre> List security groups<pre><code>aws ec2 describe-security-groups\n</code></pre> List internet gateways<pre><code>aws ec2 describe-internet-gateways\n</code></pre></p>"},{"location":"07_Cloud_Services/#lambda-serverless-computing","title":"Lambda (Serverless Computing)","text":"<p>List all Lambda functions<pre><code>aws lambda list-functions\n</code></pre> Create a function<pre><code>aws lambda create-function --function-name &lt;name&gt; --runtime &lt;runtime&gt; --role &lt;role&gt; --handler &lt;handler&gt;\n</code></pre> Update function code<pre><code>aws lambda update-function-code --function-name &lt;name&gt; --zip-file fileb://&lt;file&gt;.zip\n</code></pre> Delete a function<pre><code>aws lambda delete-function --function-name &lt;name&gt;\n</code></pre> Invoke a function<pre><code>aws lambda invoke --function-name &lt;name&gt; output.json\n</code></pre></p>"},{"location":"07_Cloud_Services/#amazon-eks-elastic-kubernetes-service","title":"Amazon EKS (Elastic Kubernetes Service)","text":"<p>List EKS clusters<pre><code>aws eks list-clusters\n</code></pre> Describe an EKS cluster<pre><code>aws eks describe-cluster --name my-cluster\n</code></pre> Create an EKS cluster<pre><code>aws eks create-cluster --name my-cluster --role-arn arn:aws:iam::account-id:role/EKSRole --resources-vpc-config subnetIds=subnet-xxxxxxx,securityGroupIds=sg-xxxxxxx\n</code></pre> Configure kubectl to use the EKS cluster<pre><code>aws eks update-kubeconfig --name my-cluster\n</code></pre> Check worker nodes<pre><code>kubectl get nodes\n</code></pre> List running pods<pre><code>kubectl get pods -A\n</code></pre></p>"},{"location":"07_Cloud_Services/#amazon-ecs-elastic-container-service","title":"Amazon ECS (Elastic Container Service)","text":"<p>List ECS clusters<pre><code>aws ecs list-cluster\n</code></pre> List ECS services<pre><code>aws ecs list-services --cluster my-cluster\n</code></pre> Describe an ECS service<pre><code>aws ecs describe-services --cluster my-cluster --services my-service\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-cloudformation","title":"AWS CloudFormation","text":"<p>List all stacks<pre><code>aws cloudformation list-stacks\n</code></pre> Create a stack<pre><code>aws cloudformation create-stack --stack-name my-stack --template-body file://template.yml\n</code></pre></p>"},{"location":"07_Cloud_Services/#cicd-codepipeline-codebuild-codedeploy","title":"CI/CD (CodePipeline, CodeBuild, CodeDeploy)","text":""},{"location":"07_Cloud_Services/#aws-codepipeline","title":"AWS CodePipeline","text":"<p>List all pipelines<pre><code>aws codepipeline list-pipelines\n</code></pre> Start a pipeline execution<pre><code>aws codepipeline start-pipeline-execution --name my-pipeline\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-codebuild","title":"AWS CodeBuild","text":"<p>List all CodeBuild projects<pre><code>aws codebuild list-projects\n</code></pre> Start a build<pre><code>aws codebuild start-build --project-name my-project\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-codedeploy","title":"AWS CodeDeploy","text":"<p>List all CodeDeploy applications<pre><code>aws deploy list-applications\n</code></pre> Deploy an application<pre><code>aws deploy create-deployment --application-name MyApp --deployment-group-name MyDeploymentGroup --s3-location bucket=my-bucket,key=app.zip,bundleType=zip\n</code></pre></p>"},{"location":"07_Cloud_Services/#security-compliance","title":"Security &amp; Compliance","text":"<p>List CloudTrail logs<pre><code>aws cloudtrail describe-trails\n</code></pre> List CloudTrail logs<pre><code>aws secretsmanager list-secrets\n</code></pre> Retrieve a secret<pre><code>aws secretsmanager get-secret-value --secret-id my-secret\n</code></pre></p>"},{"location":"07_Cloud_Services/#monitoring-logging-cloudwatch","title":"Monitoring &amp; Logging (CloudWatch)","text":"<p>List available metrics<pre><code>aws cloudwatch list-metrics\n</code></pre> Create a CloudWatch alarm<pre><code>aws cloudwatch put-metric-alarm --alarm-name cpu-high --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanThreshold --dimensions Name=InstanceId,Value=i-xxxxxxxxxx --evaluation-periods 2 --alarm-actions arn:aws:sns:region:account-id:my-topic\n</code></pre> List all log groups<pre><code>aws logs describe-log-groups\n</code></pre> Retrieve log events<pre><code>aws logs get-log-events --log-group-name my-log-group --log-stream-name my-log-stream\n</code></pre></p>"},{"location":"07_Cloud_Services/#networking-vpc-elb-route-53","title":"Networking (VPC, ELB, Route 53)","text":""},{"location":"07_Cloud_Services/#amazon-vpc","title":"Amazon VPC","text":"<p>List all VPCs<pre><code>aws ec2 describe-vpcs\n</code></pre> List all subnets<pre><code>aws ec2 describe-subnets\n</code></pre></p>"},{"location":"07_Cloud_Services/#elastic-load-balancer-elb","title":"Elastic Load Balancer (ELB)","text":"List all load balancers<pre><code>aws elbv2 describe-load-balancers\n</code></pre>"},{"location":"07_Cloud_Services/#amazon-route-53","title":"Amazon Route 53","text":"List hosted zones<pre><code>aws route53 list-hosted-zones\n</code></pre>"},{"location":"07_Cloud_Services/#amazon-ecr-elastic-container-registry","title":"Amazon ECR (Elastic Container Registry)","text":"<p>Authenticate Docker with ECR<pre><code>aws ecr get-login-password | docker login --username AWS --password-stdin &lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com\n</code></pre> List all ECR repositories<pre><code>aws ecr list-repositories\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-systems-manager-ssm","title":"AWS Systems Manager (SSM)","text":"List managed instances<pre><code>aws ssm describe-instances\n</code></pre> Run a command on an EC2 instance<pre><code>aws ssm send-command --document-name \"AWS-RunShellScript\" --targets \"Key=instanceIds,Values=i-xxxxxxxxxx\" --parameters commands=\"sudo apt update\"\n</code></pre>"},{"location":"07_Cloud_Services/#aws-auto-scaling","title":"AWS Auto Scaling","text":"<p>List Auto Scaling groups<pre><code>aws autoscaling describe-auto-scaling-groups\n</code></pre> Update the desired capacity<pre><code>aws autoscaling update-auto-scaling-group --auto-scaling-group-name my-asg --desired-capacity 3\n</code></pre> Manually scale an Auto Scaling group<pre><code>aws autoscaling set-desired-capacity --auto-scaling-group-name my-asg --desired-capacity 2\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-elastic-beanstalk","title":"AWS Elastic Beanstalk","text":"<p>List all environments<pre><code>aws elasticbeanstalk describe-environments\n</code></pre> Create an application<pre><code>aws elasticbeanstalk create-application --application-name my-app\n</code></pre> Deploy a new version<pre><code>aws elasticbeanstalk update-environment --environment-name my-env --version-label new-version\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-step-functions","title":"AWS Step Functions","text":"<p>List all state machines<pre><code>aws stepfunctions list-state-machines\n</code></pre> Start a state machine execution<pre><code>aws stepfunctions start-execution --state-machine-arn arn:aws:states:region:account-id:stateMachine:MyStateMachine\n</code></pre> Get execution details<pre><code>aws stepfunctions describe-execution --execution-arn arn:aws:states:region:account-id:execution:MyStateMachine:MyExecution\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-glue-etl-service","title":"AWS Glue (ETL Service)","text":"<p>List all Glue databases<pre><code>aws glue get-databases\n</code></pre> List all tables in a database<pre><code>aws glue get-tables --database-name my-database\n</code></pre> Start a Glue job<pre><code>aws glue start-job-run --job-name my-glue-job\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-sns-simple-notification-service","title":"AWS SNS (Simple Notification Service)","text":"<p>List all SNS topics<pre><code>aws sns list-topics\n</code></pre> Publish a message to an SNS topic<pre><code>aws sns publish --topic-arn arn:aws:sns:region:account-id:MyTopic --message \"Test Message\"\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-sqs-simple-queue-service","title":"AWS SQS (Simple Queue Service)","text":"<p>List all SQS queues<pre><code>aws sqs list-queues\n</code></pre> Send a message<pre><code>aws sqs send-message --queue-url https://sqs.region.amazonaws.com/account-id/my-queue --message-body \"Hello World\"\n</code></pre></p>"},{"location":"07_Cloud_Services/#aws-outpostsmanaged-on-prem-cloudon-premises-aws","title":"AWS Outposts(Managed on-prem cloud/On-premises AWS)","text":""},{"location":"07_Cloud_Services/#list-and-describe-outposts","title":"List and Describe Outposts","text":"<p>List all AWS Outposts<pre><code>aws outposts list-outposts\n</code></pre> Get details of a specific Outpost<pre><code>aws outposts get-outpost --outpost-id &lt;outpost-id&gt;\n</code></pre> List instance types in an Outpost<pre><code>aws outposts get-outpost-instance-types --outpost-id &lt;outpost-id&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#manage-outpost-resources","title":"Manage Outpost Resources","text":"<p>List all Outpost sites<pre><code>aws outposts list-sites\n</code></pre> List Outpost orders<pre><code>aws outposts list-orders\n</code></pre> List EC2 instances in an Outpost<pre><code>aws outposts list-outpost-instances --outpost-id &lt;outpost-id&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#deploy-and-configure-outposts","title":"Deploy and Configure Outposts","text":"<p>Order an Outpost<pre><code>aws outposts create-order --line-items \"[{\\\"catalogItemId\\\": \\\"item-id\\\", \\\"quantity\\\": 1}]\" --outpost-id &lt;outpost-id&gt;\n</code></pre> Update Outpost configuration<pre><code>aws outposts update-outpost --outpost-id &lt;outpost-id&gt; --name &lt;new-name&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#networking-and-storage-on-outposts","title":"Networking and Storage on Outposts","text":"<p>List network devices in an Outpost<pre><code>aws outposts list-outpost-network-devices --outpost-id &lt;outpost-id&gt;\n</code></pre> List S3 buckets on an Outpost<pre><code>aws s3 ls --outpost-id &lt;outpost-id&gt;\n</code></pre> Create an S3 bucket in Outpost<pre><code>aws s3 mb s3://&lt;bucket-name&gt; --outpost-id &lt;outpost-id&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#deploy-ec2-instances-in-outposts","title":"Deploy EC2 Instances in Outposts","text":"Launch an EC2 instance in Outpost<pre><code>aws ec2 run-instances --image-id &lt;ami-id&gt; --instance-type &lt;type&gt; --subnet-id &lt;outpost-subnet-id&gt;\n</code></pre>"},{"location":"07_Cloud_Services/#automate-outpost-deployments-with-cloudformation","title":"Automate Outpost Deployments with CloudFormation","text":"Deploy Outpost resources using CloudFormation<pre><code>aws cloudformation deploy --template-file outpost-config.yml --stack-name my-outpost-stack\n</code></pre>"},{"location":"07_Cloud_Services/#monitor-outposts-with-cloudwatch","title":"Monitor Outposts with CloudWatch","text":"<p>List Outpost-related CloudWatch metrics<pre><code>aws cloudwatch list-metrics --namespace AWS/Outposts\n</code></pre> Monitor CPU usage of Outpost instances<pre><code>aws cloudwatch get-metric-data --metric-name CPUUtilization --namespace AWS/Outposts\n</code></pre></p>"},{"location":"07_Cloud_Services/#integrate-outposts-with-cicd","title":"Integrate Outposts with CI/CD","text":"<p>List all CI/CD pipelines<pre><code>aws codepipeline list-pipelines\n</code></pre> Start a deployment pipeline for Outposts<pre><code>aws codepipeline start-pipeline-execution --name &lt;pipeline-name&gt;\n</code></pre> Start a build process for Outposts workloads<pre><code>aws codebuild start-build --project-name &lt;build-project&gt;\n</code></pre> Deploy an application to an Outpost<pre><code>aws deploy create-deployment --application-name &lt;app-name&gt; --deployment-group-name &lt;group-name&gt; --s3-location bucket=&lt;bucket-name&gt;,key=&lt;app.zip&gt;,bundleType=zip\n</code></pre></p>"},{"location":"07_Cloud_Services/#security-and-compliance-for-outposts","title":"Security and Compliance for Outposts","text":"<p>Create an IAM role for Outpost management<pre><code>aws iam create-role --role-name &lt;role-name&gt; --assume-role-policy-document file://policy.json\n</code></pre> List stored secrets for Outposts<pre><code>aws secretsmanager list-secrets\n</code></pre> Retrieve a stored secret<pre><code>aws secretsmanager get-secret-value --secret-id &lt;secret-name&gt;\n</code></pre> List AWS CloudTrail logs for security auditing<pre><code>aws cloudtrail describe-trails\n</code></pre> Detect security threats related to Outposts<pre><code>aws guardduty list-findings\n</code></pre></p>"},{"location":"07_Cloud_Services/#delete-or-deactivate-an-outpost","title":"Delete or Deactivate an Outpost","text":"<p>Delete an Outpost (must be empty)<pre><code>aws outposts delete-outpost --outpost-id &lt;outpost-id&gt;\n</code></pre> Cancel an Outpost order before delivery<pre><code>aws outposts cancel-order --order-id &lt;order-id&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure","title":"Azure","text":""},{"location":"07_Cloud_Services/#azure-virtual-machines-vms","title":"Azure Virtual Machines (VMs)","text":"<p>Create a VM<pre><code>az vm create --resource-group &lt;rg&gt; --name &lt;vm-name&gt; --image &lt;image&gt;\n</code></pre> List all VMs<pre><code>az vm list -o table\n</code></pre> Stop a VM<pre><code>az vm stop --name &lt;vm-name&gt; --resource-group &lt;rg&gt;\n</code></pre> Start a VM<pre><code>az vm start --name &lt;vm-name&gt; --resource-group &lt;rg&gt;\n</code></pre> Delete a VM<pre><code>az vm delete --name &lt;vm-name&gt; --resource-group &lt;rg&gt;\n</code></pre> Resize a VM<pre><code>az vm resize --name &lt;vm-name&gt; --resource-group &lt;rg&gt; --size &lt;vm-size&gt;\n</code></pre> Show VM details<pre><code>az vm show --name &lt;vm-name&gt; --resource-group &lt;rg&gt;\n</code></pre> Open a port on a VM<pre><code>az vm open-port --port &lt;port-number&gt; --name &lt;vm-name&gt; --resource-group &lt;rg&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-storage","title":"Azure Storage","text":"<p>Create a storage account<pre><code>az storage account create --name &lt;storage-name&gt; --resource-group &lt;rg&gt; --location &lt;region&gt;\n</code></pre> Create a blob container<pre><code>az storage container create --name &lt;container-name&gt; --account-name &lt;storage-name&gt;\n</code></pre> Upload a file to Blob Storage<pre><code>az storage blob upload --file &lt;file-path&gt; --container-name &lt;container-name&gt; --account-name &lt;storage-name&gt;\n</code></pre> List blobs in a container<pre><code>az storage blob list --container-name &lt;container-name&gt; --account-name &lt;storage-name&gt;\n</code></pre> Delete a storage account<pre><code>az storage account delete --name &lt;storage-name&gt; --resource-group &lt;rg&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-kubernetes-service-aks","title":"Azure Kubernetes Service (AKS)","text":"<p>Create an AKS cluster<pre><code>az aks create --resource-group &lt;rg&gt; --name &lt;aks-name&gt; --node-count &lt;num&gt; --generate-ssh-keys\n</code></pre> Get kubeconfig for AKS cluster<pre><code>az aks get-credentials --resource-group &lt;rg&gt; --name &lt;aks-name&gt;\n</code></pre> List AKS cluster nodes<pre><code>kubectl get nodes\n</code></pre> List all pods in AKS<pre><code>kubectl get pods -A\n</code></pre> Deploy an application in AKS<pre><code>kubectl apply -f &lt;file.&gt;\n</code></pre> Remove an application from AKS<pre><code>kubectl delete -f &lt;file.&gt;\n</code></pre> Delete an AKS cluster<pre><code>az aks delete --name &lt;aks-name&gt; --resource-group &lt;rg&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-functions","title":"Azure Functions","text":"<p>Create an Azure Function App<pre><code>az functionapp create --resource-group &lt;rg&gt; --name &lt;app-name&gt; --consumption-plan-location &lt;region&gt; --runtime &lt;runtime&gt;\n</code></pre> List all Function Apps<pre><code>az functionapp list -o table\n</code></pre> Delete a Function App<pre><code>az functionapp delete --name &lt;app-name&gt; --resource-group &lt;rg&gt;\n</code></pre> Initialize a local Azure Functions project<pre><code>func init &lt;app-name&gt;\n</code></pre> Create a new function<pre><code>func new\n</code></pre> Run functions locally<pre><code>func start\n</code></pre> Deploy function to Azure<pre><code>func azure functionapp publish &lt;app-name&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-networking","title":"Azure Networking","text":""},{"location":"07_Cloud_Services/#virtual-network-vnet","title":"Virtual Network (VNet)","text":"<p>List VNets<pre><code>az network vnet list --output table\n</code></pre> Create a VNet<pre><code>az network vnet create --name myVNet --resource-group myResourceGroup --subnet-name mySubnet\n</code></pre></p>"},{"location":"07_Cloud_Services/#network-security-group-nsg","title":"Network Security Group (NSG)","text":"<p>List NSGs<pre><code>az network nsg list --output table\n</code></pre> Create an NSG<pre><code>az network nsg create --resource-group myResourceGroup --name myNSG\n</code></pre></p>"},{"location":"07_Cloud_Services/#load-balancer","title":"Load Balancer","text":"<p>List load balancers<pre><code>az network lb list --output table\n</code></pre> Create a Load Balancer<pre><code>az network lb create --resource-group myResourceGroup --name myLB --sku Standard --frontend-ip-name myFrontend --backend-pool-name myBackendPool\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-devopscicd","title":"Azure DevOps(CI/CD)","text":""},{"location":"07_Cloud_Services/#azure-devops-projects","title":"Azure DevOps Projects","text":"<p>List all DevOps projects<pre><code>az devops project list --output table\n</code></pre> Create a DevOps project<pre><code>az devops project create --name myDevOpsProject\n</code></pre> Delete a DevOps project<pre><code>az devops project delete --id PROJECT_ID --yes\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-repos-git","title":"Azure Repos (Git)","text":"<p>List all repositories<pre><code>az repos list --output table\n</code></pre> Create a new repo<pre><code>az repos create --name myRepo\n</code></pre> Delete a repo<pre><code>az repos delete --name myRepo --yes\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-pipelines","title":"Azure Pipelines","text":"<p>List all pipelines<pre><code>az pipelines list --output table\n</code></pre> Create a pipeline<pre><code>az pipelines create --name myPipeline --repository myRepo --branch main --repository-type gitHub\n</code></pre> Run a pipeline<pre><code>az pipelines run --name myPipeline\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-monitor-logging","title":"Azure Monitor &amp; Logging","text":""},{"location":"07_Cloud_Services/#azure-monitor","title":"Azure Monitor","text":"<p>List metrics for a resource<pre><code>az monitor metrics list --resource myResourceID\n</code></pre> List metric alerts<pre><code>az monitor metrics alert list --resource-group myResourceGroup\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-log-analytics","title":"Azure Log Analytics","text":"<p>List log analytics workspaces<pre><code>az monitor log-analytics workspace list --output table\n</code></pre> Create a Log Analytics workspace<pre><code>az monitor log-analytics workspace create --resource-group myResourceGroup --workspace-name myWorkspace\n</code></pre></p>"},{"location":"07_Cloud_Services/#security-compliance_1","title":"Security &amp; Compliance","text":""},{"location":"07_Cloud_Services/#azure-security-center","title":"Azure Security Center","text":"<p>List security assessments<pre><code>az security assessment list --output table\n</code></pre> Enable auto-provisioning for Security Center<pre><code>az security setting update --name AutoProvisioning --value On\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-key-vault","title":"Azure Key Vault","text":"<p>List Key Vaults<pre><code>az keyvault list --output table\n</code></pre> Create a Key Vault<pre><code>az keyvault create --name myKeyVault --resource-group myResourceGroup --location eastus\n</code></pre> Store a secret in Key Vault<pre><code>az keyvault secret set --vault-name myKeyVault --name mySecret --value \"MySecretValue\"\n</code></pre> Retrieve a secret<pre><code>az keyvault secret show --vault-name myKeyVault --name mySecret\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-policies-governance","title":"Azure Policies &amp; Governance","text":"<p>List all policy assignments<pre><code>az policy assignment list --output table\n</code></pre> Assign a policy<pre><code>az policy assignment create --name myPolicyAssignment --policy myPolicyDefinition\n</code></pre> Delete a policy assignment<pre><code>az policy assignment delete --name myPolicyAssignment\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-active-directory-aad","title":"Azure Active Directory (AAD)","text":"<p>List all users<pre><code>az ad user list --output table\n</code></pre> List all groups<pre><code>az ad group list --output table\n</code></pre> List all applications<pre><code>az ad app list --output table\n</code></pre> List all service principals<pre><code>az ad sp list --output table\n</code></pre></p>"},{"location":"07_Cloud_Services/#azure-backup-recovery","title":"Azure Backup &amp; Recovery","text":"<p>List all backup vaults<pre><code>az backup vault list --output table\n</code></pre> Create a backup vault<pre><code>az backup vault create --resource-group myResourceGroup --name myBackupVault\n</code></pre> List backup items<pre><code>az backup item list --resource-group myResourceGroup --vault-name myBackupVault --output table\n</code></pre></p>"},{"location":"07_Cloud_Services/#gcp","title":"GCP","text":""},{"location":"07_Cloud_Services/#compute-engine-vms","title":"Compute Engine (VMs)","text":"<p>Create a VM instance<pre><code>gcloud compute instances create &lt;vm-name&gt; --zone=&lt;zone&gt; --machine-type=&lt;type&gt; --image=&lt;image&gt;\n</code></pre> List all VM instances<pre><code>gcloud compute instances list\n</code></pre> Start a VM instance<pre><code>gcloud compute instances start &lt;vm-name&gt; --zone=&lt;zone&gt;\n</code></pre> Stop a VM instance<pre><code>gcloud compute instances stop &lt;vm-name&gt; --zone=&lt;zone&gt;\n</code></pre> Delete a VM instance<pre><code>gcloud compute instances delete &lt;vm-name&gt; --zone=&lt;zone&gt;\n</code></pre> SSH into a VM instance<pre><code>gcloud compute ssh &lt;vm-name&gt; --zone=&lt;zone&gt;\n</code></pre> Open a specific port<pre><code>gcloud compute firewall-rules create &lt;rule-name&gt; --allow tcp:&lt;port&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-kubernetes-engine-gke","title":"Google Kubernetes Engine (GKE)","text":"<p>Create a GKE cluster<pre><code>gcloud container clusters create &lt;cluster-name&gt; --num-nodes=&lt;num&gt; --zone=&lt;zone&gt;\n</code></pre> Get credentials for the GKE cluster<pre><code>gcloud container clusters get-credentials &lt;cluster-name&gt; --zone=&lt;zone&gt;\n</code></pre> List cluster nodes<pre><code>kubectl get nodes\n</code></pre> List all running pods<pre><code>kubectl get pods -A\n</code></pre> Deploy an application to GKE<pre><code>kubectl apply -f &lt;file.&gt;\n</code></pre> Remove an application from GKE<pre><code>kubectl delete -f &lt;file.&gt;\n</code></pre> Delete a GKE cluster<pre><code>gcloud container clusters delete &lt;cluster-name&gt; --zone=&lt;zone&gt;\n</code></pre></p>"},{"location":"07_Cloud_Services/#cloud-run-serverless-containers","title":"Cloud Run (Serverless Containers)","text":"<p>Deploy an application to Cloud Run<pre><code>gcloud run deploy &lt;service-name&gt; --image=&lt;gcr.io/project/image&gt; --platform=managed --region=&lt;region&gt; --allow-unauthenticated\n</code></pre> List all deployed Cloud Run services<pre><code>gcloud run services list\n</code></pre> Update Cloud Run service to the latest image<pre><code>gcloud run services update-traffic &lt;service-name&gt; --to-latest\n</code></pre> Delete a Cloud Run service<pre><code>gcloud run services delete &lt;service-name&gt;\n</code></pre> Set environment variables in a Cloud Run service<pre><code>gcloud run services update &lt;service-name&gt; --set-env-vars VAR_NAME=value\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-storage-gcs","title":"Google Cloud Storage (GCS)","text":"<p>List all storage buckets<pre><code>gcloud storage buckets list\n</code></pre> Create a storage bucket<pre><code>gcloud storage buckets create my-bucket --location US\n</code></pre> Upload a file<pre><code>gcloud storage cp file.txt gs://my-bucket/\n</code></pre> Delete a file<pre><code>gcloud storage rm gs://my-bucket/file.txt\n</code></pre> Delete a storage bucket<pre><code>gcloud storage buckets delete my-bucket\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-iam-identity-access-management","title":"Google Cloud IAM (Identity &amp; Access Management)","text":"<p>List all IAM roles<pre><code>gcloud iam roles list\n</code></pre> List all service accounts<pre><code>gcloud iam service-accounts list\n</code></pre> Assign a role to a user<pre><code>gcloud projects add-iam-policy-binding PROJECT_ID --member=user:EMAIL --role=roles/editor\n</code></pre> Remove a role from a user<pre><code>gcloud projects remove-iam-policy-binding PROJECT_ID --member=user:EMAIL --role=roles/editor\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-sql-managed-database-service","title":"Google Cloud SQL (Managed Database Service)","text":"<p>List all Cloud SQL instances<pre><code>gcloud sql instances list\n</code></pre> Create a Cloud SQL instance<pre><code>gcloud sql instances create my-db --tier=db-f1-micro --region=us-central1\n</code></pre> Start a Cloud SQL instance<pre><code>gcloud sql instances start my-db\n</code></pre> Stop a Cloud SQL instance<pre><code>gcloud sql instances stop my-db\n</code></pre> Delete a Cloud SQL instance<pre><code>gcloud sql instances delete my-db\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-build-cicd","title":"Google Cloud Build (CI/CD)","text":"<p>List all Cloud Build runs<pre><code>gcloud builds lis\n</code></pre> Build and push an image<pre><code>gcloud builds submit --tag gcr.io/PROJECT_ID/my-app\n</code></pre> List Cloud Build triggers<pre><code>gcloud builds triggers list\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-deploy-cicd","title":"Google Cloud Deploy (CI/CD)","text":"<p>List deployment releases<pre><code>gcloud deploy releases list --delivery-pipeline=my-pipeline\n</code></pre> List rollouts<pre><code>gcloud deploy rollouts list --release=my-release --delivery-pipeline=my-pipeline\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-logging-monitoring","title":"Google Cloud Logging &amp; Monitoring","text":""},{"location":"07_Cloud_Services/#cloud-logging","title":"Cloud Logging","text":"<p>List available logs<pre><code>gcloud logging logs list\n</code></pre> Read VM logs<pre><code>gcloud logging read \"resource.type=gce_instance\" --limit 10\n</code></pre></p>"},{"location":"07_Cloud_Services/#cloud-monitoring","title":"Cloud Monitoring","text":"<p>List available monitoring metrics<pre><code>gcloud monitoring metrics list\n</code></pre> List all dashboards<pre><code>gcloud monitoring dashboards list\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-networking","title":"Google Cloud Networking","text":""},{"location":"07_Cloud_Services/#vpc-virtual-private-cloud_1","title":"VPC (Virtual Private Cloud)","text":"<p>List VPC networks<pre><code>gcloud compute networks list\n</code></pre> Create a VPC network<pre><code>gcloud compute networks create my-vpc --subnet-mode=custom\n</code></pre></p>"},{"location":"07_Cloud_Services/#firewall-rules","title":"Firewall Rules","text":"<p>List firewall rules<pre><code>gcloud compute firewall-rules list\n</code></pre> Allow SSH access<pre><code>gcloud compute firewall-rules create allow-ssh --network=my-vpc --allow=tcp:22\n</code></pre></p>"},{"location":"07_Cloud_Services/#load-balancers","title":"Load Balancers","text":"List all load balancers<pre><code>gcloud compute forwarding-rules list\n</code></pre>"},{"location":"07_Cloud_Services/#google-cloud-security","title":"Google Cloud Security","text":""},{"location":"07_Cloud_Services/#cloud-identity-aware-proxy-iap","title":"Cloud Identity-Aware Proxy (IAP)","text":"<p>List IAP-secured applications<pre><code>gcloud iap web list\n</code></pre> IAP settings<pre><code>gcloud iap settings get --resource-type=app-engine Get\n</code></pre></p>"},{"location":"07_Cloud_Services/#cloud-key-management-service-kms","title":"Cloud Key Management Service (KMS)","text":"<p>List key rings<pre><code>gcloud kms keyrings list --location global\n</code></pre> List encryption keys<pre><code>gcloud kms keys list --keyring my-keyring --location global\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-artifact-registry","title":"Google Artifact Registry","text":"<p>List all Artifact Repositories<pre><code>gcloud artifacts repositories list\n</code></pre> Create a Docker registry<pre><code>gcloud artifacts repositories create my-repo --repository-format=docker --location=us-central1\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-pubsub-messaging","title":"Google Cloud Pub/Sub (Messaging)","text":"<p>List all Pub/Sub topics<pre><code>gcloud pubsub topics list\n</code></pre> Create a topic<pre><code>gcloud pubsub topics create my-topic\n</code></pre> List all subscriptions<pre><code>gcloud pubsub subscriptions list\n</code></pre> Create a subscription<pre><code>gcloud pubsub subscriptions create my-sub --topic=my-topic\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-backup-disaster-recovery","title":"Google Cloud Backup &amp; Disaster Recovery","text":"<p>List all backup vaults<pre><code>gcloud backup vaults list\n</code></pre> List backup policies<pre><code>gcloud backup policies list\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-policies-governance","title":"Google Cloud Policies &amp; Governance","text":"<p>List policy tags<pre><code>gcloud policy-tags list --location=us\n</code></pre> List all organizational policies<pre><code>gcloud resource-manager org-policies list\n</code></pre></p>"},{"location":"07_Cloud_Services/#google-cloud-scheduler-cron-jobs","title":"Google Cloud Scheduler (Cron Jobs)","text":"<p>List all scheduled jobs<pre><code>gcloud scheduler jobs list\n</code></pre> Create a scheduled HTTP job<pre><code>gcloud scheduler jobs create http my-job --schedule=\"0 \\* \\* \\* \\*\" --uri=https://example.com/cron\n</code></pre></p>"},{"location":"08_Configuration_Management/","title":"Configuration Management","text":"<ul> <li>Ansible</li> <li>Chef</li> <li>Puppet</li> <li>Salt</li> </ul>"},{"location":"08_Configuration_Management/#ansible-playbooks-roles-inventory","title":"Ansible (playbooks, roles, inventory)","text":""},{"location":"08_Configuration_Management/#1-ansible-basics","title":"1. Ansible Basics","text":"<p>Check version<pre><code>ansible --version\n</code></pre> Check inventory<pre><code>ansible-inventory --list -y\n</code></pre> Ping all hosts<pre><code>ansible all -m ping\n</code></pre> Run command on all hosts<pre><code>ansible all -a \"uptime\"\n</code></pre></p>"},{"location":"08_Configuration_Management/#2-inventory-configuration","title":"2. Inventory &amp; Configuration","text":""},{"location":"08_Configuration_Management/#default-inventory","title":"Default inventory:","text":"<ul> <li><code>/etc/ansible/hosts</code></li> </ul>"},{"location":"08_Configuration_Management/#custom-inventory","title":"Custom inventory:","text":"<ul> <li><code>ansible -i inventory.ini all -m ping</code></li> </ul>"},{"location":"08_Configuration_Management/#define-hosts-in-inventoryini","title":"Define hosts in inventory.ini:","text":"inventory.ini<pre><code># fmt: ini\n\n[web]\n\nweb1 ansible_host=192.168.1.10 ansible_user=ubuntu\n\n[db]\n\ndb1 ansible_host=192.168.1.20 ansible_user=root\n</code></pre>"},{"location":"08_Configuration_Management/#3-ad-hoc-commands","title":"3. Ad-Hoc Commands","text":"<p>Run as a specific user<pre><code>ansible all -m ping -u ubuntu --become\n</code></pre> Copy file to remote host<pre><code>ansible all -m copy -a \"src=/etc/hosts dest=/tmp/hosts\"\n</code></pre> Install a package (example: nginx)<pre><code>ansible all -m apt -a \"name=nginx state=present\" --become\n</code></pre></p>"},{"location":"08_Configuration_Management/#4-playbook-structure","title":"4. Playbook Structure","text":"<pre><code>- name: Install Nginx\n  hosts: web\n  become: yes\n\n  tasks:\n  - name: Install Nginx\n    apt:\n    name: nginx\n    state: present\n</code></pre> Run the playbook:<pre><code>ansible-playbook install_nginx.yml\n</code></pre>"},{"location":"08_Configuration_Management/#5-variables-facts","title":"5. Variables &amp; Facts","text":"Define variables in vars.yml:<pre><code>nginx_version: latest\n</code></pre>"},{"location":"08_Configuration_Management/#use-variables-in-playbook","title":"Use variables in playbook:","text":"<pre><code>- name: Install Nginx\n  apt:\n  name: nginx={{ nginx_version }}\n  state: present\n</code></pre> Display all facts:<pre><code>ansible all -m setup\n</code></pre>"},{"location":"08_Configuration_Management/#6-handlers-notifications","title":"6. Handlers &amp; Notifications","text":"<pre><code>- name: Restart Nginx\n  hosts: web\n  become: yes\n\n  tasks:\n  - name: Install Nginx\n    apt:\n      name: nginx\n      state: present\n    notify: Restart Nginx\n\n  handlers:\n  - name: Restart Nginx\n    service:\n    name: nginx\n    state: restarted\n</code></pre>"},{"location":"08_Configuration_Management/#7-loops-conditionals","title":"7. Loops &amp; Conditionals","text":""},{"location":"08_Configuration_Management/#loop-over-items","title":"Loop over items:","text":"<pre><code>- name: Install multiple packages\n  apt:\n    name: \"{{ item }}\"\n    state: present\n  loop:\n  - nginx\n  - curl\n  - git\n</code></pre>"},{"location":"08_Configuration_Management/#conditional-execution","title":"Conditional execution:","text":"<pre><code>- name: Restart service only if Nginx is installed\n  service:\n    name: nginx\n    state: restarted\n  when: ansible_facts['pkg_mgr'] == 'apt'\n</code></pre>"},{"location":"08_Configuration_Management/#8-roles-reusability","title":"8. Roles &amp; Reusability","text":"Create a role:<pre><code>Ansible-galaxy init my_role\n</code></pre>"},{"location":"08_Configuration_Management/#run-a-role-in-a-playbook","title":"Run a role in a playbook:","text":"<pre><code>- hosts: web\n  roles:\n  - my_role\n</code></pre>"},{"location":"08_Configuration_Management/#9-debugging-testing","title":"9. Debugging &amp; Testing","text":""},{"location":"08_Configuration_Management/#debug-a-variable","title":"Debug a variable:","text":"<pre><code>- debug:\n  msg: \"The value of nginx_version is {{ nginx_version }}\"\n</code></pre> Check playbook syntax:<pre><code>ansible-playbook myplaybook.yml --syntax-check\n</code></pre> Run in dry mode:<pre><code>ansible-playbook myplaybook.yml --check\n</code></pre>"},{"location":"08_Configuration_Management/#ansible-playbook","title":"Ansible Playbook","text":""},{"location":"08_Configuration_Management/#1-playbook-structure","title":"1. Playbook Structure","text":"<pre><code>- name: Example Playbook\n  hosts: all\n  become: yes\n\n  tasks:\n  - name: Print a message\n    debug:\n      msg: \"Hello, Ansible!\"\n</code></pre> Run the playbook:<pre><code>ansible-playbook playbook.yml\n</code></pre>"},{"location":"08_Configuration_Management/#2-defining-hosts-privilege-escalation","title":"2. Defining Hosts &amp; Privilege Escalation","text":"<pre><code>- name: Install Nginx\n  hosts: web\n  become: yes\n</code></pre>"},{"location":"08_Configuration_Management/#run-as-a-specific-user","title":"Run as a specific user:","text":"<pre><code>- name: Install package\n  apt:\n    name: nginx\n  state: present\n  become_user: root\n</code></pre>"},{"location":"08_Configuration_Management/#3-tasks-modules","title":"3. Tasks &amp; Modules","text":"<pre><code>- name: Ensure Nginx is installed\n  hosts: web\n  become: yes\n\n  tasks:\n  - name: Install Nginx\n    apt:\n      name: nginx\n      state: present\n</code></pre>"},{"location":"08_Configuration_Management/#common-modules","title":"Common Modules","text":"<ul> <li><code>command</code>: Run shell commands</li> <li><code>copy</code>: Copy files</li> <li><code>service</code>: Manage services</li> <li><code>user</code>: Manage users</li> <li><code>file</code>: Set file permissions</li> </ul>"},{"location":"08_Configuration_Management/#4-using-variables","title":"4. Using Variables","text":""},{"location":"08_Configuration_Management/#define-variables-inside-the-playbook","title":"Define variables inside the playbook:","text":"<pre><code>vars:\n  package_name: nginx\n</code></pre>"},{"location":"08_Configuration_Management/#use-them-in-tasks","title":"Use them in tasks:","text":"<pre><code>- name: Install {{ package_name }}\n  apt:\n    name: \"{{ package_name }}\"\n    state: present\n</code></pre>"},{"location":"08_Configuration_Management/#load-external-variables-from-varsyml","title":"Load external variables from vars.yml:","text":"<pre><code>- name: Load Variables\n  include_vars: vars.yml\n</code></pre>"},{"location":"08_Configuration_Management/#5-conditionals","title":"5. Conditionals","text":"<pre><code>- name: Restart Nginx only if installed\n  service:\n    name: nginx\n    state: restarted\n  when: ansible_facts['pkg_mgr'] == 'apt'\n</code></pre>"},{"location":"08_Configuration_Management/#6-loops","title":"6. Loops","text":"<pre><code>- name: Install multiple packages\n  apt:\n    name: \"{{ item }}\"\n    state: present\n  loop:\n  - nginx\n  - git\n  - curl\n</code></pre>"},{"location":"08_Configuration_Management/#7-handlers","title":"7. Handlers","text":"<pre><code>- name: Install Nginx\n  apt:\n    name: nginx\n    state: present\n  notify: Restart Nginx\n\nhandlers:\n  - name: Restart Nginx\n    service:\n      name: nginx\n      state: restarted\n</code></pre>"},{"location":"08_Configuration_Management/#8-debugging-testing","title":"8. Debugging &amp; Testing","text":"<pre><code>- name: Debug Variable\n  debug:\n    msg: \"The server is running {{ ansible_distribution }}\"\n</code></pre> Check syntax:<pre><code>ansible-playbook playbook.yml --syntax-check\n</code></pre> Dry run:<pre><code>ansible-playbook playbook.yml --check\n</code></pre>"},{"location":"08_Configuration_Management/#9-rolesbest-practice","title":"9. Roles(Best Practice)","text":"Create a role:<pre><code>ansible-galaxy init my_role\n</code></pre> <ul> <li>Use the role in a playbook:</li> </ul> <pre><code>- hosts: web\n  roles:\n  - my_role\n</code></pre>"},{"location":"08_Configuration_Management/#chef-recipes-cookbooks","title":"Chef (recipes, cookbooks)","text":""},{"location":"08_Configuration_Management/#basic-concepts","title":"Basic Concepts","text":"<ul> <li><code>Recipe</code> - Defines a set of resources to configure a system.</li> <li><code>Cookbook</code> - A collection of recipes, templates, and attributes.</li> <li><code>Resource</code> - Represents system objects (e.g., package, service, file).</li> <li><code>Node</code> - A machine managed by Chef.</li> <li><code>Run List</code> - Specifies the order in which recipes are applied.</li> <li><code>Attributes</code> - Variables used to customize recipes.</li> </ul>"},{"location":"08_Configuration_Management/#commands","title":"Commands","text":"<p>Run Chef on a node<pre><code>chef-client\n</code></pre> Create a new cookbook<pre><code>knife cookbook create my_cookbook\n</code></pre> List all nodes<pre><code>knife node list\n</code></pre> List all roles<pre><code>knife role list\n</code></pre> Run Chef in solo mode<pre><code>chef-solo -c solo.rb -j run_list.json\n</code></pre></p>"},{"location":"08_Configuration_Management/#example-recipe","title":"Example Recipe","text":"<pre><code>package 'nginx' do\n  action :install\n\nend\n\nservice 'nginx' do\n  action [:enable, :start]\n\nend\n\nfile '/var/www/html/index.html' do\n  content '&lt;h1&gt;Welcome to Chef&lt;/h1&gt;' \n\nend\n</code></pre>"},{"location":"08_Configuration_Management/#puppet-manifests-modules","title":"Puppet (manifests, modules)","text":""},{"location":"08_Configuration_Management/#basic-concepts_1","title":"Basic Concepts","text":"<ul> <li><code>Manifest</code> - A file defining resources and configurations (.pp).</li> <li><code>Module</code> - A collection of manifests, templates, and files.</li> <li><code>Class</code> - A reusable block of Puppet code.</li> <li><code>Node</code> - A system managed by Puppet.</li> <li><code>Fact</code> - System information collected by Facter.</li> <li><code>Resource</code> - The basic unit of configuration (e.g., package, service).</li> </ul>"},{"location":"08_Configuration_Management/#commands_1","title":"Commands","text":"<p>Apply a local manifest<pre><code>puppet apply my_manifest.pp\n</code></pre> Install a module<pre><code>puppet module install my_module\n</code></pre> Run Puppet on an agent node<pre><code>puppet agent --test\n</code></pre> Check a resource state<pre><code>puppet resource service nginx\n</code></pre></p>"},{"location":"08_Configuration_Management/#example-manifest","title":"Example Manifest","text":"<pre><code>class nginx {\n  package { 'nginx':\n  ensure =&gt; installed,\n}\n\nservice { 'nginx': \n  ensure =&gt; running, \n  enable =&gt; true,\n}\n\nfile { '/var/www/html/index.html':\n  content =&gt; '&lt;h1&gt;Welcome to Puppet&lt;/h1&gt;', \n  mode =&gt; '0644',\n  }\n}\n\ninclude nginx\n</code></pre>"},{"location":"08_Configuration_Management/#saltstack-states-grains","title":"SaltStack (states, grains)","text":""},{"location":"08_Configuration_Management/#basic-concepts_2","title":"Basic Concepts","text":"<ul> <li><code>State</code> - Defines configurations and how they should be enforced.</li> <li><code>Grain</code> - System metadata like OS, CPU, and memory.</li> <li><code>Pillar</code> - Secure data storage for variables.</li> <li><code>Minion</code> - A node managed by the Salt master.</li> <li><code>Master</code> - The central server controlling minions.</li> </ul>"},{"location":"08_Configuration_Management/#commands_2","title":"Commands","text":"<p>Check connectivity with minions<pre><code>salt '*' test.ping\n</code></pre> Install a package on all minions<pre><code>salt '*' pkg.install nginx\n</code></pre> Start a service<pre><code>salt '*' service.start nginx\n</code></pre> Show all grains for a minion<pre><code>salt '*' grains.items\n</code></pre> Apply a state to minions<pre><code>salt '*' state.apply webserver\n</code></pre></p>"},{"location":"08_Configuration_Management/#example-state-nginxsls","title":"Example State (nginx.sls)","text":"<pre><code>nginx:\n  pkg.installed: []\n  service.running:\n  - enable: true\n\n/var/www/html/index.html:\n  file.managed:\n  - source: salt://webserver/index.html\n  - mode: 644\n</code></pre>"},{"location":"09_Monitoring_Logging/","title":"Monitoring &amp; Logging","text":"<ul> <li>Prometheus &amp; Grafana</li> <li>ELK Stack (Elasticsearch, Logstash, Kibana)</li> <li>Datadog</li> <li>New Relic</li> </ul>"},{"location":"09_Monitoring_Logging/#prometheus-grafana","title":"Prometheus &amp; Grafana","text":""},{"location":"09_Monitoring_Logging/#prometheus-cli-commands","title":"Prometheus CLI Commands","text":"<p>Check Prometheus version<pre><code>prometheus --version\n</code></pre> Start Prometheus<pre><code>prometheus --config.file=prometheus.yml\n</code></pre> Reload Prometheus configuration<pre><code>curl -X POST http://localhost:9090/-/reload\n</code></pre> List active targets<pre><code>curl http://localhost:9090/api/v1/targets\n</code></pre> Query Prometheus API<pre><code>curl http://localhost:9090/api/v1/query?query=up\n</code></pre> View Prometheus metrics<pre><code>curl http://localhost:9090/metrics\n</code></pre> List running alerts<pre><code>curl http://localhost:9090/api/v1/alerts\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#prometheus-configuration-prometheusyml","title":"Prometheus Configuration (prometheus.yml)","text":"<pre><code>scrape_configs:\n  - job_name: 'node'\n    static_configs:\n    - targets: ['localhost:9100']\n  - job_name: 'kubernetes'\n    static_configs:\n    - targets: ['kube-state-metrics:8080']\n</code></pre>"},{"location":"09_Monitoring_Logging/#prometheus-alert-manager-configuration-alertmanageryml","title":"Prometheus Alert Manager Configuration (alertmanager.yml)","text":"<pre><code>route:\n  receiver: 'slack'\n\nreceivers:\n  - name: 'slack'\n    slack_configs:\n    - channel: '#alerts'\n      send_resolved: true\n      api_url: 'https://hooks.slack.com/services/your_webhook_url'\n</code></pre>"},{"location":"09_Monitoring_Logging/#useful-promql-queries","title":"Useful PromQL Queries","text":"<p>Check target availability<pre><code>up\n</code></pre> CPU usage<pre><code>100 - (avg by(instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) \\* 100)\n</code></pre> Memory usage<pre><code>(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) \\* 100\n</code></pre> HTTP request count<pre><code>sum(rate(http_requests_total[5m]))\n</code></pre> Disk space usage<pre><code>node_filesystem_free_bytes / node_filesystem_size_bytes \\* 100\n</code></pre> Active Kubernetes pods<pre><code>count(kube_pod_status_phase{phase=\"Running\"})\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#grafana-cli-commands","title":"Grafana CLI Commands","text":"<p>Check Grafana version<pre><code>grafana-server -v\n</code></pre> Start Grafana<pre><code>systemctl start grafana-server\n</code></pre> Stop Grafana<pre><code>systemctl stop grafana-server\n</code></pre> Restart Grafana<pre><code>systemctl restart grafana-server\n</code></pre> Enable Grafana on boot<pre><code>systemctl enable grafana-server\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#grafana-api-commands","title":"Grafana API Commands","text":"<p>List dashboards<pre><code>curl -X GET http://localhost:3000/api/search\\?query\\=\\&amp;type\\=dash-db -H \"Authorization: Bearer &lt;API_TOKEN&gt;\"\n</code></pre> Create dashboard<pre><code>curl -X POST http://localhost:3000/api/dashboards/db -H \"Content-Type: application/json\" -H \"Authorization: Bearer &lt;API_TOKEN&gt;\" --data '@dashboard.json'\n</code></pre> Add Prometheus data source<pre><code>curl -X POST http://localhost:3000/api/datasources -H \"Content-Type:application/json\" -H \"Authorization: Bearer &lt;API_TOKEN&gt;\" --data '{ \"name\":\"Prometheus\", \"type\": \"prometheus\", \"url\": \"http://localhost:9090\", \"access\":\"proxy\" }'\n</code></pre> List all users<pre><code>curl -X GET http://localhost:3000/api/users -H \"Authorization: Bearer &lt;API_TOKEN&gt;\"\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#integrating-prometheus-with-grafana","title":"Integrating Prometheus with Grafana","text":"<ol> <li>Add Prometheus Data Source in Grafana<ul> <li>Grafana \u2192 Configuration \u2192 Data Sources \u2192 Add Prometheus</li> <li>Set URL to http://localhost:9090</li> <li>Click Save &amp; Test</li> </ul> </li> <li>Import a Prebuilt Dashboard<ul> <li>Grafana \u2192 Dashboards \u2192 Import</li> <li>Enter Dashboard ID from Grafana Repository</li> <li>Select Prometheus as data source \u2192 Import</li> </ul> </li> <li>Create a New Dashboard<ul> <li>Grafana \u2192 Dashboards \u2192 New Dashboard</li> <li>Add PromQL queries for visualization</li> <li>Choose Panel Type (Graph, Gauge, Table, etc.)</li> <li>Click Save Dashboard</li> </ul> </li> </ol>"},{"location":"09_Monitoring_Logging/#grafana-alerting-setup","title":"Grafana Alerting Setup","text":""},{"location":"09_Monitoring_Logging/#create-alert-in-grafana","title":"Create Alert in Grafana","text":"<ol> <li>Open Dashboard \u2192 Edit Panel</li> <li>Click Alert \u2192 Create Alert</li> <li>Set Condition (e.g., CPU usage &gt; 80%)</li> <li>Define Evaluation Interval (e.g., Every 1 min)</li> <li>Configure Notification Channels (Slack, Email, PagerDuty, etc.)</li> <li>Click Save Alert</li> </ol>"},{"location":"09_Monitoring_Logging/#configure-slack-alerts-in-grafana","title":"Configure Slack Alerts in Grafana","text":"<ol> <li>Grafana \u2192 Alerting \u2192 Notification Channels</li> <li>Click Add New Channel</li> <li>Select Slack, enter Webhook URL</li> <li>Click Save &amp; Test</li> </ol>"},{"location":"09_Monitoring_Logging/#elk-stack-elasticsearch-logstash-kibana","title":"ELK Stack (Elasticsearch, Logstash, Kibana)","text":""},{"location":"09_Monitoring_Logging/#1-elasticsearch-commands","title":"1. Elasticsearch Commands","text":""},{"location":"09_Monitoring_Logging/#elasticsearch-cli-commands","title":"Elasticsearch CLI Commands","text":"<p>Check Elasticsearch version<pre><code>elasticsearch --version\n</code></pre> Start Elasticsearch<pre><code>systemctl start elasticsearch\n</code></pre> Stop Elasticsearch<pre><code>systemctl stop elasticsearch\n</code></pre> Restart Elasticsearch<pre><code>systemctl restart elasticsearch\n</code></pre> Enable Elasticsearch on boot<pre><code>systemctl enable elasticsearch\n</code></pre> Check Elasticsearch status<pre><code>curl -X GET \"http://localhost:9200\"\n</code></pre> Cluster health<pre><code>curl -X GET \"http://localhost:9200/_cluster/health?pretty\"\n</code></pre> List cluster nodes<pre><code>curl -X GET \"http://localhost:9200/_cat/nodes?v\"\n</code></pre> List all indices<pre><code>curl -X GET \"http://localhost:9200/_cat/indices?v\"\n</code></pre> Delete an index<pre><code>curl -X DELETE \"http://localhost:9200/index_name\"\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#index-management","title":"Index Management","text":"<p>Create an index<pre><code>curl -X PUT \"http://localhost:9200/index\\_name\"\n</code></pre> Search index<pre><code>curl -X GET \"http://localhost:9200/index\\_name/\\_search?pretty\"\n</code></pre> Insert a document<pre><code>curl -X PUT \"http://localhost:9200/index\\_name/\\_doc/1\" -H \"Content-Type: application/json\" -d '{\"name\": \"DevOps\"}'\n</code></pre> Retrieve a document<pre><code>curl -X GET \"http://localhost:9200/index\\_name/\\_doc/1?pretty\"\n</code></pre> Delete a document<pre><code>curl -X DELETE \"http://localhost:9200/index\\_name/\\_doc/1\"\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#elasticsearch-query-examples","title":"Elasticsearch Query Examples","text":"<p>Search for 'DevOps'<pre><code>curl -X GET \"http://localhost:9200/index\\_name/\\_search?q=name:DevOps&amp;pretty\"\n</code></pre> Query using JSON<pre><code>curl -X GET \"http://localhost:9200/index\\_name/\\_search\" -H \"Content-Type: application/json\" -d '{ \"query\": { \"match\": { \"name\": \"DevOps\" } } }'\n</code></pre> Get all documents<pre><code>curl -X GET \"http://localhost:9200/index\\_name/\\_search?pretty\" -H \"Content-Type: application/json\" -d '{ \"size\": 10, \"query\": { \"match_all\": {} } }'\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#2-logstash-commands","title":"2. Logstash Commands","text":""},{"location":"09_Monitoring_Logging/#logstash-cli-commands","title":"Logstash CLI Commands","text":"<p>Check Logstash version<pre><code>logstash --version\n</code></pre> Start Logstash with a config file<pre><code>logstash -f /etc/logstash/logstash.conf\n</code></pre> Start Logstash<pre><code>systemctl start logstash\n</code></pre> Stop Logstash<pre><code>systemctl stop logstash\n</code></pre> Restart Logstash<pre><code>systemctl restart logstash\n</code></pre> Enable Logstash on boot<pre><code>systemctl enable logstash\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#sample-logstash-configuration-logstashconf","title":"Sample Logstash Configuration (logstash.conf)","text":"<pre><code>input {\n  file {\n    path =&gt; \"/var/log/syslog\" \n    start_position =&gt; \"beginning\"\n  }\n}\n\nfilter {\n  grok {\n    match =&gt; {\n      \"message\" =&gt; \"%{SYSLOGTIMESTAMP:timestamp} %{HOSTNAME:host} %{DATA:process}: %{GREEDYDATA:log_message}\"\n      }\n  }\n}\n\noutput { \n  elasticsearch {\n    hosts =&gt; [\"http://localhost:9200\"] \n    index =&gt; \"logstash-logs\"\n  }\n  stdout { codec =&gt; rubydebug }\n}\n</code></pre>"},{"location":"09_Monitoring_Logging/#3-kibana-commands","title":"3. Kibana Commands","text":""},{"location":"09_Monitoring_Logging/#kibana-cli-commands","title":"Kibana CLI Commands","text":"<p>Check Kibana version<pre><code>kibana --version\n</code></pre> Start Kibana<pre><code>systemctl start kibana\n</code></pre> Stop Kibana<pre><code>systemctl stop kibana\n</code></pre> Restart Kibana<pre><code>systemctl restart kibana\n</code></pre> Enable Kibana on boot<pre><code>systemctl enable kibana\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#kibana-api-commands","title":"Kibana API Commands","text":"<p>Check Kibana status<pre><code>curl -X GET \"http://localhost:5601/api/status\" -H \"kbn-xsrf: true\"\n</code></pre> List all Kibana spaces<pre><code>curl -X GET \"http://localhost:5601/api/spaces/space\" -H \"kbn-xsrf: true\"\n</code></pre></p> Kibana Dashboard Import Example<pre><code>curl -X POST \"http://localhost:5601/api/saved\\_objects/\\_import\" -H \"kbn-xsrf: true\" --form file=@dashboard.ndjson\n</code></pre>"},{"location":"09_Monitoring_Logging/#4-integrating-elk-stack","title":"4. Integrating ELK Stack","text":""},{"location":"09_Monitoring_Logging/#1-configure-elasticsearch-in-kibana","title":"1. Configure Elasticsearch in Kibana","text":"<ul> <li>Go to Kibana \u2192 Management \u2192 Stack Management \u2192 Data Views</li> <li>Click Create Data View</li> <li>Set Index Pattern as logstash-*</li> <li>Click Save</li> </ul>"},{"location":"09_Monitoring_Logging/#2-configuring-logstash-to-send-logs-to-elasticsearch","title":"2. Configuring Logstash to Send Logs to Elasticsearch","text":"<ul> <li>Open <code>/etc/logstash/logstash.conf</code></li> <li>Ensure the output points to Elasticsearch:</li> </ul> <pre><code>output { \n  elasticsearch {\n    hosts =&gt; [\"http://localhost:9200\"] \n    index =&gt; \"logstash-logs\"\n  }\n}\n</code></pre> Restart Logstash:<pre><code>systemctl restart logstash\n</code></pre>"},{"location":"09_Monitoring_Logging/#5-visualizing-logs-in-kibana","title":"5. Visualizing Logs in Kibana","text":"<ul> <li>Go to Kibana \u2192 Discover</li> <li>Select logstash-* Data View</li> <li>Apply Filters &amp; View Logs</li> </ul>"},{"location":"09_Monitoring_Logging/#6-elk-stack-monitoring","title":"6. ELK Stack Monitoring","text":""},{"location":"09_Monitoring_Logging/#monitor-elasticsearch-cluster-health","title":"Monitor Elasticsearch Cluster Health","text":"<p>Get Cluster health<pre><code>curl -X GET \"http://localhost:9200/_cluster/health?pretty\"\n</code></pre> Get Node health<pre><code>curl -X GET \"http://localhost:9200/_cat/nodes?v\"\n</code></pre> Get index health<pre><code>curl -X GET \"http://localhost:9200/_cat/indices?v\"\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#monitor-logstash-logs","title":"Monitor Logstash Logs","text":"<p><pre><code>tail -f /var/log/logstash/logstash-plain.log\n</code></pre> <pre><code>journalctl -u logstash -f\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#monitor-kibana-logs","title":"Monitor Kibana Logs","text":"<p><pre><code>tail -f /var/log/kibana/kibana.log\n</code></pre> <pre><code>journalctl -u kibana -f\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog","title":"Datadog","text":""},{"location":"09_Monitoring_Logging/#datadog-agent-installation-linux","title":"Datadog Agent Installation (Linux)","text":"<pre><code>DD_API_KEY=your_api_key bash -c \"$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)\"\n</code></pre>"},{"location":"09_Monitoring_Logging/#enable-log-monitoring","title":"Enable Log Monitoring","text":"<p><pre><code>sudo nano /etc/datadog-agent/datadog.yaml\n</code></pre> <pre><code>logs_enabled: true\n</code></pre> <pre><code>systemctl restart datadog-agent\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-agent-cli-commands","title":"Datadog Agent CLI Commands","text":"<p>Check Datadog agent version<pre><code>datadog-agent version\n</code></pre> Check Datadog agent status<pre><code>datadog-agent status\n</code></pre> Run a specific check<pre><code>datadog-agent check &lt;integration&gt;\n</code></pre> Gather logs and configuration for<pre><code>datadog-agent flare troubleshooting\n</code></pre> Start Datadog agent<pre><code>systemctl start datadog-agent\n</code></pre> Stop Datadog agent<pre><code>systemctl stop datadog-agent\n</code></pre> Restart Datadog agent<pre><code>systemctl restart datadog-agent\n</code></pre> Enable Datadog agent on boot<pre><code>systemctl enable datadog-agent\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#metric-queries","title":"Metric Queries","text":"<p>CPU usage<pre><code>avg:system.cpu.user{*}\n</code></pre> Top 5 disk users<pre><code>top(avg:system.disk.used{*}, 5, 'mean')\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-api-commands","title":"Datadog API Commands","text":"List all metrics<pre><code>curl -X GET \"https://api.datadoghq.com/api/v1/metrics\" -H \"DD-API-KEY:&lt;API_KEY&gt;\"\n</code></pre> Submit a custom metric<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/series\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n-H \"Content-Type: application/json\" \\\n--data '{ \"series\": [{ \"metric\": \"custom.metric\", \"points\": [[1633000000, 10]],\"type\": \"gauge\", \"tags\": [\"env:prod\"] }] }'\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-configuration","title":"Datadog Configuration","text":"/etc/datadog-agent/datadog.yaml<pre><code>api_key: \"&lt;YOUR_API_KEY&gt;\"\nsite: \"datadoghq.com\"\napm_config:\n  enabled: true\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-log-collection-setup","title":"Datadog Log Collection Setup","text":"<p>/etc/datadog-agent/datadog.yaml<pre><code>logs_enabled: true\n</code></pre> <pre><code>systemctl restart datadog-agent\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#monitor-logs-in-datadog-ui","title":"Monitor Logs in Datadog UI","text":"<ol> <li>Go to Datadog \u2192 Logs \u2192 Live Tail</li> <li>Filter logs by service, environment, or host</li> </ol>"},{"location":"09_Monitoring_Logging/#datadog-monitoring-commands","title":"Datadog Monitoring Commands","text":"<p>Check configuration validity<pre><code>datadog-agent configcheck\n</code></pre> Get the hostname recognized by Datadog<pre><code>datadog-agent hostname\n</code></pre> Check agent health<pre><code>datadog-agent health\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-kubernetes-agent-installation","title":"Datadog Kubernetes Agent Installation","text":"<p><pre><code>kubectl create secret generic datadog-secret --from-literal=api-key=&lt;YOUR_API_KEY&gt;\n</code></pre> <pre><code>kubectl apply -f https://raw.githubusercontent.com/DataDog/datadog-agent/main/Dockerfiles/manifests/agent.yaml\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-kubernetes-monitoring","title":"Datadog Kubernetes Monitoring","text":"<p>List Datadog agent pods<pre><code>kubectl get pods -n datadog\n</code></pre> Check logs of a Datadog agent pod<pre><code>kubectl logs -n datadog &lt;pod-name&gt;\n</code></pre> Describe Datadog agent pod<pre><code>kubectl describe pod &lt;pod-name&gt; -n datadog\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-integrations-for-devops","title":"Datadog Integrations for DevOps","text":"<p>Install Docker integration<pre><code>datadog-agent integration install -t docker\n</code></pre> Install Kubernetes integration<pre><code>datadog-agent integration install -t kubernetes\n</code></pre> Install AWS integration<pre><code>datadog-agent integration install -t aws\n</code></pre> Install Prometheus integration<pre><code>datadog-agent integration install -t prometheus\n</code></pre> Install Jenkins integration<pre><code>datadog-agent integration install -t jenkins\n</code></pre> Install GitLab integration<pre><code>datadog-agent integration install -t gitlab\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-log-collection-for-docker","title":"Datadog Log Collection for Docker","text":"<pre><code>docker run -d --name datadog-agent \\\n-e DD_API_KEY=&lt;YOUR_API_KEY&gt; \\\n-e DD_LOGS_ENABLED=true \\\n-e DD_CONTAINER_EXCLUDE=\"name:datadog-agent\" \\\n-v /var/run/docker.sock:/var/run/docker.sock:ro \\\n-v /proc/:/host/proc/:ro \\\n-v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \\\ndatadog/agent\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-apm-application-performance-monitoring","title":"Datadog APM (Application Performance Monitoring)","text":"<p>Check trace agent status<pre><code>datadog-agent trace-agent status\n</code></pre> Show trace agent configuration<pre><code>datadog-agent trace-agent config\n</code></pre> Restart the trace agent<pre><code>datadog-agent trace-agent restart\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#datadog-cicd-monitoring","title":"Datadog CI/CD Monitoring","text":"Track CI/CD pipeline duration<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/series\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n-H \"Content-Type: application/json\" \\\n--data '{ \"series\": [{ \"metric\": \"ci.pipeline.duration\", \"points\": [[1633000000, 30]], \"type\": \"gauge\", \"tags\": [\"pipeline:deploy\"] }] }'\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-synthetic-monitoring-api-tests","title":"Datadog Synthetic Monitoring (API Tests)","text":"<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/synthetics/tests\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n-H \"Content-Type: application/json\" \\\n--data '{\n  \"config\": { \"request\": { \"method\": \"GET\", \"url\": \"https://example.com\" },\n  \"assertions\": [{ \"operator\": \"is\", \"type\": \"statusCode\", \"target\": 200 }] },\n  \"locations\": [\"aws:us-east-1\"],\n  \"message\": \"Website should be reachable\",\n  \"name\": \"Website Availability Test\",\n  \"options\": { \"monitor_options\": { \"renotify_interval\": 0 } },\n  \"tags\": [\"env:prod\"],\n  \"type\": \"api\"\n}'\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-dashboard-alerts","title":"Datadog Dashboard &amp; Alerts","text":""},{"location":"09_Monitoring_Logging/#create-a-new-dashboard","title":"Create a new dashboard","text":"<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/dashboard\" \\\n-H \"Content-Type: application/json\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n--data '{\n \"title\": \"DevOps Dashboard\", \n \"widgets\": [\n    {\n       \"definition\": {\n         \"type\": \"timeseries\", \n         \"requests\": [\n            { \"q\": \"avg:system.cpu.user{*}\" }\n         ]\n       }\n    }\n ]\n}'\n</code></pre>"},{"location":"09_Monitoring_Logging/#create-an-alert","title":"Create an alert","text":"<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/monitor\" \\\n-H \"Content-Type: application/json\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n--data '{\n  \"name\": \"High CPU Usage\", \n  \"type\": \"query alert\",\n  \"query\": \"avg(last_5m):avg:system.cpu.user{*} &gt; 80\", \n  \"message\": \"CPU usage is too high!\",\n  \"tags\": [\"env:prod\"]\n}'\n</code></pre>"},{"location":"09_Monitoring_Logging/#datadog-incident-management","title":"Datadog Incident Management","text":"<pre><code>curl -X POST \"https://api.datadoghq.com/api/v1/incidents\" \\\n-H \"Content-Type: application/json\" \\\n-H \"DD-API-KEY: &lt;API_KEY&gt;\" \\\n--data '{\n  \"data\": {\n  \"type\": \"incidents\",\n  \"attributes\": {\n    \"title\": \"Production Outage\",\n    \"customer_impact_scope\": \"global\",\n    \"customer_impact_duration\": 30,\n    \"severity\": \"critical\",\n    \"state\": \"active\",\n    \"commander\": \"DevOps Team\"\n    }\n  }\n}'\n</code></pre>"},{"location":"09_Monitoring_Logging/#new-relic","title":"New Relic","text":""},{"location":"09_Monitoring_Logging/#install-new-relic-agent","title":"Install New Relic Agent","text":"For Linux Servers<pre><code>curl -Ls https://download.newrelic.com/install/newrelic-cli/scripts/install.sh | newrelic install\n</code></pre>"},{"location":"09_Monitoring_Logging/#query-logs-metrics","title":"Query Logs &amp; Metrics","text":""},{"location":"09_Monitoring_Logging/#nrql-queries-new-relic-query-language","title":"NRQL Queries (New Relic Query Language)","text":"<p><pre><code>SELECT average(cpuPercent) FROM SystemSample SINCE 30 minutes ago\n</code></pre> <pre><code>SELECT count(*) FROM Transaction WHERE appName = 'my-app'\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#new-relic-agent-cli-commands","title":"New Relic Agent CLI Commands","text":"<p>Check New Relic agent version<pre><code>newrelic-daemon -v\n</code></pre> Start New Relic infrastructure agent<pre><code>systemctl start newrelic-infra\n</code></pre> Stop New Relic infrastructure agent<pre><code>systemctl stop newrelic-infra\n</code></pre> Restart New Relic infrastructure agent<pre><code>systemctl restart newrelic-infra\n</code></pre> Enable agent on boot<pre><code>systemctl enable newrelic-infra\n</code></pre> View New Relic agent logs<pre><code>journalctl -u newrelic-infra -f\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#new-relic-api-commands","title":"New Relic API Commands","text":"<p>List all applications<pre><code>curl -X GET \"https://api.newrelic.com/v2/applications.json\" -H \"X-Api-Key:&lt;API_KEY&gt;\" -H \"Content-Type: application/json\"\n</code></pre> List monitored servers<pre><code>curl -X GET \"https://api.newrelic.com/v2/servers.json\" -H \"X-Api-Key:&lt;API_KEY&gt;\"\n</code></pre> Record a deployment<pre><code>curl -X POST \"https://api.newrelic.com/v2/applications/&lt;APP_ID&gt;/deployments.json\" -H \"X-Api-Key:&lt;API_KEY&gt;\" -H \"Content-Type: application/json\" -d '{ \"deployment\": { \"revision\": \"1.0.1\", \"description\": \"New deployment\", \"user\": \"DevOps Team\" } }'\n</code></pre></p>"},{"location":"09_Monitoring_Logging/#new-relic-configuration","title":"New Relic Configuration","text":"/etc/newrelic-infra.yml<pre><code>license_key: \"&lt;YOUR_LICENSE_KEY&gt;\"\nlog_file: /var/log/newrelic-infra.log\ncustom_attributes:\n  environment: production\n</code></pre>"},{"location":"09_Monitoring_Logging/#new-relic-log-monitoring-setup","title":"New Relic Log Monitoring Setup","text":""},{"location":"09_Monitoring_Logging/#enable-log-forwarding","title":"Enable Log Forwarding","text":"Edit: /etc/newrelic-infra.yml:<pre><code>logs:\n  enabled: true\n  include:\n  - /var/log/syslog\n  - /var/log/nginx/access.log\n</code></pre> Restart the agent:<pre><code>systemctl restart newrelic-infra\n</code></pre>"},{"location":"09_Monitoring_Logging/#view-logs-in-new-relic-ui","title":"View Logs in New Relic UI","text":"<ul> <li>Go to New Relic \u2192 Logs</li> <li>Filter logs by application, environment, or tags</li> </ul>"},{"location":"09_Monitoring_Logging/#new-relic-monitoring-commands","title":"New Relic Monitoring Commands","text":"<p>Check agent status<pre><code>newrelic-infra --status\n</code></pre> Run a diagnostic test<pre><code>newrelic-infra --test\n</code></pre></p>"},{"location":"10_Security_Compliance/","title":"Security &amp; Compliance","text":"<ul> <li>SonarQube</li> <li>Trivy</li> <li>OWASP</li> </ul>"},{"location":"10_Security_Compliance/#1-sonarqube-code-analysis","title":"1. SonarQube (Code Analysis)","text":""},{"location":"10_Security_Compliance/#1-install-sonarqube","title":"1. Install SonarQube","text":"<ul> <li>Download SonarQube from the official website: https://www.sonarqube.org/downloads/</li> </ul>"},{"location":"10_Security_Compliance/#extract-the-downloaded-file","title":"Extract the downloaded file:","text":"<p>For Linux/macOS<pre><code>tar -xvzf sonarqube-&lt;version&gt;.zip\n</code></pre> For Windows<pre><code>unzip sonarqube-&lt;version&gt;.zip\n</code></pre></p>"},{"location":"10_Security_Compliance/#2-start-sonarqube-server","title":"2. Start SonarQube server","text":"<p>For Linux/macOS<pre><code>./bin/linux-x86-64/sonar.sh start\n</code></pre> For Windows<pre><code>bin\\windows-x86-64\\StartSonar.bat\n</code></pre></p>"},{"location":"10_Security_Compliance/#3-access-sonarqube-dashboard","title":"3. Access SonarQube dashboard","text":"<ul> <li>Open your browser and go to: http://localhost:9000 (default credentials: admin/admin)</li> </ul>"},{"location":"10_Security_Compliance/#4-install-sonarscanner-if-not-already-installed","title":"4. Install SonarScanner (if not already installed)","text":"<ul> <li>download and install from: https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/</li> </ul>"},{"location":"10_Security_Compliance/#5-configure-sonarscanner","title":"5. Configure SonarScanner","text":"<ul> <li>Set the SonarQube server URL in the <code>sonar-scanner.properties</code> file</li> </ul> <p>Example</p> <p>sonar.host.url=http://localhost:9000</p>"},{"location":"10_Security_Compliance/#6-run-analysis-with-sonarscanner","title":"6. Run analysis with SonarScanner","text":"<pre><code>sonar-scanner -Dsonar.projectKey=&lt;project_key&gt; -Dsonar.sources=&lt;source_directory&gt; -Dsonar.host.url=http://localhost:9000\n</code></pre>"},{"location":"10_Security_Compliance/#7-maven-run-analysis-with-sonarqube","title":"7. Maven: Run analysis with SonarQube","text":"<ul> <li>Add SonarQube plugin to your Maven <code>pom.xml</code></li> </ul> <pre><code>&lt;build&gt;\n  &lt;plugins&gt;\n    &lt;plugin&gt;\n      &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt;\n      &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt;\n      &lt;version&gt;3.9.0.1100&lt;/version&gt;\n    &lt;/plugin&gt;\n  &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <ul> <li>Run SonarQube analysis with Maven</li> </ul> <pre><code>mvn clean verify sonar:sonar -Dsonar.host.url=http://localhost:9000\n</code></pre>"},{"location":"10_Security_Compliance/#8-set-up-sonarqube-in-jenkins","title":"8. Set up SonarQube in Jenkins","text":"<ul> <li>Install SonarQube Scanner Plugin in Jenkins (Manage Jenkins &gt; Manage Plugins &gt; Available &gt; SonarQube Scanner for Jenkins)</li> <li>Configure SonarQube in Jenkins (Manage Jenkins &gt; Configure System &gt; SonarQube Servers)</li> </ul>"},{"location":"10_Security_Compliance/#9-jenkins-pipeline-for-sonarqube-analysis","title":"9. Jenkins Pipeline for SonarQube analysis","text":"<pre><code>pipeline {\n  agent any\n  environment {\n    SONAR_SCANNER_HOME = tool 'SonarQubeScanner'\n  }\n  stages { \n    stage('Checkout') { \n    steps {\n      git 'https://github.com/your-repo.git'\n    }\n  }\n    stage('SonarQube Analysis') { \n      steps {\n        script { \n          withSonarQubeEnv('SonarQubeServer') { \n          sh 'mvn sonar:sonar'\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"10_Security_Compliance/#10-gitlab-cicd-integration-for-sonarqube","title":"10. GitLab CI/CD Integration for SonarQube","text":"<pre><code>stages:\n  - code_analysis\n\nsonarqube_scan:\n  stage: code_analysis\n  image: maven:3.8.7-openjdk-17\n  script:\n  - mvn sonar:sonar -Dsonar.host.url=$SONAR_HOST_URL -Dsonar.login=$SONAR_TOKEN\n  variables:\n    SONAR_HOST_URL: [\"http://sonarqube-server:9000\"](http://sonarqube-server:9000/)\n    SONAR_TOKEN: \"your-sonarqube-token\"\n</code></pre>"},{"location":"10_Security_Compliance/#11-github-actions-integration-for-sonarqube","title":"11. GitHub Actions Integration for SonarQube","text":"<pre><code>name: SonarQube Analysis\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  sonar_scan:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Set up JDK\n      uses: actions/setup-java@v3\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n    - name: Run SonarQube Scan\n      run: mvn sonar:sonar -Dsonar.host.url=$SONAR_HOST_URL -Dsonar.login=$SONAR_TOKEN\n      env:\n        SONAR_HOST_URL: \"http://sonarqube-server:9000\"\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n</code></pre>"},{"location":"10_Security_Compliance/#12-argocd-integration-presync-hook","title":"12. ArgoCD Integration (PreSync Hook)","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: sonarqube-analysis\nannotations:\nargocd.argoproj.io/hook: PreSync\nspec:\n  template:\n    spec:\n      containers:\n      - name: sonar-scanner\n        image: maven:3.8.7-openjdk-17\n        command: [\"mvn\", \"sonar:sonar\"]\n        env:\n        - name: SONAR_HOST_URL\n          value: \"http://sonarqube-server:9000\"\n        - name: SONAR_TOKEN\n          valueFrom:\n            secretKeyRef:\n            name: sonar-secret\n            key: sonar-token\n      restartPolicy: Never\n</code></pre>"},{"location":"10_Security_Compliance/#2-trivy-container-vulnerability-scanning","title":"2. Trivy (Container Vulnerability Scanning)","text":""},{"location":"10_Security_Compliance/#basic-commands","title":"Basic Commands","text":"<p>Scan a Docker image<pre><code>trivy image &lt;image-name&gt;\n</code></pre> Scan a Kubernetes cluster<pre><code>trivy k8s cluster\n</code></pre> Generate a JSON report<pre><code>trivy image --format json -o report.json &lt;image-name&gt;\n</code></pre></p>"},{"location":"10_Security_Compliance/#jenkins-integration","title":"Jenkins Integration","text":"<pre><code>pipeline {\n  agent any \n  stages {\n    stage('Checkout') { \n      steps {\n        git 'https://github.com/your-repo.git'\n        }\n    }\n    stage('Trivy Scan') { \n      steps {\n        sh 'trivy image your-docker-image:latest'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"10_Security_Compliance/#gitlab-cicd-integration","title":"GitLab CI/CD Integration","text":"<pre><code>stages:\n- security_scan\n\ntrivy_scan:\n  stage: security_scan\n  image: aquasec/trivy\n  script:\n  - trivy image your-docker-image:latest --format json -o trivy_report.json\n  artifacts:\n    paths:\n    - trivy_report.json\n</code></pre>"},{"location":"10_Security_Compliance/#github-actions-integration","title":"GitHub Actions Integration","text":"<pre><code>name: Trivy Scan\non:\n  push:\n    branches:\n    - main\n\njobs:\n  trivy_scan:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Run Trivy Scan\n      run: |\n        docker pull your-docker-image:latest\n        trivy image your-docker-image:latest --format json --output trivy_report.json\n    - name: Upload Trivy Report\n      uses: actions/upload-artifact@v4\n      with:\n        name: trivy-report\n        path: trivy_report.json\n</code></pre>"},{"location":"10_Security_Compliance/#argocd-integration-presync-hook","title":"ArgoCD Integration (PreSync Hook)","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: trivy-scan\nannotations:\n  argocd.argoproj.io/hook: PreSync\nspec:\n  template:\n    spec:\n      containers:\n      - name: trivy-scanner\n        image: aquasec/trivy\n        command: [\"trivy\", \"image\", \"your-docker-image:latest\"]\n      restartPolicy: Never\n</code></pre>"},{"location":"10_Security_Compliance/#kubernetes-integration-admission-controller","title":"Kubernetes Integration (Admission Controller)","text":"<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: trivy-webhook\nwebhooks:\n- name: trivy-scan.k8s\n  rules:\n  - apiGroups: [\"\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\"]\n    resources: [\"pods\"]\n  clientConfig:\n    service:\n      name: trivy-webhook-service\n      namespace: security\n      path: /validate\n    admissionReviewVersions: [\"v1\"]\n    sideEffects: None\n</code></pre>"},{"location":"10_Security_Compliance/#3-owasp-dependency-check-software-dependency-analysis","title":"3. OWASP Dependency-Check (Software Dependency Analysis)","text":""},{"location":"10_Security_Compliance/#basic-commands_1","title":"Basic Commands","text":"Run a scan on a project<pre><code>./dependency-check/bin/dependency-check.sh --scan /path/to/project\n</code></pre> Run a scan using Maven plugin<pre><code>mvn org.owasp:dependency-check-maven:check\n</code></pre>"},{"location":"10_Security_Compliance/#jenkins-integration_1","title":"Jenkins Integration","text":"<pre><code>pipeline {\n  agent any \n  stages {\n    stage('Checkout') { \n      steps {\n        git 'https://github.com/your-repo.git'\n      }\n    }\n    stage('OWASP Dependency Check') { \n      steps {\n        sh 'mvn org.owasp:dependency-check-maven:check'\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"10_Security_Compliance/#gitlab-cicd-integration_1","title":"GitLab CI/CD Integration","text":"<pre><code>stages:\n- security_scan\n\nowasp_dependency_check:\n  stage: security_scan\n  image: maven:3.8.7-openjdk-17\n  script:\n  - mvn org.owasp:dependency-check-maven:check\n  artifacts:\n    paths:\n    - target/dependency-check-report.html\n</code></pre>"},{"location":"10_Security_Compliance/#github-actions-integration_1","title":"GitHub Actions Integration","text":"<pre><code>name: OWASP Dependency Check\n\non:\n  push:\n    branches:\n    - main\n\njobs:\n  owasp_dependency_check:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout Code\n      uses: actions/checkout@v4\n    - name: Run OWASP Dependency-Check\n      run: mvn org.owasp:dependency-check-maven:check\n    - name: Upload OWASP Report\n      uses: actions/upload-artifact@v4\n      with:\n        name: owasp-report\n        path: target/dependency-check-report.html\n</code></pre>"},{"location":"10_Security_Compliance/#argocd-integration-presync-hook_1","title":"ArgoCD Integration (PreSync Hook)","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: owasp-dependency-check\nannotations:\n  argocd.argoproj.io/hook: PreSync\nspec:\n  template:\n    spec:\n      containers:\n      - name: owasp-check\n        image: maven:3.8.7-openjdk-17\n        command: [\"mvn\", \"org.owasp:dependency-check-maven:check\"]\n      restartPolicy: Never\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/","title":"Networking, Ports &amp; Load Balancing","text":""},{"location":"11_Networking_Ports_Load_Balancing/#networking-basics","title":"Networking Basics","text":"<ul> <li>IP Addressing<ul> <li>Private IPs: <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code>, <code>192.168.0.0/16</code></li> <li>Public IPs: Assigned by ISPs</li> <li>CIDR Notation: 192.168.1.0/24 (Subnet Mask: 255.255.255.0)</li> </ul> </li> <li>Ports<ul> <li>HTTP: 80</li> <li>HTTPS: 443</li> <li>SSH: 22</li> <li>DNS: 53</li> <li>FTP: 21</li> <li>MySQL: 3306</li> <li>PostgreSQL: 5432</li> </ul> </li> <li>Protocols<ul> <li>TCP (Reliable, connection-based)</li> <li>UDP (Fast, connectionless)</li> <li>ICMP (Used for ping)</li> <li>HTTP(S), FTP, SSH, DNS</li> </ul> </li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#2-network-commands","title":"2. Network Commands","text":""},{"location":"11_Networking_Ports_Load_Balancing/#linux-networking-show-network-interfaces","title":"Linux Networking Show network interfaces","text":"<p>Show IP addresses<pre><code>ip a\n</code></pre> Older command<pre><code>ifconfig\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#check-connectivity","title":"Check connectivity","text":"<p>Check site/host is reachable<pre><code>ping google.com\n</code></pre> Trace route<pre><code>traceroute google.com\n</code></pre> Query Internet name servers<pre><code>nslookup google.com\n</code></pre> DNS lookup<pre><code>dig google.com\n</code></pre> Test ports<pre><code>telnet google.com 80\n\nnc -zv google.com 443\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#firewall-rules-iptables","title":"Firewall Rules (iptables)","text":"<p>List firewall rules<pre><code>sudo iptables -L -v\n</code></pre> Allow SSH<pre><code>sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT\n</code></pre> Block an IP<pre><code>sudo iptables -A INPUT -s 192.168.1.100 -j DROP\n</code></pre> Netcat (nc) Start a simple TCP listener<pre><code>nc -lvp 8080\n</code></pre> Send data to a listening server<pre><code>echo \"Hello\" | nc 192.168.1.100 8080\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#3-kubernetes-networking","title":"3. Kubernetes Networking","text":"<p>List services and their endpoints<pre><code>kubectl get svc -o wide\n</code></pre> Get pods and their IPs<pre><code>kubectl get pods -o wide\n</code></pre> Port forward a service<pre><code>kubectl port-forward svc/my-service 8080:80\n</code></pre> Expose a pod<pre><code>kubectl expose pod mypod --type=NodePort --port=80\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#4-docker-networking","title":"4. Docker Networking","text":"<p>List networks<pre><code>docker network ls\n</code></pre> Inspect a network<pre><code>docker network inspect bridge\n</code></pre> Create a custom network<pre><code>docker network create mynetwork\n</code></pre> Run a container in a custom network<pre><code>docker run -d --network=mynetwork nginx\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#5-cloud-networking-aws-azure-gcp","title":"5. Cloud Networking (AWS, Azure, GCP)","text":""},{"location":"11_Networking_Ports_Load_Balancing/#aws","title":"AWS","text":"<p>List VPCs<pre><code>aws ec2 describe-vpcs\n</code></pre> List subnets<pre><code>aws ec2 describe-subnets\n</code></pre> Open security group port<pre><code>aws ec2 authorize-security-group-ingress --group-id sg-12345 --protocol tcp --port 22 --cidr 0.0.0.0/0\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#azure","title":"Azure","text":"<p>List VNets<pre><code>az network vnet list -o table\n</code></pre> List NSGs<pre><code>az network nsg list -o table\n</code></pre> Open a port in NSG<pre><code>az network nsg rule create --resource-group MyGroup --nsg-name MyNSG --name AllowSSH --protocol Tcp --direction Inbound --priority 100 --source-address-prefixes'\\*' --source-port-ranges '\\*' --destination-port-ranges 22 --access Allow\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#aws-vpc-basics","title":"AWS VPC Basics","text":"<ul> <li>Definition: A logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network.</li> <li>CIDR Block: Define the IP range (e.g., 10.0.0.0/16).</li> <li>Components:<ul> <li>Subnets: Divide your VPC into public (with internet access) and private (without direct internet access) segments.</li> <li>Route Tables: Control the traffic routing for subnets.</li> <li>Internet Gateway (IGW): Allows communication between instances in your VPC and the internet.</li> <li>NAT Gateway/Instance: Enables outbound internet access for instances in private subnets.</li> <li>VPC Peering: Connects multiple VPCs.</li> <li>VPN Connections &amp; Direct Connect: Securely link your on-premises network with your VPC.</li> <li>VPC Endpoints: Privately connect your VPC to supported AWS services.</li> </ul> </li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#security-groups-essentials","title":"Security Groups Essentials","text":"<ul> <li>Definition: Virtual firewalls that control inbound and outbound traffic for your EC2 instances.</li> <li>Key Characteristics:<ul> <li>Stateful: Return traffic is automatically allowed regardless of inbound/outbound rules.</li> <li>Default Behavior: All outbound traffic is allowed; inbound is denied until explicitly allowed.</li> </ul> </li> <li>Rule Components:<ul> <li>Protocol: (TCP, UDP, ICMP, etc.)</li> <li>Port Range: Specific ports or a range (e.g., port 80 for HTTP).</li> <li>Source/Destination: IP addresses or CIDR blocks (e.g., 0.0.0.0/0 for all).</li> </ul> </li> <li>Usage:<ul> <li>Assign one or more security groups to an instance.</li> <li>Modify rules anytime without stopping or restarting the instance.</li> </ul> </li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#common-aws-cli-commands","title":"Common AWS CLI Commands","text":""},{"location":"11_Networking_Ports_Load_Balancing/#vpc-operations","title":"VPC Operations","text":"<p>Create a VPC:<pre><code>aws ec2 create-vpc --cidr-block 10.0.0.0/16\n</code></pre> Create a Subnet:<pre><code>aws ec2 create-subnet --vpc-id &lt;vpc-id&gt; --cidr-block 10.0.1.0/24\n</code></pre> Create &amp; Attach an Internet Gateway:<pre><code>aws ec2 create-internet-gateway\naws ec2 attach-internet-gateway --vpc-id &lt;vpc-id&gt; --internet-gateway-id &lt;igw-id&gt;\n</code></pre> Associate a Route Table:<pre><code>aws ec2 associate-route-table --subnet-id &lt;subnet-id&gt; --route-table-id &lt;rtb-id&gt;\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#security-group-operations","title":"Security Group Operations","text":"<p>Create a Security Group:<pre><code>aws ec2 create-security-group --group-name MySecurityGroup --description \"My security group\" --vpc-id &lt;vpc-id&gt;\n</code></pre> Authorize Inbound Traffic:<pre><code>aws ec2 authorize-security-group-ingress --group-id &lt;sg-id&gt; --protocol tcp --port 80 --cidr 0.0.0.0/0\n</code></pre> Authorize Outbound Traffic (if restricting defaults):<pre><code>aws ec2 authorize-security-group-egress --group-id &lt;sg-id&gt; --protocol tcp --port 443 --cidr 0.0.0.0/0\n</code></pre> List Security Groups:<pre><code>aws ec2 describe-security-groups\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#ports","title":"Ports","text":""},{"location":"11_Networking_Ports_Load_Balancing/#devops-essential-port","title":"DevOps Essential Port","text":""},{"location":"11_Networking_Ports_Load_Balancing/#networking-security","title":"Networking &amp; Security","text":"<ul> <li>SSH <code>22</code> (Secure remote access)</li> <li>FTP <code>21</code> (File Transfer Protocol)</li> <li>SFTP <code>22</code> (Secure File Transfer Protocol)</li> <li>Telnet <code>23</code> (Unsecured remote access)</li> <li>SMTP <code>25, 587</code> (Email sending)</li> <li>DNS <code>53</code> (Domain Name System)</li> <li>DHCP <code>67/68</code> (Dynamic IP assignment)</li> <li>HTTP <code>80</code> (Default web traffic)</li> <li>HTTPS <code>443</code> (Secure web traffic)</li> <li>SMB <code>445</code> (Windows file sharing)</li> <li>LDAP <code>389</code> (Directory services)</li> <li>LDAPS <code>636</code> (Secure LDAP)</li> <li>RDP <code>3389</code> (Remote Desktop Protocol)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#cicd-devops-tools","title":"CI/CD &amp; DevOps Tools","text":"<ul> <li>Jenkins <code>8080</code> (CI/CD automation server)</li> <li>Git <code>9418</code> (Git repository access)</li> <li>SonarQube <code>9000</code> (Code quality analysis)</li> <li>Nexus Repository <code>8081</code> (Artifact repository)</li> <li>Harbor <code>443</code> (Container registry)</li> <li>GitLab CI/CD <code>443, 80, 22</code> (GitLab services &amp; SSH)</li> <li>Bitbucket <code>7990</code> (Bitbucket web UI)</li> <li>TeamCity <code>8111</code> (CI/CD server)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#containerization-orchestration","title":"Containerization &amp; Orchestration","text":"<ul> <li>Docker Registry <code>5000</code> (Private Docker Registry)</li> <li>Kubernetes API Server <code>6443</code> (Cluster API)</li> <li>Kubelet <code>10250</code> (Node agent)</li> <li>ETCD (Kubernetes Storage) <code>2379-2380</code> (Key-value store)</li> <li>Flannel (Kubernetes Networking) <code>8285/8286</code> (Overlay network)</li> <li>Calico (Kubernetes Networking) <code>179</code> (BGP Protocol)</li> <li>Istio Ingress Gateway <code>15021, 15090</code> (Service mesh ingress)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#monitoring-logging","title":"Monitoring &amp; Logging","text":"<ul> <li>Prometheus <code>9090</code> (Metrics monitoring)</li> <li>Grafana <code>3000</code> (Visualization dashboard)</li> <li>Elasticsearch <code>9200</code> (Search &amp; analytics engine)</li> <li>Logstash <code>5044</code> (Log ingestion)</li> <li>Fluentd <code>24224</code> (Log collector)</li> <li>Kibana <code>5601</code> (Log visualization)</li> <li>Loki <code>3100</code> (Log aggregation)</li> <li>Jaeger <code>16686</code> (Tracing UI)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#databases","title":"Databases","text":"<ul> <li>PostgreSQL <code>5432</code> (Relational database)</li> <li>MySQL/MariaDB <code>3306</code> (Relational database)</li> <li>MongoDB <code>27017</code> (NoSQL database)</li> <li>Redis <code>6379</code> (In-memory database)</li> <li>Cassandra <code>9042</code> (NoSQL distributed database)</li> <li>CockroachDB <code>26257</code> (Distributed SQL database)</li> <li>Neo4j <code>7474</code> (Graph database UI), 7687 (Bolt protocol)</li> <li>InfluxDB <code>8086</code> (Time-series database)</li> <li>Couchbase <code>8091</code> (Web UI), 11210 (Data access)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#message-brokers-caching","title":"Message Brokers &amp; Caching","text":"<ul> <li>Kafka <code>9092</code> (Event streaming)</li> <li>RabbitMQ <code>5672</code> (Message broker)</li> <li>ActiveMQ <code>61616</code> (JMS messaging)</li> <li>NATS <code>4222</code> (High-performance messaging)</li> <li>Memcached <code>11211</code> (In-memory caching)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#web-servers-reverse-proxies","title":"Web Servers &amp; Reverse Proxies","text":"<ul> <li>Nginx <code>80, 443</code> (Web server &amp; reverse proxy)</li> <li>Apache HTTP <code>80, 443</code> (Web server)</li> <li>HAProxy <code>443, 80</code> (Load balancer)</li> <li>Caddy <code>2019</code> (API endpoint)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#cloud-services-storage","title":"Cloud Services &amp; Storage","text":"<ul> <li>AWS S3 <code>443</code> (Object storage API)</li> <li>AWS RDS <code>3306, 5432, 1433</code> (Managed databases)</li> <li>Azure Blob Storage <code>443</code> (Storage API)</li> <li>Google Cloud Storage <code>443</code> (Object storage API)</li> <li>MinIO <code>9000</code> (S3-compatible storage)</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#nginx-reverse-proxy-load-balancing","title":"Nginx (Reverse Proxy &amp; Load Balancing)","text":"<p>What is a Reverse Proxy?</p> <p>A Reverse Proxy is a server that forwards client requests to backend servers. It helps:</p> <ul> <li>Improve security by hiding backend servers.</li> <li>Handle traffic and reduce load on backend servers.</li> <li>Improve performance with caching and compression.</li> </ul> <p>What is Load Balancing?</p> <p>Load Balancing distributes traffic across multiple servers to:</p> <ul> <li>Prevent overloading of a single server.</li> <li>Ensure high availability (if one server fails, others handle traffic).</li> <li>Improve speed and performance.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#1-nginx-reverse-proxy-load-balancing","title":"1. Nginx Reverse Proxy &amp; Load Balancing","text":""},{"location":"11_Networking_Ports_Load_Balancing/#reverse-proxy","title":"Reverse Proxy","text":"<p>Reverse Proxy (Forward Requests to Backend)</p> <p>When a user visits example.com, Nginx forwards the request to the backend server.</p> <ul> <li>Configuration File (nginx.conf)</li> </ul> <pre><code>server { \n    listen 80; # Listen for requests on port 80\n    server_name example.com; # Your domain name\n    location / {\n        proxy_pass http://backend_servers; # Forward requests to backend \n        proxy_set_header Host $host; # Keep the original host \n        proxy_set_header X-Real-IP $remote_addr; # Send real client IP \n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre> <p>What This Does:</p> <ul> <li>Nginx forwards requests from example.com to backend servers.</li> <li>proxy_pass tells Nginx where to send traffic.</li> <li>Keeps client IP and host name intact for logs.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#load-balancing","title":"Load Balancing","text":"<p>Load Balancing (Distribute Traffic Across Multiple Servers)</p> <p>Instead of sending all traffic to one server, Nginx distributes it across multiple servers.</p> <ul> <li>Configuration File (nginx.conf)</li> </ul> <pre><code>upstream backend_servers {\n  server server1.example.com; # Backend Server 1 \n  server server2.example.com; # Backend Server 2\n}\nserver {\n  listen 80;\n  server_name example.com;\n\n  location / {\n    proxy_pass http://backend_servers; # Send traffic to multiple backend servers\n  }\n}\n</code></pre> <p>What This Does:</p> <ul> <li>upstream defines multiple backend servers.</li> <li>Traffic is balanced between server1 and server2.</li> <li>Default method: Round-robin (each request goes to the next server).</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#2-apache-reverse-proxy-load-balancing","title":"2. Apache (reverse proxy, load balancing)","text":""},{"location":"11_Networking_Ports_Load_Balancing/#enable-required-modules","title":"Enable Required Modules","text":"<p>Before using Apache as a Reverse Proxy, enable these modules:</p> <p><pre><code>a2enmod proxy\n</code></pre> <pre><code>a2enmod proxy_http\n</code></pre> <pre><code>a2enmod proxy_balancer\n</code></pre> <pre><code>a2enmod lbmethod_byrequests\n</code></pre> <pre><code>systemctl restart apache2 # Restart Apache for changes\n</code></pre></p> <p>What This Does:</p> <p>These modules allow Apache to forward requests and balance traffic.</p>"},{"location":"11_Networking_Ports_Load_Balancing/#reverse-proxy-forward-requests-to-backend-servers","title":"Reverse Proxy (Forward Requests to Backend Servers)","text":"<ul> <li>Configuration File (apache.conf)</li> </ul> <pre><code>&lt;VirtualHost \\*:80&gt;\n  ServerName example.com # Domain handled by Apache\n\n  ProxyPass \"/\" \"http://backend_servers/\" \n  ProxyPassReverse \"/\" \"http://backend_servers/\"\n&lt;/VirtualHost&gt;\n</code></pre> <p>What This Does:</p> <ul> <li>Apache listens on example.com and forwards requests to backend servers.</li> <li>ProxyPassReverse ensures responses return correctly to the client.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#load-balancing-send-traffic-to-multiple-backend-servers","title":"Load Balancing (Send Traffic to Multiple Backend Servers)","text":"<ul> <li>Configuration File (apache.conf)</li> </ul> <pre><code>&lt;Proxy \"balancer://mycluster\"&gt;\n  BalancerMember \"http://server1.example.com\" \n  BalancerMember \"http://server2.example.com\"\n&lt;/Proxy&gt;\n\n&lt;VirtualHost \\*:80&gt;\n  ServerName example.com\n\n  ProxyPass \"/\" \"balancer://mycluster/\"\n  ProxyPassReverse \"/\" \"balancer://mycluster/\"\n&lt;/VirtualHost&gt;\n</code></pre> <p>What This Does:</p> <ul> <li>BalancerMember defines multiple backend servers.</li> <li>Apache automatically distributes traffic using round-robin.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#3-haproxy-load-balancing","title":"3. HAProxy (Load Balancing)","text":"<p>HAProxy is a lightweight and high-performance Load Balancer for web applications.</p>"},{"location":"11_Networking_Ports_Load_Balancing/#install-haproxy","title":"Install HAProxy","text":"<p>Ubuntu/Debian<pre><code>apt install haproxy\n</code></pre> RHEL/CentOS<pre><code>yum install haproxy\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#load-balancing-with-haproxy","title":"Load Balancing with HAProxy","text":"<ul> <li>Configuration File (haproxy.cfg)</li> </ul> <pre><code>frontend http_front\n  bind \\*:80 # Accept traffic on port 80\n  default_backend backend_servers # Forward traffic to backend servers\n\nbackend backend_servers\n  balance roundrobin # Distribute traffic evenly\n  server server1 server1.example.com:80 check # First server\n  server server2 server2.example.com:80 check # Second server\n</code></pre> <p>What This Does:</p> <ul> <li>frontend handles incoming requests.</li> <li>backend defines multiple backend servers.</li> <li>Round-robin ensures traffic is evenly distributed.</li> <li>check makes sure only healthy servers receive traffic.</li> </ul> <p>Restart HAProxy<pre><code>systemctl restart haproxy\n</code></pre> Enable on startup<pre><code>systemctl enable haproxy\n</code></pre></p>"},{"location":"11_Networking_Ports_Load_Balancing/#4-kubernetes-ingress-controller","title":"4. Kubernetes Ingress Controller","text":"<ul> <li>Install Nginx Ingress Controller</li> </ul> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml\n</code></pre> <p>What This Does:</p> <p>Installs Nginx Ingress Controller for managing external traffic in Kubernetes.</p>"},{"location":"11_Networking_Ports_Load_Balancing/#define-an-ingress-resource","title":"Define an Ingress Resource","text":"<ul> <li>Configuration File (ingress.yaml)</li> </ul> <pre><code>apiVersion: networking.k8s.io/v1 \nkind: Ingress\nmetadata:\n name: my-ingress \n annotations:\n  nginx.ingress.kubernetes.io/rewrite-target: / # Optional URL rewrite \nspec:\n  rules:\n  - host: example.com # Define the domain \n    http:\n      paths:\n      - path: / \n        pathType: Prefix\n      backend:\n        service:\n          name: my-service # Forward traffic to this Kubernetes service\n          port:\n            number: 80\n</code></pre> <p>What This Does:</p> <ul> <li>Routes traffic from example.com to my-service inside Kubernetes.</li> <li>Annotations modify behavior (like URL rewriting).</li> </ul> <ul> <li>Verify Ingress is Working</li> </ul> <pre><code>kubectl get ingress kubectl describe ingress my-ingress\n</code></pre> <p>What This Does:</p> <ul> <li>kubectl get ingress \u2192 Checks if Ingress exists.</li> <li>kubectl describe ingress \u2192 Shows detailed configuration.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#which-one-should-you-use","title":"Which One Should You Use?","text":"<ul> <li>For a simple website/API \u2192 Use Nginx Reverse Proxy.</li> <li>For balancing multiple servers \u2192 Use Nginx, Apache, or HAProxy.</li> <li>For Kubernetes applications \u2192 Use Ingress Controller.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#practical-examples-docker-for-nginx-apache-haproxy-and-kubernetes-ingress","title":"Practical Examples: Docker for Nginx, Apache, HAProxy, and Kubernetes Ingress","text":"<ul> <li>Step-by-step practical examples using Docker for Nginx, Apache, HAProxy, and Kubernetes Ingress.</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#1-nginx-reverse-proxy-load-balancer-with-docker","title":"1. Nginx Reverse Proxy &amp; Load Balancer (With Docker)","text":"<p>Scenario:</p> <p>We have two backend servers running a Python Flask application, and we want Nginx to act as a Reverse Proxy and Load Balancer.</p>"},{"location":"11_Networking_Ports_Load_Balancing/#step-1-create-two-backend-servers-flask-create-a-directory-for-the-project","title":"Step 1: Create Two Backend Servers (Flask) Create a directory for the project","text":"<pre><code>mkdir nginx-loadbalancer &amp;&amp; cd nginx-loadbalancer\n</code></pre> <ul> <li>server1.py (Backend Server 1)</li> </ul> <pre><code>from flask import Flask\napp = Flask( name )\n\n@app.route('/')\ndef home():\n  return \"Hello from Server 1\"\n\nif name == ' main ':\n  app.run(host='0.0.0.0', port=5000)\n</code></pre> <ul> <li>server2.py (Backend Server 2)</li> </ul> <pre><code>from flask import Flask\napp = Flask( name )\n\n@app.route('/')\ndef home():\n  return \"Hello from Server 2\"\n\nif name == ' main ':\n  app.run(host='0.0.0.0', port=5000)\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-2-create-a-dockerfile-for-backend-servers-dockerfile","title":"Step 2: Create a Dockerfile for Backend Servers Dockerfile","text":"<pre><code>FROM python:3.9\n\nWORKDIR /app\n\nCOPY server1.py /app/\n\nRUN pip install flask\n\nCMD [\"python\", \"server1.py\"]\n</code></pre> <p>For server2.py, create another Dockerfile and replace <code>server1.py</code> with <code>server2.py</code></p>"},{"location":"11_Networking_Ports_Load_Balancing/#step-3-create-an-nginx-configuration-file-nginxconf","title":"Step 3: Create an Nginx Configuration File nginx.conf","text":"<pre><code>events {}\nhttp {\n  upstream backend_servers {\n    server server1:5000;\n    server server2:5000;\n  }\n\n  server {\n    listen 80;\n    server_name localhost;\n    location / {\n      proxy_pass http://backend_servers;\n      proxy_set_header Host $host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n  }\n}\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-4-create-a-docker-compose-file","title":"Step 4: Create a Docker Compose File","text":"<ul> <li>docker-compose.yml</li> </ul> <pre><code>version: '3'\nservices:\n  server1:\n    build: .\n    container_name:server1\n    ports:\n    - \"5001:5000\"\n\n  server2:\n    build: .\n    container_name:server2\n    ports:\n    - \"5002:5000\"\n\n  nginx:\n    image: nginx:latest\n    container_name: nginx_proxy\n    ports:\n    - \"80:80\"\n    volumes:\n    - ./nginx.conf:/etc/nginx/nginx.conf\n    depends_on:\n    - server1\n    - server2\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-5-run-the-containers","title":"Step 5: Run the Containers","text":"<pre><code>docker-compose up --build\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-6-test-load-balancing-run-the-following-command","title":"Step 6: Test Load Balancing Run the following command","text":"<pre><code>curl http://localhost\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#expected-output-requests-will-alternate","title":"Expected Output (requests will alternate)","text":"<ul> <li>Hello from Server 1</li> <li>Hello from Server 2</li> <li>Hello from Server 1</li> <li>Hello from Server 2</li> </ul>"},{"location":"11_Networking_Ports_Load_Balancing/#2-apache-reverse-proxy-load-balancer-with-docker","title":"2. Apache Reverse Proxy &amp; Load Balancer (With Docker)","text":""},{"location":"11_Networking_Ports_Load_Balancing/#step-1-create-apache-configuration-file-apacheconf","title":"Step 1: Create Apache Configuration File <code>apache.conf</code>","text":"<pre><code>&lt;VirtualHost \\*:80&gt;\n  ServerName localhost\n  &lt;Proxy \"balancer://mycluster\"&gt;\n    BalancerMember \"http://server1:5000\"\n    BalancerMember \"http://server2:5000\"\n  &lt;/Proxy&gt;\n\n  ProxyPass \"/\" \"balancer://mycluster/\"\n  ProxyPassReverse \"/\" \"balancer://mycluster/\"\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-2-create-docker-composeyml-for-apache","title":"Step 2: Create docker-compose.yml for Apache","text":"<pre><code>version: '3'\nservices:\n  server1:\n    build: .\n    container_name:server1\n    ports:\n    - \"5001:5000\"\n  server2:\n    build: .\n    container_name:server2\n    ports:\n    - \"5002:5000\"\n  apache:\n    image: httpd:latest\n    container_name: apache_proxy\n    ports:\n    - \"80:80\"\n    volumes:\n    - ./apache.conf:/usr/local/apache2/conf/httpd.conf\n    depends_on:\n    - server1\n    - server2\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-3-run-apache-proxy","title":"Step 3: Run Apache Proxy","text":"<pre><code>docker-compose up --build\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#3-haproxy-load-balancer-with-docker","title":"3. HAProxy Load Balancer (With Docker)","text":""},{"location":"11_Networking_Ports_Load_Balancing/#step-1-create-haproxy-configuration-file-haproxycfg","title":"Step 1: Create HAProxy Configuration File <code>haproxy.cfg</code>","text":"<pre><code>frontend http_front\n  bind \\*:80\n  default_backend backend_servers\nbackend backend_servers\n  balance roundrobin\n  server server1 server1:5000 check\n  server server2 server2:5000 check\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-2-create-docker-composeyml-for-haproxy","title":"Step 2: Create <code>docker-compose.yml</code> for HAProxy","text":"<pre><code>version: '3'\nservices:\n  server1:\n    build: .\n    container_name:server1\n    ports:\n    - \"5001:5000\"\n  server2:\n    build: .\n    container_name:server2\n    ports:\n    - \"5002:5000\"\n  haproxy:\n    image: haproxy:latest\n    container_name: haproxy_loadbalancer\n    ports:\n    - \"80:80\"\n    volumes:\n    - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg\n    depends_on:\n    - server1\n    - server2\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-3-run-haproxy","title":"Step 3: Run HAProxy","text":"<pre><code>docker-compose up --build\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#4-kubernetes-ingress-controller_1","title":"4. Kubernetes Ingress Controller","text":""},{"location":"11_Networking_Ports_Load_Balancing/#step-1-deploy-nginx-ingress-controller","title":"Step 1: Deploy Nginx Ingress Controller","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-2-create-ingress-resource","title":"Step 2: Create Ingress Resource","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ingress\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n        service:\n          name: my-service\n          port:\n            number: 80\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#step-3-apply-ingress","title":"Step 3: Apply Ingress","text":"<pre><code>kubectl apply -f ingress.\n</code></pre>"},{"location":"11_Networking_Ports_Load_Balancing/#comparison-table","title":"Comparison Table","text":"<ul> <li>Nginx: Reverse Proxy (forwards requests to backend servers), Load Balancing (distributes traffic across servers)</li> <li>Apache: Reverse Proxy (similar to Nginx), Load Balancing (balances traffic using a balancer)</li> <li>HAProxy: Load Balancing (efficient traffic handling)</li> <li>Kubernetes Ingress: Traffic Routing (manages external traffic in Kubernetes)</li> </ul>"},{"location":"12_Databases/","title":"Database Cheat Sheet","text":"<ul> <li>SQL Database</li> <li>NoSQL Database</li> <li>Database Automation</li> <li>Deploy MongoDB with Docker</li> </ul> <p>Databases are essential for CI/CD pipelines, monitoring, logging, and cloud automation. DevOps engineers interact with databases to store configurations, manage infrastructure state, and automate deployments. This guide covers SQL, NoSQL, and cloud databases with relevant DevOps commands and use cases.</p>"},{"location":"12_Databases/#database-automation-for-devops","title":"Database Automation for DevOps","text":"<p>Why Automate Databases in DevOps?</p> <ul> <li>Eliminate manual work in database provisioning, backup, and monitoring</li> <li>Ensure consistency across environments (dev, staging, production)</li> <li>Reduce downtime with automated backups and performance monitoring</li> <li>Enable CI/CD pipelines to manage database migrations</li> </ul>"},{"location":"12_Databases/#1-sql-databases-mysql-postgresql-mariadb","title":"1. SQL Databases (MySQL, PostgreSQL, MariaDB)","text":""},{"location":"12_Databases/#database-management","title":"Database Management","text":"<p>List databases<pre><code>SHOW DATABASES;\n</code></pre> Create a database<pre><code>CREATE DATABASE db_name;\n</code></pre> Delete a database<pre><code>DROP DATABASE db_name;\n</code></pre> Select a database<pre><code>USE db_name;\n</code></pre></p>"},{"location":"12_Databases/#user-management","title":"User Management","text":"<p><pre><code>CREATE USER 'devops'@'localhost' IDENTIFIED BY 'password';\n</code></pre> <pre><code>GRANT ALL PRIVILEGES ON db_name.\\* TO 'devops'@'localhost';\n</code></pre></p>"},{"location":"12_Databases/#table-data-operations","title":"Table &amp; Data Operations","text":"<p>List tables<pre><code>SHOW TABLES;\n</code></pre> <pre><code>INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com');\n</code></pre> <pre><code>SELECT * FROM users;\n</code></pre></p>"},{"location":"12_Databases/#backup-restore","title":"Backup &amp; Restore","text":"<p>Backup MySQL<pre><code>mysqldump -u root -p db_name &gt; backup.sql\n</code></pre> Restore MySQL<pre><code>mysql -u root -p db_name &lt; backup.sql\n</code></pre></p>"},{"location":"12_Databases/#2-nosql-databases","title":"2. NoSQL Databases","text":""},{"location":"12_Databases/#mongodb","title":"MongoDB","text":"<p>List databases<pre><code>show dbs;\n</code></pre> Select a database<pre><code>use mydb;\n</code></pre> Create a collection<pre><code>db.createCollection(\"users\");\n</code></pre> Insert data<pre><code>db.users.insertOne({name: \"Alice\"});\n</code></pre> Backup<pre><code>mongodump --out /backup/\n</code></pre></p>"},{"location":"12_Databases/#redis","title":"Redis","text":"<p>Store a key<pre><code>SET key \"value\";\n</code></pre> Retrieve value<pre><code>GET key;\n</code></pre> Delete key<pre><code>DEL key;\n</code></pre></p>"},{"location":"12_Databases/#cassandra-cql","title":"Cassandra (CQL)","text":"<p><pre><code>CREATE KEYSPACE mykeyspace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\n</code></pre> <pre><code>CREATE TABLE users (id UUID PRIMARY KEY, name TEXT);\n</code></pre></p>"},{"location":"12_Databases/#3-database-automation","title":"3. Database Automation","text":""},{"location":"12_Databases/#terraform-for-aws-rds","title":"Terraform for AWS RDS","text":"<pre><code>resource \"aws_db_instance\" \"default\" { \n  identifier = \"devops-db\"\n  engine = \"mysql\" \n  instance_class = \"db.t3.micro\" \n  allocated_storage = 20\n}\n</code></pre>"},{"location":"12_Databases/#docker-database-containers","title":"Docker Database Containers","text":"<p><pre><code>docker run -d --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 mysql\n</code></pre> <pre><code>docker run -d --name postgres -e POSTGRES_PASSWORD=root -p 5432:5432 postgres\n</code></pre></p>"},{"location":"12_Databases/#automating-mysql-with-ansible","title":"Automating MySQL with Ansible","text":"<pre><code>- name: Install MySQL\n  hosts: db_servers\n  become: yes\n  tasks:\n  - name: Install MySQL\n    apt: name=mysql-server state=present\n  - name: Create Database\n    mysql_db: name=devops_db state=present\n</code></pre>"},{"location":"12_Databases/#jenkins-pipeline-for-database-backup","title":"Jenkins Pipeline for Database Backup","text":"<pre><code>pipeline {\n  agent any\n  stages {\n    stage('Backup') {\n      steps { sh 'mysqldump -u root -p$MYSQL_ROOT_PASSWORD db &gt; /backup/db.sql' }\n    }\n    stage('Restore') {\n      steps { sh 'mysql -u root -p$MYSQL_ROOT_PASSWORD db &lt; /backup/db.sql' }\n    }\n  }\n}\n</code></pre>"},{"location":"12_Databases/#database-monitoring-mysql-prometheus-grafana","title":"Database Monitoring (MySQL + Prometheus &amp; Grafana)","text":"<pre><code>wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.14.0/mysql d_exporter.tar.gz\n</code></pre> <pre><code>tar xvf mysqld_exporter.tar.gz &amp;&amp; mv mysqld_exporter /usr/local/bin/\n</code></pre> <pre><code>mysqld_exporter --config.my-cnf=/etc/.my.cnf &amp;\n</code></pre>"},{"location":"12_Databases/#4-deploying-mongodb-with-docker-compose","title":"4. Deploying MongoDB with Docker Compose","text":"<pre><code>version: '3.8'\nservices:\n  mongo:\n    image: mongo\n    container_name: mongodb\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: admin\n      MONGO_INITDB_ROOT_PASSWORD: DevOps@123\n    ports:\n    - \"27017:27017\"\n</code></pre>"},{"location":"13_Storage/","title":"Storage Cheat Sheet","text":""},{"location":"13_Storage/#storage-types-in-devops","title":"Storage Types in DevOps","text":"<ul> <li>Block Storage \u2013 Used for databases, VMs, containers (e.g., EBS, Cinder)</li> <li>File Storage \u2013 Used for shared access &amp; persistence (e.g., NFS, EFS)</li> <li>Object Storage \u2013 Used for backups, logs, and media (e.g., S3, MinIO)</li> </ul>"},{"location":"13_Storage/#disk-management-linux","title":"Disk Management (Linux)","text":"<p>List disks and partitions<pre><code>lsblk\n</code></pre> List disk partitions<pre><code>fdisk -l\n</code></pre> Show disk usage<pre><code>df -h\n</code></pre> Check disk space usage<pre><code>du -sh /path/to/directory\n</code></pre> Mount a disk<pre><code>mount /dev/sdb1 /mnt\n</code></pre> Unmount a disk<pre><code>umount /mnt\n</code></pre> Format a disk<pre><code>mkfs.ext4 /dev/sdb1\n</code></pre> Check filesystem usage<pre><code>df -Th\n</code></pre> Check disk health<pre><code>smartctl -a /dev/sdb\n</code></pre></p>"},{"location":"13_Storage/#aws-s3","title":"AWS S3","text":"<p>List all S3 buckets<pre><code>aws s3 ls\n</code></pre> Upload a file to S3<pre><code>aws s3 cp file.txt s3://mybucket/\n</code></pre> Download a file from S3<pre><code>aws s3 cp s3://mybucket/file.txt .\n</code></pre> Sync local directory to S3<pre><code>aws s3 sync /local/path s3://mybucket/\n</code></pre></p>"},{"location":"13_Storage/#azure-blob-storage","title":"Azure Blob Storage","text":"<p>List all storage accounts<pre><code>az storage account list\n</code></pre> Upload a file to Azure Blob<pre><code>az storage blob upload --container-name mycontainer --file file.txt --name file.txt\n</code></pre> Download a file from Azure Blob<pre><code>az storage blob download --container-name mycontainer --name file.txt --file file.txt\n</code></pre></p>"},{"location":"13_Storage/#google-cloud-storage-gcs","title":"Google Cloud Storage (GCS)","text":"<p>List GCS buckets<pre><code>gsutil ls\n</code></pre> Upload a file to GCS<pre><code>gsutil cp file.txt gs://mybucket/\n</code></pre> Download a file from GCS<pre><code>gsutil cp gs://mybucket/file.txt .\n</code></pre></p>"},{"location":"13_Storage/#linux-storage-monitoring","title":"Linux Storage Monitoring","text":"<p>Monitor disk usage in real-time<pre><code>iotop\n</code></pre> Check disk performance<pre><code>iostat -x 1\n</code></pre></p>"},{"location":"13_Storage/#linux-backup","title":"Linux Backup","text":"Backup using rsync<pre><code>rsync -av --delete /source/ /backup/\n</code></pre>"},{"location":"13_Storage/#aws-backup","title":"AWS Backup","text":"Backup data to AWS S3<pre><code>aws s3 sync /data s3://backup-bucket/\n</code></pre>"},{"location":"13_Storage/#azure-backup","title":"Azure Backup","text":"Backup data to Azure Blob<pre><code>az storage blob upload-batch --destination mycontainer --source /data\n</code></pre>"},{"location":"13_Storage/#yaml-configurations","title":"YAML Configurations:","text":""},{"location":"13_Storage/#persistent-volume-pv","title":"Persistent Volume (PV)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: my-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  hostPath:\n    path: \"/mnt/data\"\n</code></pre>"},{"location":"13_Storage/#persistent-volume-claim-pvc","title":"Persistent Volume Claim (PVC)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-pvc\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n</code></pre>"},{"location":"13_Storage/#pod-with-persistent-volume","title":"Pod with Persistent Volume","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: app\n    image: nginx\n    volumeMounts:\n    - mountPath: \"/usr/share/nginx/html\"\n      name: storage-volume\n  volumes:\n  - name: storage-volume\n    persistentVolumeClaim:\n    claimName: my-pvc\n</code></pre>"},{"location":"13_Storage/#terraform-configurations","title":"Terraform Configurations:","text":"<ul> <li>AWS S3 Bucket</li> </ul> <pre><code>provider \"aws\" { \n  region = \"us-east-1\"\n}\nresource \"aws_s3_bucket\" \"devops_bucket\" { \n  bucket = \"devops-backup-bucket\"\n  acl = \"private\"\n}\noutput \"bucket_name\" {\n  value = aws_s3_bucket.devops_bucket.id\n}\n</code></pre> <ul> <li>Azure Storage Account</li> </ul> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_storage_account\" \"example\" { \n  name = \"devopsstorageacc\" \n  resource_group_name = \"devops-rg\"\n  location = \"East US\"\n  account_tier = \"Standard\" \n  account_replication_type = \"LRS\"\n}\n</code></pre>"},{"location":"14_Helm/","title":"Helm Chart","text":"<p>What is Helm?</p> <ul> <li>Helm helps deploy applications in Kubernetes using pre-configured templates called Helm Charts.</li> <li>A Chart is a collection of files that describe a Kubernetes application.</li> </ul>"},{"location":"14_Helm/#helm-basics","title":"Helm Basics","text":"Check which version of Helm is installed<pre><code>helm version\n</code></pre> Get help with Helm commands<pre><code>helm help\n</code></pre> Show all added Helm repositories<pre><code>helm repo list\n</code></pre>"},{"location":"14_Helm/#adding-and-updating-repositories","title":"Adding and Updating Repositories","text":"Add a repository<pre><code>helm repo add &lt;repo-name&gt; &lt;repo-url&gt;\n</code></pre> Get the latest list of available charts<pre><code>helm repo update\n</code></pre> Search for a chart<pre><code>helm search repo &lt;chart-name&gt;\n</code></pre>"},{"location":"14_Helm/#installing-applications-using-helm","title":"Installing Applications using Helm","text":"Install an application<pre><code>helm install &lt;release-name&gt; &lt;chart&gt;\n</code></pre> See running applications in Kubernetes<pre><code>kubectl get pods\n</code></pre>"},{"location":"14_Helm/#listing-installed-applications","title":"Listing Installed Applications","text":"Show all installed applications<pre><code>helm list\n</code></pre>"},{"location":"14_Helm/#checking-application-details","title":"Checking Application Details","text":"Check the status of your installed application<pre><code>helm status &lt;release-name&gt;\n</code></pre> See configuration values used<pre><code>helm get values &lt;release-name&gt;\n</code></pre>"},{"location":"14_Helm/#updating-an-installed-application","title":"Updating an Installed Application","text":"Update an installed application<pre><code>helm upgrade &lt;release-name&gt; &lt;chart&gt; --set &lt;parameter&gt;\n</code></pre>"},{"location":"14_Helm/#uninstalling-an-application","title":"Uninstalling an Application","text":"Remove an application<pre><code>helm uninstall &lt;release-name&gt;\n</code></pre>"},{"location":"14_Helm/#debugging-helm-charts","title":"Debugging Helm Charts","text":"Check for issues in a Helm chart<pre><code>helm lint &lt;chart&gt;\n</code></pre> Simulate installation<pre><code>helm install --debug --dry-run &lt;release-name&gt; &lt;chart&gt;\n</code></pre>"},{"location":"14_Helm/#creating-your-own-helm-chart","title":"Creating Your Own Helm Chart","text":"Create a new Helm chart<pre><code>helm create &lt;chart-name&gt;\n</code></pre>"},{"location":"15_Scenario_1/","title":"Scenario #1","text":""},{"location":"15_Scenario_1/#context","title":"Context:","text":"<p>You\u2019ve been paged for an alert due to a sudden spike in HTTP 5xx errors in production. Your task is to quickly identify and summarize the spike from web server logs.</p>"},{"location":"15_Scenario_1/#objective","title":"Objective:","text":"<p>Write a Python script that parses a given web server log_lines below and identifies time windows with a spike in 5xx HTTP errors.</p>"},{"location":"15_Scenario_1/#logs","title":"Logs","text":"<pre><code>log_lines = [\n    \"2025-05-04 09:34:01,818 - INFO - 500 Service error\",\n    \"2025-05-04 09:39:20,912 - INFO - 500 Timeout\",\n    \"2025-05-04 09:55:45,999 - INFO - 503 Backend unavailable\",\n    \"2025-05-04 09:57:01,101 - INFO - 200 OK...\",\n    \"2025-05-04 09:58:20,912 - INFO - 500 Timeout\",\n    \"2025-05-04 09:58:45,999 - INFO - 503 Backend unavailable\",\n    \"2025-05-04 09:58:50,912 - INFO - 500 Timeout\",\n    \"2025-05-04 10:01:01,600 - INFO - 500 Service error\",\n    \"2025-05-04 10:01:20,710 - INFO - 500 Timeout\"\n]\n</code></pre>"},{"location":"15_Scenario_1/#requirements","title":"Requirements:","text":"<ol> <li>Read the log file and extract:<ul> <li>Timestamp (minute granularity)</li> <li>HTTP status code</li> </ul> </li> <li>Detect spike windows:<ul> <li>A \u201cspike\u201d is defined as 2 or more requests with 5xx status codes in any one-minute window.</li> </ul> </li> <li> <p>Output:</p> <ul> <li>Print all time windows (minute-resolution) that qualify as a spike.</li> <li>For each window, print the timestamp and number of 5xx errors.</li> <li>Example output:</li> </ul> <pre><code>5xx Error Spike Detection\n-----------------------------\nSpike detected!\n2025-05-04 09:58 \u2192 3 errors\nSpike detected!\n2025-05-04 10:01 \u2192 2 errors\n</code></pre> </li> </ol>"},{"location":"15_Scenario_1/#python-script","title":"Python Script","text":"detect_500_spikes.py<pre><code>#!/usr/bin/env python3\n\n'''\nDetect 5xx error spikes in a web\u2011server log.\n\nA spike = 2 or more 5xx responses in the same minute.\n'''\n\nimport re\nfrom collections import Counter\nfrom datetime import datetime\n\n# ----------------------------------------------------------------------\n# Parse the log lines\n\nlog_lines = [\n    \"2025-05-04 09:34:01,818 - INFO - 500 Service error\",\n    \"2025-05-04 09:39:20,912 - INFO - 500 Timeout\",\n    \"2025-05-04 09:55:45,999 - INFO - 503 Backend unavailable\",\n    \"2025-05-04 09:57:01,101 - INFO - 200 OK...\",\n    \"2025-05-04 09:58:20,912 - INFO - 500 Timeout\",\n    \"2025-05-04 09:58:45,999 - INFO - 503 Backend unavailable\",\n    \"2025-05-04 09:58:50,912 - INFO - 500 Timeout\",\n    \"2025-05-04 10:01:01,600 - INFO - 500 Service error\",\n    \"2025-05-04 10:01:20,710 - INFO - 500 Timeout\"\n]\n\n# Regex that grabs:\n#   1) the timestamp (YYYY-MM-DD HH:MM:SS,mmm)\n#   2) the numeric HTTP status code\n\nLOG_RE = re.compile(\n    r'(?P&lt;ts&gt;\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) - .* - (?P&lt;code&gt;\\d{3})'\n)\n\n# ----------------------------------------------------------------------\n# Count 5xx errors per minute\n\nminute_counts = Counter()\n\nfor line in log_lines:\n    m = LOG_RE.search(line)\n    if not m:\n        continue  # ignore lines that don't match the expected format\n\n    ts_str = m.group('ts')\n    code   = int(m.group('code'))\n\n    # We only care about 5xx status codes\n    if 500 &lt;= code &lt; 600:\n        # Convert timestamp to minute granularity\n        ts = datetime.strptime(ts_str, \"%Y-%m-%d %H:%M:%S,%f\")\n        minute_key = ts.strftime(\"%Y-%m-%d %H:%M\")\n        minute_counts[minute_key] += 1\n\n# ----------------------------------------------------------------------\n# Identify and print spike windows\n\nprint(\"5xx Error Spike Detection\")\nprint(\"-\" * 30)\n\nfor minute, count in sorted(minute_counts.items()):\n    if count &gt;= 2:\n        print(\"Spike detected!\")\n        print(f\"{minute} \u2192 {count} errors\")\n</code></pre> <p>Note</p> <p>To read a real log file instead of the hard\u2011coded list, just replace the <code>log_lines</code> loop with a file read:</p> <pre><code>with open('access.log', 'r', encoding='utf-8') as fh:\n\nLOG_RE = re.compile(\n    r'(?P&lt;ts&gt;\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) - .* - (?P&lt;code&gt;\\d{3})'\n)\n\n# ----------------------------------------------------------------------\n# Count 5xx errors per minute\n\nminute_counts = Counter()\n\nfor line in fh:\n        # ... same processing ...\n</code></pre>"},{"location":"15_Scenario_1/#how-it-works","title":"How it works","text":"Step What it does Why it\u2019s useful Parse the log Uses a regex to capture the timestamp and status code from each line. Keeps the code simple \u2013 we only care about those two pieces of data. Normalize to minutes Converts each full timestamp to a string that contains only the year\u2011month\u2011day and hour\u2011minute. A minute\u2011resolution key lets us aggregate counts efficiently. Count 5xx errors For each 5xx status code, increment a <code>Counter</code> entry keyed by the minute. We only want to flag minutes that hit the threshold. Detect spikes Scan the counter; any minute with 2+ errors is a spike. The problem statement\u2019s definition of a spike. Print A small header followed by a friendly \u201cSpike detected!\u201d line for each minute. Matches the example output you provided."},{"location":"15_Scenario_1/#the-regular-expression-in-plain-english","title":"The regular expression in plain English","text":"<pre><code>LOG_RE = re.compile(\n    r'(?P&lt;ts&gt;\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) - .* - (?P&lt;code&gt;\\d{3})'\n)\n</code></pre> Piece What it matches Why we need it <code>(?P&lt;ts&gt; \u2026 )</code> Named group called <code>ts</code> \u2013 the part of the string that will be retrieved as <code>match.group('ts')</code>. Lets us pull out the timestamp later without having to remember its position in the regex. <code>\\d{4}</code> Exactly four digits (e.g., <code>2025</code>). The year part of the timestamp. <code>-</code> A literal hyphen. Separates year from month. <code>\\d{2}</code> Exactly two digits (e.g., <code>05</code>). The month. <code>-</code> Literal hyphen. Separates month from day. <code>\\d{2}</code> Exactly two digits (e.g., <code>04</code>). The day. <code></code> A single space. Separates date from time. <code>\\d{2}</code> Two digits for the hour (00\u201123). <code>:</code> Literal colon. Separates hour from minute. <code>\\d{2}</code> Two digits for the minute (00\u201159). <code>:</code> Literal colon. Separates minute from second. <code>\\d{2}</code> Two digits for the second (00\u201159). <code>,</code> Literal comma. In this log format the millisecond separator is a comma, not a period. <code>\\d{3}</code> Exactly three digits \u2013 the milliseconds. <code>)</code> End of the named group <code>ts</code>. <code>- .* -</code> Matches the literal string <code>\" - \"</code> followed by any characters (as many as possible) and then another <code>\" - \"</code>. In the log line this section looks like <code>- INFO -</code>.  We don\u2019t care about the log level or any other text, so we just consume it with <code>.*</code>.  The surrounding dashes act as clear boundaries. <code>(?P&lt;code&gt;\\d{3})</code> Named group called <code>code</code> that contains exactly three digits. This is the HTTP status code (e.g., <code>500</code>, <code>503</code>, <code>200</code>).  We\u2019ll later cast it to an integer to test whether it\u2019s a 5xx error."},{"location":"15_Scenario_1/#fullline-example","title":"Full\u2011line example","text":"<pre><code>2025-05-04 09:34:01,818 - INFO - 500 Service error\n</code></pre> <ul> <li><code>(?P&lt;ts&gt; \u2026 )</code> captures <code>2025-05-04 09:34:01,818</code></li> <li><code>- .* -</code> consumes <code>- INFO -</code> (the <code>.*</code> gobbles the <code>INFO</code>)</li> <li><code>(?P&lt;code&gt;\\d{3})</code> captures <code>500</code></li> <li>Everything after the code (<code>Service error</code>) is ignored because the regex ends there.</li> </ul>"}]}